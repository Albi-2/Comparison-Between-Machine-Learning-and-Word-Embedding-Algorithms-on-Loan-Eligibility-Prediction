{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d2c91a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f460afa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "import numpy as np\n",
    "from pprint import pprint as pp\n",
    "import csv\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "from itertools import product\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from imblearn.pipeline import Pipeline \n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import r2_score, classification_report, confusion_matrix, accuracy_score, roc_auc_score, roc_curve, precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import homogeneity_score, silhouette_score\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import MiniBatchKMeans, DBSCAN\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17e9cee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, precision_score, recall_score, f1_score, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6238cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, precision_score, recall_score, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75e8fc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.combine import SMOTETomek\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "378df2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0db62d0",
   "metadata": {},
   "source": [
    "### Retrieving the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10513ea6",
   "metadata": {},
   "source": [
    "#### DF 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc3d2069",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = pd.read_csv('df5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82ed7cb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>emp_title</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>issue_d</th>\n",
       "      <th>pymnt_plan</th>\n",
       "      <th>purpose</th>\n",
       "      <th>title</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>addr_state</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>earliest_cr_line</th>\n",
       "      <th>fico_range_low</th>\n",
       "      <th>fico_range_high</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>mths_since_last_delinq</th>\n",
       "      <th>mths_since_last_record</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>revol_bal</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>total_acc</th>\n",
       "      <th>out_prncp</th>\n",
       "      <th>out_prncp_inv</th>\n",
       "      <th>total_pymnt</th>\n",
       "      <th>total_pymnt_inv</th>\n",
       "      <th>total_rec_prncp</th>\n",
       "      <th>total_rec_int</th>\n",
       "      <th>total_rec_late_fee</th>\n",
       "      <th>recoveries</th>\n",
       "      <th>collection_recovery_fee</th>\n",
       "      <th>last_pymnt_d</th>\n",
       "      <th>last_pymnt_amnt</th>\n",
       "      <th>next_pymnt_d</th>\n",
       "      <th>last_credit_pull_d</th>\n",
       "      <th>last_fico_range_high</th>\n",
       "      <th>last_fico_range_low</th>\n",
       "      <th>collections_12_mths_ex_med</th>\n",
       "      <th>acc_now_delinq</th>\n",
       "      <th>chargeoff_within_12_mths</th>\n",
       "      <th>delinq_amnt</th>\n",
       "      <th>pub_rec_bankruptcies</th>\n",
       "      <th>tax_liens</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1077501.0</td>\n",
       "      <td>1296599.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>4975.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1065</td>\n",
       "      <td>162.87</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>25275</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3160</td>\n",
       "      <td>860</td>\n",
       "      <td>3</td>\n",
       "      <td>27.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>735.0</td>\n",
       "      <td>739.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13648.0</td>\n",
       "      <td>0.837</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5863.155187</td>\n",
       "      <td>5833.84</td>\n",
       "      <td>5000.00</td>\n",
       "      <td>863.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>171.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>744.0</td>\n",
       "      <td>740.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1077430.0</td>\n",
       "      <td>1314167.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1527</td>\n",
       "      <td>59.83</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>20173</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17558</td>\n",
       "      <td>309</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>740.0</td>\n",
       "      <td>744.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1687.0</td>\n",
       "      <td>0.094</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1008.710000</td>\n",
       "      <td>1008.71</td>\n",
       "      <td>456.46</td>\n",
       "      <td>435.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117.08</td>\n",
       "      <td>1.11</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>119.66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>499.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         id  member_id  loan_amnt  funded_amnt  funded_amnt_inv  \\\n",
       "0           0  1077501.0  1296599.0     5000.0       5000.0           4975.0   \n",
       "1           1  1077430.0  1314167.0     2500.0       2500.0           2500.0   \n",
       "\n",
       "   term  int_rate  installment  grade  sub_grade  emp_title  emp_length  \\\n",
       "0     0    0.1065       162.87      1          6      25275        10.0   \n",
       "1     1    0.1527        59.83      2         13      20173         1.0   \n",
       "\n",
       "   home_ownership  annual_inc  verification_status  issue_d  pymnt_plan  \\\n",
       "0               4     24000.0                    2   2011.0           0   \n",
       "1               4     30000.0                    1   2011.0           0   \n",
       "\n",
       "   purpose  title  zip_code  addr_state    dti  delinq_2yrs  earliest_cr_line  \\\n",
       "0        1   3160       860           3  27.65          0.0            1985.0   \n",
       "1        0  17558       309          10   1.00          0.0            1999.0   \n",
       "\n",
       "   fico_range_low  fico_range_high  inq_last_6mths  mths_since_last_delinq  \\\n",
       "0           735.0            739.0             1.0                   500.0   \n",
       "1           740.0            744.0             5.0                   500.0   \n",
       "\n",
       "   mths_since_last_record  open_acc  pub_rec  revol_bal  revol_util  \\\n",
       "0                   222.0       3.0      0.0    13648.0       0.837   \n",
       "1                   222.0       3.0      0.0     1687.0       0.094   \n",
       "\n",
       "   total_acc  out_prncp  out_prncp_inv  total_pymnt  total_pymnt_inv  \\\n",
       "0        9.0        0.0            0.0  5863.155187          5833.84   \n",
       "1        4.0        0.0            0.0  1008.710000          1008.71   \n",
       "\n",
       "   total_rec_prncp  total_rec_int  total_rec_late_fee  recoveries  \\\n",
       "0          5000.00         863.16                 0.0        0.00   \n",
       "1           456.46         435.17                 0.0      117.08   \n",
       "\n",
       "   collection_recovery_fee  last_pymnt_d  last_pymnt_amnt  next_pymnt_d  \\\n",
       "0                     0.00        2015.0           171.62           0.0   \n",
       "1                     1.11        2013.0           119.66           0.0   \n",
       "\n",
       "   last_credit_pull_d  last_fico_range_high  last_fico_range_low  \\\n",
       "0              2016.0                 744.0                740.0   \n",
       "1              2016.0                 499.0                  0.0   \n",
       "\n",
       "   collections_12_mths_ex_med  acc_now_delinq  chargeoff_within_12_mths  \\\n",
       "0                           0               0                         0   \n",
       "1                           0               0                         0   \n",
       "\n",
       "   delinq_amnt  pub_rec_bankruptcies  tax_liens  target  \n",
       "0          0.0                   0.0          0       1  \n",
       "1          0.0                   0.0          0       2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed385af",
   "metadata": {},
   "source": [
    "#### DF 5c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4218b67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df5c = pd.read_csv('df5c.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "026f4728",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df5c.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f9963f",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b0bea07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store evaluation metrics for each fold\n",
    "dataset_used = []\n",
    "model_used = []\n",
    "data_balancing_technique = []\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "conf_matrices = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e6d6d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combined_metrics = pd.DataFrame()\n",
    "\n",
    "combined_metrics = pd.DataFrame(columns=['dataset', 'model', 'data balancing technique', 'fold', 'precision_1','precision_2','recall_1','recall_2','f1-score_1','f1-score_2','support_1','support_2','TP','FP','TN','FN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052cda7c",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedf6e11",
   "metadata": {},
   "source": [
    "## DF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89f99b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:\n",
      "2\n",
      "Fold:\n",
      "3\n",
      "Fold:\n",
      "4\n",
      "Fold:\n",
      "5\n",
      "Fold:\n",
      "6\n",
      "Mean Accuracy: 0.86\n",
      "Mean Precision: 0.88\n",
      "Mean Recall: 0.86\n",
      "Mean F1-Score: 0.80\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df5' is your DataFrame with features and the target column\n",
    "# Replace 'features' with the actual list of feature columns\n",
    "features = df5.drop(columns=['target'])  # Drop the target column to get the feature columns\n",
    "target = df5['target']  # Target column to predict\n",
    "\n",
    "# Initialize SVC model\n",
    "model = SVC()\n",
    "\n",
    "# Initialize KFold with 10 folds\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the testing set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    y_pred = np.round(y_pred)\n",
    "    \n",
    "    y_pred[y_pred <= 0] = 1\n",
    "    y_pred[y_pred >= 2] = 2\n",
    "    \n",
    "    # Model evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred.round())\n",
    "    precision = precision_score(y_test, y_pred.round(), average='weighted')\n",
    "    recall = recall_score(y_test, y_pred.round(), average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred.round(), average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred.round())\n",
    "    \n",
    "    \n",
    "    # Convert classification report to DataFrame\n",
    "    report_df = pd.DataFrame(classification_report(y_test, y_pred.round(), output_dict=True)).transpose()\n",
    "    # Convert confusion matrix to DataFrame\n",
    "    matrix_df = pd.DataFrame(confusion_matrix(y_test, y_pred.round()))\n",
    "    \n",
    "    # Extract metrics for class 1\n",
    "    metrics_1 = report_df.loc['1', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract metrics for class 2\n",
    "    metrics_2 = report_df.loc['2', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract TP, TN, FP, FN counts from the confusion matrix DataFrame\n",
    "    TP = matrix_df.loc[0, 0]\n",
    "    TN = matrix_df.loc[1, 1]\n",
    "    FP = matrix_df.loc[1, 0]\n",
    "    FN = matrix_df.loc[0, 1]\n",
    "    \n",
    "    new_metric_row = {\n",
    "    'dataset': 'DF5',\n",
    "    'model' : 'SVC',\n",
    "    'data balancing technique' : 'None',\n",
    "    'fold' : i,\n",
    "    'precision_1': metrics_1['precision'],\n",
    "    'precision_2': metrics_2['precision'],\n",
    "    'recall_1': metrics_1['recall'],\n",
    "    'recall_2': metrics_2['recall'],\n",
    "    'f1-score_1': metrics_1['f1-score'],\n",
    "    'f1-score_2': metrics_2['f1-score'],\n",
    "    'support_1': metrics_1['support'],\n",
    "    'support_2': metrics_2['support'],\n",
    "    'TP' : TP,\n",
    "    'FP' : FP,\n",
    "    'TN' : TN,\n",
    "    'FN' : FN\n",
    "    }\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    #combined_metrics = combined_metrics.append(new_metric_row, ignore_index=True)\n",
    "    combined_metrics.loc[len(combined_metrics)] = new_metric_row\n",
    "    \n",
    "    \n",
    "    # Append evaluation metrics to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "    \n",
    "    print(\"Fold:\")\n",
    "    print(i)\n",
    "\n",
    "# Calculate mean evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores) #sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = np.mean(precision_scores) #sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = np.mean(recall_scores) #sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = np.mean(f1_scores) #sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print('Mean Accuracy: {:.2f}'.format(mean_accuracy))\n",
    "print('Mean Precision: {:.2f}'.format(mean_precision))\n",
    "print('Mean Recall: {:.2f}'.format(mean_recall))\n",
    "print('Mean F1-Score: {:.2f}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5cd58d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>data balancing technique</th>\n",
       "      <th>fold</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_2</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>f1-score_1</th>\n",
       "      <th>f1-score_2</th>\n",
       "      <th>support_1</th>\n",
       "      <th>support_2</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DF5</td>\n",
       "      <td>SVC</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0.853199</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.013300</td>\n",
       "      <td>0.920785</td>\n",
       "      <td>0.026250</td>\n",
       "      <td>18110.0</td>\n",
       "      <td>3158.0</td>\n",
       "      <td>18110</td>\n",
       "      <td>3116</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DF5</td>\n",
       "      <td>SVC</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>0.847168</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.008552</td>\n",
       "      <td>0.917261</td>\n",
       "      <td>0.016959</td>\n",
       "      <td>17993.0</td>\n",
       "      <td>3274.0</td>\n",
       "      <td>17993</td>\n",
       "      <td>3246</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset model data balancing technique  fold  precision_1  precision_2  \\\n",
       "0     DF5   SVC                     None     1     0.853199          1.0   \n",
       "1     DF5   SVC                     None     2     0.847168          1.0   \n",
       "\n",
       "   recall_1  recall_2  f1-score_1  f1-score_2  support_1  support_2     TP  \\\n",
       "0       1.0  0.013300    0.920785    0.026250    18110.0     3158.0  18110   \n",
       "1       1.0  0.008552    0.917261    0.016959    17993.0     3274.0  17993   \n",
       "\n",
       "     FP  TN  FN  \n",
       "0  3116  42   0  \n",
       "1  3246  28   0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_metrics[(combined_metrics['data balancing technique'] == 'None') & (combined_metrics['dataset'] == 'DF5')].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd45aea",
   "metadata": {},
   "source": [
    "### SVC with df5 data and imbalance data tackling (SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eaaba2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Assuming 'df5' is your DataFrame with features and the target column\n",
    "# Replace 'features' with the actual list of feature columns\n",
    "features = df5.drop(columns=['target'])  # Drop the target column to get the feature columns\n",
    "target = df5['target']  # Target column to predict\n",
    "\n",
    "# Initialize SVC model\n",
    "model = SVC()\n",
    "\n",
    "# Initialize KFold with 10 folds\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    # Apply SMOTE to the training data\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Predict on the testing set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    y_pred = np.round(y_pred)\n",
    "    \n",
    "    y_pred[y_pred <= 0] = 1\n",
    "    y_pred[y_pred >= 2] = 2\n",
    "    \n",
    "    # Model evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred.round())\n",
    "    precision = precision_score(y_test, y_pred.round(), average='weighted')\n",
    "    recall = recall_score(y_test, y_pred.round(), average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred.round(), average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred.round())\n",
    "    \n",
    "    # Convert classification report to DataFrame\n",
    "    report_df = pd.DataFrame(classification_report(y_test, y_pred.round(), output_dict=True)).transpose()\n",
    "    # Convert confusion matrix to DataFrame\n",
    "    matrix_df = pd.DataFrame(confusion_matrix(y_test, y_pred.round()))\n",
    "    \n",
    "    # Extract metrics for class 1\n",
    "    metrics_1 = report_df.loc['1', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract metrics for class 2\n",
    "    metrics_2 = report_df.loc['2', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract TP, TN, FP, FN counts from the confusion matrix DataFrame\n",
    "    TP = matrix_df.loc[0, 0]\n",
    "    TN = matrix_df.loc[1, 1]\n",
    "    FP = matrix_df.loc[1, 0]\n",
    "    FN = matrix_df.loc[0, 1]\n",
    "    \n",
    "    new_metric_row = {\n",
    "    'dataset': 'DF5',\n",
    "    'model' : 'SVC',\n",
    "    'data balancing technique' : 'SMOTE',\n",
    "    'fold' : i,\n",
    "    'precision_1': metrics_1['precision'],\n",
    "    'precision_2': metrics_2['precision'],\n",
    "    'recall_1': metrics_1['recall'],\n",
    "    'recall_2': metrics_2['recall'],\n",
    "    'f1-score_1': metrics_1['f1-score'],\n",
    "    'f1-score_2': metrics_2['f1-score'],\n",
    "    'support_1': metrics_1['support'],\n",
    "    'support_2': metrics_2['support'],\n",
    "    'TP' : TP,\n",
    "    'FP' : FP,\n",
    "    'TN' : TN,\n",
    "    'FN' : FN\n",
    "    }\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    #combined_metrics = combined_metrics.append(new_metric_row, ignore_index=True)\n",
    "    combined_metrics.loc[len(combined_metrics)] = new_metric_row\n",
    "    \n",
    "    \n",
    "    # Append evaluation metrics to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "    \n",
    "    print(\"Fold:\")\n",
    "    print(i)\n",
    "\n",
    "# Calculate mean evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores) #sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = np.mean(precision_scores) #sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = np.mean(recall_scores) #sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = np.mean(f1_scores) #sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print('Mean Accuracy: {:.2f}'.format(mean_accuracy))\n",
    "print('Mean Precision: {:.2f}'.format(mean_precision))\n",
    "print('Mean Recall: {:.2f}'.format(mean_recall))\n",
    "print('Mean F1-Score: {:.2f}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "031ffc3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>data balancing technique</th>\n",
       "      <th>fold</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_2</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>f1-score_1</th>\n",
       "      <th>f1-score_2</th>\n",
       "      <th>support_1</th>\n",
       "      <th>support_2</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DF5</td>\n",
       "      <td>SVC</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>1</td>\n",
       "      <td>0.974475</td>\n",
       "      <td>0.640824</td>\n",
       "      <td>0.918477</td>\n",
       "      <td>0.858070</td>\n",
       "      <td>0.945648</td>\n",
       "      <td>0.733703</td>\n",
       "      <td>7274.0</td>\n",
       "      <td>1233.0</td>\n",
       "      <td>6681</td>\n",
       "      <td>175</td>\n",
       "      <td>1058</td>\n",
       "      <td>593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DF5</td>\n",
       "      <td>SVC</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>2</td>\n",
       "      <td>0.969016</td>\n",
       "      <td>0.723997</td>\n",
       "      <td>0.943798</td>\n",
       "      <td>0.830086</td>\n",
       "      <td>0.956241</td>\n",
       "      <td>0.773420</td>\n",
       "      <td>7224.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>6818</td>\n",
       "      <td>218</td>\n",
       "      <td>1065</td>\n",
       "      <td>406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DF5</td>\n",
       "      <td>SVC</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>3</td>\n",
       "      <td>0.976091</td>\n",
       "      <td>0.618182</td>\n",
       "      <td>0.904083</td>\n",
       "      <td>0.875195</td>\n",
       "      <td>0.938708</td>\n",
       "      <td>0.724572</td>\n",
       "      <td>7225.0</td>\n",
       "      <td>1282.0</td>\n",
       "      <td>6532</td>\n",
       "      <td>160</td>\n",
       "      <td>1122</td>\n",
       "      <td>693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset model data balancing technique  fold  precision_1  precision_2  \\\n",
       "7     DF5   SVC                    SMOTE     1     0.974475     0.640824   \n",
       "8     DF5   SVC                    SMOTE     2     0.969016     0.723997   \n",
       "9     DF5   SVC                    SMOTE     3     0.976091     0.618182   \n",
       "\n",
       "   recall_1  recall_2  f1-score_1  f1-score_2  support_1  support_2    TP  \\\n",
       "7  0.918477  0.858070    0.945648    0.733703     7274.0     1233.0  6681   \n",
       "8  0.943798  0.830086    0.956241    0.773420     7224.0     1283.0  6818   \n",
       "9  0.904083  0.875195    0.938708    0.724572     7225.0     1282.0  6532   \n",
       "\n",
       "    FP    TN   FN  \n",
       "7  175  1058  593  \n",
       "8  218  1065  406  \n",
       "9  160  1122  693  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_metrics[(combined_metrics['data balancing technique'] == 'SMOTE') & (combined_metrics['dataset'] == 'DF5')]#.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737bdf77",
   "metadata": {},
   "source": [
    "### SVC with df5 data and imbalance data tackling (RandomUnderSampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0efc30fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.73\n",
      "Mean Precision: 0.88\n",
      "Mean Recall: 0.73\n",
      "Mean F1-Score: 0.74\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df5' is your DataFrame with features and the target column\n",
    "# Replace 'features' with the actual list of feature columns\n",
    "features = df5.drop(columns=['target'])  # Drop the target column to get the feature columns\n",
    "target = df5['target']  # Target column to predict\n",
    "\n",
    "# Initialize SVC model\n",
    "model = SVC()\n",
    "\n",
    "# Initialize KFold with 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    # Undersampling the majority class\n",
    "    rus = RandomUnderSampler(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Predict on the testing set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    y_pred = np.round(y_pred)\n",
    "    \n",
    "    y_pred[y_pred <= 0] = 1\n",
    "    y_pred[y_pred >= 2] = 2\n",
    "    \n",
    "    # Model evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred.round())\n",
    "    precision = precision_score(y_test, y_pred.round(), average='weighted')\n",
    "    recall = recall_score(y_test, y_pred.round(), average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred.round(), average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred.round())\n",
    "    \n",
    "    # Convert classification report to DataFrame\n",
    "    report_df = pd.DataFrame(classification_report(y_test, y_pred.round(), output_dict=True)).transpose()\n",
    "    # Convert confusion matrix to DataFrame\n",
    "    matrix_df = pd.DataFrame(confusion_matrix(y_test, y_pred.round()))\n",
    "    \n",
    "    # Extract metrics for class 1\n",
    "    metrics_1 = report_df.loc['1', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract metrics for class 2\n",
    "    metrics_2 = report_df.loc['2', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract TP, TN, FP, FN counts from the confusion matrix DataFrame\n",
    "    TP = matrix_df.loc[0, 0]\n",
    "    TN = matrix_df.loc[1, 1]\n",
    "    FP = matrix_df.loc[1, 0]\n",
    "    FN = matrix_df.loc[0, 1]\n",
    "    \n",
    "    new_metric_row = {\n",
    "    'dataset': 'DF5',\n",
    "    'model' : 'SVC',\n",
    "    'data balancing technique' : 'Random Under Sampler',\n",
    "    'fold' : i,\n",
    "    'precision_1': metrics_1['precision'],\n",
    "    'precision_2': metrics_2['precision'],\n",
    "    'recall_1': metrics_1['recall'],\n",
    "    'recall_2': metrics_2['recall'],\n",
    "    'f1-score_1': metrics_1['f1-score'],\n",
    "    'f1-score_2': metrics_2['f1-score'],\n",
    "    'support_1': metrics_1['support'],\n",
    "    'support_2': metrics_2['support'],\n",
    "    'TP' : TP,\n",
    "    'FP' : FP,\n",
    "    'TN' : TN,\n",
    "    'FN' : FN\n",
    "    }\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    #combined_metrics = combined_metrics.append(new_metric_row, ignore_index=True)\n",
    "    combined_metrics.loc[len(combined_metrics)] = new_metric_row\n",
    "    \n",
    "    \n",
    "    # Append evaluation metrics to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "\n",
    "# Calculate mean evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores) #sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = np.mean(precision_scores) #sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = np.mean(recall_scores) #sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = np.mean(f1_scores) #sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print('Mean Accuracy: {:.2f}'.format(mean_accuracy))\n",
    "print('Mean Precision: {:.2f}'.format(mean_precision))\n",
    "print('Mean Recall: {:.2f}'.format(mean_recall))\n",
    "print('Mean F1-Score: {:.2f}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d72cc02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>data balancing technique</th>\n",
       "      <th>fold</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_2</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>f1-score_1</th>\n",
       "      <th>f1-score_2</th>\n",
       "      <th>support_1</th>\n",
       "      <th>support_2</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DF5</td>\n",
       "      <td>SVC</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>1</td>\n",
       "      <td>0.966309</td>\n",
       "      <td>0.237473</td>\n",
       "      <td>0.519627</td>\n",
       "      <td>0.891980</td>\n",
       "      <td>0.675830</td>\n",
       "      <td>0.375086</td>\n",
       "      <td>3643.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>1893</td>\n",
       "      <td>66</td>\n",
       "      <td>545</td>\n",
       "      <td>1750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DF5</td>\n",
       "      <td>SVC</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>2</td>\n",
       "      <td>0.970807</td>\n",
       "      <td>0.252127</td>\n",
       "      <td>0.540198</td>\n",
       "      <td>0.905145</td>\n",
       "      <td>0.694145</td>\n",
       "      <td>0.394396</td>\n",
       "      <td>3632.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>1962</td>\n",
       "      <td>59</td>\n",
       "      <td>563</td>\n",
       "      <td>1670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset model data balancing technique  fold  precision_1  precision_2  \\\n",
       "10     DF5   SVC     Random Under Sampler     1     0.966309     0.237473   \n",
       "11     DF5   SVC     Random Under Sampler     2     0.970807     0.252127   \n",
       "\n",
       "    recall_1  recall_2  f1-score_1  f1-score_2  support_1  support_2    TP  \\\n",
       "10  0.519627  0.891980    0.675830    0.375086     3643.0      611.0  1893   \n",
       "11  0.540198  0.905145    0.694145    0.394396     3632.0      622.0  1962   \n",
       "\n",
       "    FP   TN    FN  \n",
       "10  66  545  1750  \n",
       "11  59  563  1670  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_metrics[(combined_metrics['data balancing technique'] == 'Random Under Sampler') & (combined_metrics['dataset'] == 'DF5')].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc10646",
   "metadata": {},
   "source": [
    "### SVC with df5 data and imbalance data tackling (RandomOverSampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c500a1fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m X_train_resampled, y_train_resampled \u001b[38;5;241m=\u001b[39m ros\u001b[38;5;241m.\u001b[39mfit_resample(X_train, y_train)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train_resampled, y_train_resampled)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Predict on the testing set\u001b[39;00m\n\u001b[0;32m     27\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:252\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LibSVM]\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    251\u001b[0m seed \u001b[38;5;241m=\u001b[39m rnd\u001b[38;5;241m.\u001b[39mrandint(np\u001b[38;5;241m.\u001b[39miinfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mmax)\n\u001b[1;32m--> 252\u001b[0m fit(X, y, sample_weight, solver_type, kernel, random_seed\u001b[38;5;241m=\u001b[39mseed)\n\u001b[0;32m    253\u001b[0m \u001b[38;5;66;03m# see comment on the other call to np.iinfo in this file\u001b[39;00m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape_fit_ \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m (n_samples,)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:331\u001b[0m, in \u001b[0;36mBaseLibSVM._dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    317\u001b[0m libsvm\u001b[38;5;241m.\u001b[39mset_verbosity_wrap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose)\n\u001b[0;32m    319\u001b[0m \u001b[38;5;66;03m# we don't pass **self.get_params() to allow subclasses to\u001b[39;00m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;66;03m# add other parameters to __init__\u001b[39;00m\n\u001b[0;32m    321\u001b[0m (\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_,\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_vectors_,\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_support,\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdual_coef_,\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_,\n\u001b[0;32m    327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probA,\n\u001b[0;32m    328\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probB,\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_status_,\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_iter,\n\u001b[1;32m--> 331\u001b[0m ) \u001b[38;5;241m=\u001b[39m libsvm\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m    332\u001b[0m     X,\n\u001b[0;32m    333\u001b[0m     y,\n\u001b[0;32m    334\u001b[0m     svm_type\u001b[38;5;241m=\u001b[39msolver_type,\n\u001b[0;32m    335\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m    336\u001b[0m     \u001b[38;5;66;03m# TODO(1.4): Replace \"_class_weight\" with \"class_weight_\"\u001b[39;00m\n\u001b[0;32m    337\u001b[0m     class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_class_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m, np\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;241m0\u001b[39m)),\n\u001b[0;32m    338\u001b[0m     kernel\u001b[38;5;241m=\u001b[39mkernel,\n\u001b[0;32m    339\u001b[0m     C\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mC,\n\u001b[0;32m    340\u001b[0m     nu\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnu,\n\u001b[0;32m    341\u001b[0m     probability\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprobability,\n\u001b[0;32m    342\u001b[0m     degree\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdegree,\n\u001b[0;32m    343\u001b[0m     shrinking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshrinking,\n\u001b[0;32m    344\u001b[0m     tol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol,\n\u001b[0;32m    345\u001b[0m     cache_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_size,\n\u001b[0;32m    346\u001b[0m     coef0\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef0,\n\u001b[0;32m    347\u001b[0m     gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gamma,\n\u001b[0;32m    348\u001b[0m     epsilon\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon,\n\u001b[0;32m    349\u001b[0m     max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter,\n\u001b[0;32m    350\u001b[0m     random_seed\u001b[38;5;241m=\u001b[39mrandom_seed,\n\u001b[0;32m    351\u001b[0m )\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warn_from_fit_status()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Assuming 'df5' is your DataFrame with features and the target column\n",
    "# Replace 'features' with the actual list of feature columns\n",
    "features = df5.drop(columns=['target'])  # Drop the target column to get the feature columns\n",
    "target = df5['target']  # Target column to predict\n",
    "\n",
    "# Initialize SVC model\n",
    "model = SVC()\n",
    "\n",
    "# Initialize KFold with 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    # Oversampling the majority class\n",
    "    ros = RandomOverSampler(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Predict on the testing set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    y_pred = np.round(y_pred)\n",
    "    \n",
    "    y_pred[y_pred <= 0] = 1\n",
    "    y_pred[y_pred >= 2] = 2\n",
    "    \n",
    "    # Model evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred.round())\n",
    "    precision = precision_score(y_test, y_pred.round(), average='weighted')\n",
    "    recall = recall_score(y_test, y_pred.round(), average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred.round(), average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred.round())\n",
    "    \n",
    "    # Convert classification report to DataFrame\n",
    "    report_df = pd.DataFrame(classification_report(y_test, y_pred.round(), output_dict=True)).transpose()\n",
    "    # Convert confusion matrix to DataFrame\n",
    "    matrix_df = pd.DataFrame(confusion_matrix(y_test, y_pred.round()))\n",
    "    \n",
    "    # Extract metrics for class 1\n",
    "    metrics_1 = report_df.loc['1', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract metrics for class 2\n",
    "    metrics_2 = report_df.loc['2', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract TP, TN, FP, FN counts from the confusion matrix DataFrame\n",
    "    TP = matrix_df.loc[0, 0]\n",
    "    TN = matrix_df.loc[1, 1]\n",
    "    FP = matrix_df.loc[1, 0]\n",
    "    FN = matrix_df.loc[0, 1]\n",
    "    \n",
    "    new_metric_row = {\n",
    "    'dataset': 'DF5',\n",
    "    'model' : 'SVC',\n",
    "    'data balancing technique' : 'Random Over Sampler',\n",
    "    'fold' : i,\n",
    "    'precision_1': metrics_1['precision'],\n",
    "    'precision_2': metrics_2['precision'],\n",
    "    'recall_1': metrics_1['recall'],\n",
    "    'recall_2': metrics_2['recall'],\n",
    "    'f1-score_1': metrics_1['f1-score'],\n",
    "    'f1-score_2': metrics_2['f1-score'],\n",
    "    'support_1': metrics_1['support'],\n",
    "    'support_2': metrics_2['support'],\n",
    "    'TP' : TP,\n",
    "    'FP' : FP,\n",
    "    'TN' : TN,\n",
    "    'FN' : FN\n",
    "    }\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    #combined_metrics = combined_metrics.append(new_metric_row, ignore_index=True)\n",
    "    combined_metrics.loc[len(combined_metrics)] = new_metric_row\n",
    "    \n",
    "    \n",
    "    # Append evaluation metrics to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "\n",
    "# Calculate mean evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores) #sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = np.mean(precision_scores) #sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = np.mean(recall_scores) #sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = np.mean(f1_scores) #sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print('Mean Accuracy: {:.2f}'.format(mean_accuracy))\n",
    "print('Mean Precision: {:.2f}'.format(mean_precision))\n",
    "print('Mean Recall: {:.2f}'.format(mean_recall))\n",
    "print('Mean F1-Score: {:.2f}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca7e58c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>data balancing technique</th>\n",
       "      <th>fold</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_2</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>f1-score_1</th>\n",
       "      <th>f1-score_2</th>\n",
       "      <th>support_1</th>\n",
       "      <th>support_2</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>DF5</td>\n",
       "      <td>SVC</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>1</td>\n",
       "      <td>0.967532</td>\n",
       "      <td>0.696629</td>\n",
       "      <td>0.940708</td>\n",
       "      <td>0.811784</td>\n",
       "      <td>0.953932</td>\n",
       "      <td>0.749811</td>\n",
       "      <td>3643.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>3427</td>\n",
       "      <td>115</td>\n",
       "      <td>496</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>DF5</td>\n",
       "      <td>SVC</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>2</td>\n",
       "      <td>0.974709</td>\n",
       "      <td>0.725170</td>\n",
       "      <td>0.944383</td>\n",
       "      <td>0.856913</td>\n",
       "      <td>0.959306</td>\n",
       "      <td>0.785556</td>\n",
       "      <td>3632.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>3430</td>\n",
       "      <td>89</td>\n",
       "      <td>533</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset model data balancing technique  fold  precision_1  precision_2  \\\n",
       "20     DF5   SVC      Random Over Sampler     1     0.967532     0.696629   \n",
       "21     DF5   SVC      Random Over Sampler     2     0.974709     0.725170   \n",
       "\n",
       "    recall_1  recall_2  f1-score_1  f1-score_2  support_1  support_2    TP  \\\n",
       "20  0.940708  0.811784    0.953932    0.749811     3643.0      611.0  3427   \n",
       "21  0.944383  0.856913    0.959306    0.785556     3632.0      622.0  3430   \n",
       "\n",
       "     FP   TN   FN  \n",
       "20  115  496  216  \n",
       "21   89  533  202  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_metrics[(combined_metrics['data balancing technique'] == 'Random Over Sampler') & (combined_metrics['dataset'] == 'DF5')].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3502aa0f",
   "metadata": {},
   "source": [
    "### SVC with df5 data and imbalance data tackling (SMOTEENN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14344c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:\n",
      "2\n",
      "Fold:\n",
      "3\n",
      "Fold:\n",
      "4\n",
      "Fold:\n",
      "5\n",
      "Mean Accuracy: 0.74\n",
      "Mean Precision: 0.88\n",
      "Mean Recall: 0.74\n",
      "Mean F1-Score: 0.75\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df5' is your DataFrame with features and the target column\n",
    "# Replace 'features' with the actual list of feature columns\n",
    "features = df5.drop(columns=['target'])  # Drop the target column to get the feature columns\n",
    "target = df5['target']  # Target column to predict\n",
    "\n",
    "# Initialize SVC model\n",
    "model = SVC()\n",
    "\n",
    "# Initialize KFold with 10 folds\n",
    "kf = KFold(n_splits=4, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    # Apply SMOTEENN for combined over and undersampling\n",
    "    smote_enn = SMOTEENN(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote_enn.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Predict on the testing set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    y_pred = np.round(y_pred)\n",
    "    \n",
    "    y_pred[y_pred <= 0] = 1\n",
    "    y_pred[y_pred >= 2] = 2\n",
    "    \n",
    "    # Model evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred.round())\n",
    "    precision = precision_score(y_test, y_pred.round(), average='weighted')\n",
    "    recall = recall_score(y_test, y_pred.round(), average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred.round(), average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred.round())\n",
    "    \n",
    "    # Convert classification report to DataFrame\n",
    "    report_df = pd.DataFrame(classification_report(y_test, y_pred.round(), output_dict=True)).transpose()\n",
    "    # Convert confusion matrix to DataFrame\n",
    "    matrix_df = pd.DataFrame(confusion_matrix(y_test, y_pred.round()))\n",
    "    \n",
    "    # Extract metrics for class 1\n",
    "    metrics_1 = report_df.loc['1', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract metrics for class 2\n",
    "    metrics_2 = report_df.loc['2', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract TP, TN, FP, FN counts from the confusion matrix DataFrame\n",
    "    TP = matrix_df.loc[0, 0]\n",
    "    TN = matrix_df.loc[1, 1]\n",
    "    FP = matrix_df.loc[1, 0]\n",
    "    FN = matrix_df.loc[0, 1]\n",
    "    \n",
    "    new_metric_row = {\n",
    "    'dataset': 'DF5',\n",
    "    'model' : 'SVC',\n",
    "    'data balancing technique' : 'SMOTEENN',\n",
    "    'fold' : i,\n",
    "    'precision_1': metrics_1['precision'],\n",
    "    'precision_2': metrics_2['precision'],\n",
    "    'recall_1': metrics_1['recall'],\n",
    "    'recall_2': metrics_2['recall'],\n",
    "    'f1-score_1': metrics_1['f1-score'],\n",
    "    'f1-score_2': metrics_2['f1-score'],\n",
    "    'support_1': metrics_1['support'],\n",
    "    'support_2': metrics_2['support'],\n",
    "    'TP' : TP,\n",
    "    'FP' : FP,\n",
    "    'TN' : TN,\n",
    "    'FN' : FN\n",
    "    }\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    #combined_metrics = combined_metrics.append(new_metric_row, ignore_index=True)\n",
    "    combined_metrics.loc[len(combined_metrics)] = new_metric_row\n",
    "    \n",
    "    \n",
    "    # Append evaluation metrics to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "    \n",
    "    print(\"Fold:\")\n",
    "    print(i)\n",
    "\n",
    "# Calculate mean evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores) #sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = np.mean(precision_scores) #sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = np.mean(recall_scores) #sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = np.mean(f1_scores) #sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print('Mean Accuracy: {:.2f}'.format(mean_accuracy))\n",
    "print('Mean Precision: {:.2f}'.format(mean_precision))\n",
    "print('Mean Recall: {:.2f}'.format(mean_recall))\n",
    "print('Mean F1-Score: {:.2f}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "661a7658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>data balancing technique</th>\n",
       "      <th>fold</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_2</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>f1-score_1</th>\n",
       "      <th>f1-score_2</th>\n",
       "      <th>support_1</th>\n",
       "      <th>support_2</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>DF5</td>\n",
       "      <td>SVC</td>\n",
       "      <td>SMOTEENN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.977907</td>\n",
       "      <td>0.283842</td>\n",
       "      <td>0.595961</td>\n",
       "      <td>0.922441</td>\n",
       "      <td>0.740588</td>\n",
       "      <td>0.434106</td>\n",
       "      <td>9061.0</td>\n",
       "      <td>1573.0</td>\n",
       "      <td>5400</td>\n",
       "      <td>122</td>\n",
       "      <td>1451</td>\n",
       "      <td>3661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>DF5</td>\n",
       "      <td>SVC</td>\n",
       "      <td>SMOTEENN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.977869</td>\n",
       "      <td>0.290400</td>\n",
       "      <td>0.605481</td>\n",
       "      <td>0.921767</td>\n",
       "      <td>0.747884</td>\n",
       "      <td>0.441657</td>\n",
       "      <td>9049.0</td>\n",
       "      <td>1585.0</td>\n",
       "      <td>5479</td>\n",
       "      <td>124</td>\n",
       "      <td>1461</td>\n",
       "      <td>3570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset model data balancing technique  fold  precision_1  precision_2  \\\n",
       "22     DF5   SVC                 SMOTEENN     1     0.977907     0.283842   \n",
       "23     DF5   SVC                 SMOTEENN     2     0.977869     0.290400   \n",
       "\n",
       "    recall_1  recall_2  f1-score_1  f1-score_2  support_1  support_2    TP  \\\n",
       "22  0.595961  0.922441    0.740588    0.434106     9061.0     1573.0  5400   \n",
       "23  0.605481  0.921767    0.747884    0.441657     9049.0     1585.0  5479   \n",
       "\n",
       "     FP    TN    FN  \n",
       "22  122  1451  3661  \n",
       "23  124  1461  3570  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_metrics[(combined_metrics['data balancing technique'] == 'SMOTEENN') & (combined_metrics['dataset'] == 'DF5')].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d61e0f",
   "metadata": {},
   "source": [
    "### SVC with df5 data and imbalance data tackling (SMOTETOMEK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "474f7eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:\n",
      "2\n",
      "Fold:\n",
      "3\n",
      "Fold:\n",
      "4\n",
      "Fold:\n",
      "5\n",
      "Mean Accuracy: 0.76\n",
      "Mean Precision: 0.89\n",
      "Mean Recall: 0.76\n",
      "Mean F1-Score: 0.77\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df5' is your DataFrame with features and the target column\n",
    "# Replace 'features' with the actual list of feature columns\n",
    "features = df5.drop(columns=['target'])  # Drop the target column to get the feature columns\n",
    "target = df5['target']  # Target column to predict\n",
    "\n",
    "# Initialize SVC model\n",
    "model = SVC()\n",
    "\n",
    "# Initialize KFold with 10 folds\n",
    "kf = KFold(n_splits=4, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    # Apply SMOTETomek for combined over and undersampling\n",
    "    SMOTE_Tomek = SMOTETomek(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = SMOTE_Tomek.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Predict on the testing set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    y_pred = np.round(y_pred)\n",
    "    \n",
    "    y_pred[y_pred <= 0] = 1\n",
    "    y_pred[y_pred >= 2] = 2\n",
    "    \n",
    "    # Model evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred.round())\n",
    "    precision = precision_score(y_test, y_pred.round(), average='weighted')\n",
    "    recall = recall_score(y_test, y_pred.round(), average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred.round(), average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred.round())\n",
    "    \n",
    "    # Convert classification report to DataFrame\n",
    "    report_df = pd.DataFrame(classification_report(y_test, y_pred.round(), output_dict=True)).transpose()\n",
    "    # Convert confusion matrix to DataFrame\n",
    "    matrix_df = pd.DataFrame(confusion_matrix(y_test, y_pred.round()))\n",
    "    \n",
    "    # Extract metrics for class 1\n",
    "    metrics_1 = report_df.loc['1', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract metrics for class 2\n",
    "    metrics_2 = report_df.loc['2', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract TP, TN, FP, FN counts from the confusion matrix DataFrame\n",
    "    TP = matrix_df.loc[0, 0]\n",
    "    TN = matrix_df.loc[1, 1]\n",
    "    FP = matrix_df.loc[1, 0]\n",
    "    FN = matrix_df.loc[0, 1]\n",
    "    \n",
    "    new_metric_row = {\n",
    "    'dataset': 'DF5',\n",
    "    'model' : 'SVC',\n",
    "    'data balancing technique' : 'SMOTETomek',\n",
    "    'fold' : i,\n",
    "    'precision_1': metrics_1['precision'],\n",
    "    'precision_2': metrics_2['precision'],\n",
    "    'recall_1': metrics_1['recall'],\n",
    "    'recall_2': metrics_2['recall'],\n",
    "    'f1-score_1': metrics_1['f1-score'],\n",
    "    'f1-score_2': metrics_2['f1-score'],\n",
    "    'support_1': metrics_1['support'],\n",
    "    'support_2': metrics_2['support'],\n",
    "    'TP' : TP,\n",
    "    'FP' : FP,\n",
    "    'TN' : TN,\n",
    "    'FN' : FN\n",
    "    }\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    #combined_metrics = combined_metrics.append(new_metric_row, ignore_index=True)\n",
    "    combined_metrics.loc[len(combined_metrics)] = new_metric_row\n",
    "    \n",
    "    \n",
    "    # Append evaluation metrics to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "    \n",
    "    print(\"Fold:\")\n",
    "    print(i)\n",
    "\n",
    "# Calculate mean evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores) #sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = np.mean(precision_scores) #sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = np.mean(recall_scores) #sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = np.mean(f1_scores) #sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print('Mean Accuracy: {:.2f}'.format(mean_accuracy))\n",
    "print('Mean Precision: {:.2f}'.format(mean_precision))\n",
    "print('Mean Recall: {:.2f}'.format(mean_recall))\n",
    "print('Mean F1-Score: {:.2f}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f6da809c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>data balancing technique</th>\n",
       "      <th>fold</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_2</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>f1-score_1</th>\n",
       "      <th>f1-score_2</th>\n",
       "      <th>support_1</th>\n",
       "      <th>support_2</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>DF5</td>\n",
       "      <td>SVC</td>\n",
       "      <td>SMOTETomek</td>\n",
       "      <td>1</td>\n",
       "      <td>0.973929</td>\n",
       "      <td>0.626796</td>\n",
       "      <td>0.911158</td>\n",
       "      <td>0.859504</td>\n",
       "      <td>0.941498</td>\n",
       "      <td>0.724933</td>\n",
       "      <td>9061.0</td>\n",
       "      <td>1573.0</td>\n",
       "      <td>8256</td>\n",
       "      <td>221</td>\n",
       "      <td>1352</td>\n",
       "      <td>805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>DF5</td>\n",
       "      <td>SVC</td>\n",
       "      <td>SMOTETomek</td>\n",
       "      <td>2</td>\n",
       "      <td>0.976142</td>\n",
       "      <td>0.604448</td>\n",
       "      <td>0.899768</td>\n",
       "      <td>0.874448</td>\n",
       "      <td>0.936400</td>\n",
       "      <td>0.714801</td>\n",
       "      <td>9049.0</td>\n",
       "      <td>1585.0</td>\n",
       "      <td>8142</td>\n",
       "      <td>199</td>\n",
       "      <td>1386</td>\n",
       "      <td>907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset model data balancing technique  fold  precision_1  precision_2  \\\n",
       "26     DF5   SVC               SMOTETomek     1     0.973929     0.626796   \n",
       "27     DF5   SVC               SMOTETomek     2     0.976142     0.604448   \n",
       "\n",
       "    recall_1  recall_2  f1-score_1  f1-score_2  support_1  support_2    TP  \\\n",
       "26  0.911158  0.859504    0.941498    0.724933     9061.0     1573.0  8256   \n",
       "27  0.899768  0.874448    0.936400    0.714801     9049.0     1585.0  8142   \n",
       "\n",
       "     FP    TN   FN  \n",
       "26  221  1352  805  \n",
       "27  199  1386  907  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_metrics[(combined_metrics['data balancing technique'] == 'SMOTETomek') & (combined_metrics['dataset'] == 'DF5')].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c945b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85f183d",
   "metadata": {},
   "source": [
    "## DF5c - SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07b53bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.52\n",
      "Mean Precision: 0.53\n",
      "Mean Recall: 0.52\n",
      "Mean F1-Score: 0.48\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df5' is your DataFrame with features and the target column\n",
    "# Replace 'features' with the actual list of feature columns\n",
    "features = df5c.drop(columns=['target'])  # Drop the target column to get the feature columns\n",
    "target = df5c['target']  # Target column to predict\n",
    "\n",
    "# Initialize SVC model\n",
    "model = SVC()\n",
    "\n",
    "# Initialize KFold with 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the testing set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Model evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred.round())\n",
    "    precision = precision_score(y_test, y_pred.round().round(), average='weighted')\n",
    "    recall = recall_score(y_test, y_pred.round(), average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred.round(), average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred.round())\n",
    "    \n",
    "    # Convert classification report to DataFrame\n",
    "    report_df = pd.DataFrame(classification_report(y_test, y_pred.round(), output_dict=True)).transpose()\n",
    "    # Convert confusion matrix to DataFrame\n",
    "    matrix_df = pd.DataFrame(confusion_matrix(y_test, y_pred.round()))\n",
    "    \n",
    "    # Extract metrics for class 1\n",
    "    metrics_1 = report_df.loc['1', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract metrics for class 2\n",
    "    metrics_2 = report_df.loc['2', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract TP, TN, FP, FN counts from the confusion matrix DataFrame\n",
    "    TP = matrix_df.loc[0, 0]\n",
    "    TN = matrix_df.loc[1, 1]\n",
    "    FP = matrix_df.loc[1, 0]\n",
    "    FN = matrix_df.loc[0, 1]\n",
    "    \n",
    "    new_metric_row = {\n",
    "    'dataset': 'DF5c',\n",
    "    'model' : 'SVC',\n",
    "    'data balancing technique' : 'None',\n",
    "    'fold' : i,\n",
    "    'precision_1': metrics_1['precision'],\n",
    "    'precision_2': metrics_2['precision'],\n",
    "    'recall_1': metrics_1['recall'],\n",
    "    'recall_2': metrics_2['recall'],\n",
    "    'f1-score_1': metrics_1['f1-score'],\n",
    "    'f1-score_2': metrics_2['f1-score'],\n",
    "    'support_1': metrics_1['support'],\n",
    "    'support_2': metrics_2['support'],\n",
    "    'TP' : TP,\n",
    "    'FP' : FP,\n",
    "    'TN' : TN,\n",
    "    'FN' : FN\n",
    "    }\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    #combined_metrics = combined_metrics.append(new_metric_row, ignore_index=True)\n",
    "    combined_metrics.loc[len(combined_metrics)] = new_metric_row\n",
    "    \n",
    "    \n",
    "    # Append evaluation metrics to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "\n",
    "# Calculate mean evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores) #sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = np.mean(precision_scores) #sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = np.mean(recall_scores) #sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = np.mean(f1_scores) #sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print('Mean Accuracy: {:.2f}'.format(mean_accuracy))\n",
    "print('Mean Precision: {:.2f}'.format(mean_precision))\n",
    "print('Mean Recall: {:.2f}'.format(mean_recall))\n",
    "print('Mean F1-Score: {:.2f}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9dbc10dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>data balancing technique</th>\n",
       "      <th>fold</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_2</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>f1-score_1</th>\n",
       "      <th>f1-score_2</th>\n",
       "      <th>support_1</th>\n",
       "      <th>support_2</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>DF5c</td>\n",
       "      <td>SVC</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0.724490</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.840237</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>71.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>71</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>DF5c</td>\n",
       "      <td>SVC</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>0.707071</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.828402</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>70.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>70</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset model data balancing technique  fold  precision_1  precision_2  \\\n",
       "60    DF5c   SVC                     None     1     0.724490          1.0   \n",
       "61    DF5c   SVC                     None     2     0.707071          1.0   \n",
       "\n",
       "    recall_1  recall_2  f1-score_1  f1-score_2  support_1  support_2  TP  FP  \\\n",
       "60       1.0  0.068966    0.840237    0.129032       71.0       29.0  71  27   \n",
       "61       1.0  0.033333    0.828402    0.064516       70.0       30.0  70  29   \n",
       "\n",
       "    TN  FN  \n",
       "60   2   0  \n",
       "61   1   0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_metrics[(combined_metrics['data balancing technique'] == 'None') & (combined_metrics['dataset'] == 'DF5c')].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a96351",
   "metadata": {},
   "source": [
    "### SVC with df5c data and imbalance data tackling (SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cfa40392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.50\n",
      "Mean Precision: 0.53\n",
      "Mean Recall: 0.50\n",
      "Mean F1-Score: 0.47\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df5' is your DataFrame with features and the target column\n",
    "# Replace 'features' with the actual list of feature columns\n",
    "features = df5c.drop(columns=['target'])  # Drop the target column to get the feature columns\n",
    "target = df5c['target']  # Target column to predict\n",
    "\n",
    "# Initialize SVC model\n",
    "model = SVC()\n",
    "\n",
    "# Initialize KFold with 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    # Apply SMOTE to the training data\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Predict on the testing set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Model evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred.round())\n",
    "    precision = precision_score(y_test, y_pred.round(), average='weighted')\n",
    "    recall = recall_score(y_test, y_pred.round(), average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred.round(), average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred.round())\n",
    "    \n",
    "    # Convert classification report to DataFrame\n",
    "    report_df = pd.DataFrame(classification_report(y_test, y_pred.round(), output_dict=True)).transpose()\n",
    "    # Convert confusion matrix to DataFrame\n",
    "    matrix_df = pd.DataFrame(confusion_matrix(y_test, y_pred.round()))\n",
    "    \n",
    "    # Extract metrics for class 1\n",
    "    metrics_1 = report_df.loc['1', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract metrics for class 2\n",
    "    metrics_2 = report_df.loc['2', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract TP, TN, FP, FN counts from the confusion matrix DataFrame\n",
    "    TP = matrix_df.loc[0, 0]\n",
    "    TN = matrix_df.loc[1, 1]\n",
    "    FP = matrix_df.loc[1, 0]\n",
    "    FN = matrix_df.loc[0, 1]\n",
    "    \n",
    "    new_metric_row = {\n",
    "    'dataset': 'DF5c',\n",
    "    'model' : 'SVC',\n",
    "    'data balancing technique' : 'SMOTE',\n",
    "    'fold' : i,\n",
    "    'precision_1': metrics_1['precision'],\n",
    "    'precision_2': metrics_2['precision'],\n",
    "    'recall_1': metrics_1['recall'],\n",
    "    'recall_2': metrics_2['recall'],\n",
    "    'f1-score_1': metrics_1['f1-score'],\n",
    "    'f1-score_2': metrics_2['f1-score'],\n",
    "    'support_1': metrics_1['support'],\n",
    "    'support_2': metrics_2['support'],\n",
    "    'TP' : TP,\n",
    "    'FP' : FP,\n",
    "    'TN' : TN,\n",
    "    'FN' : FN\n",
    "    }\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    #combined_metrics = combined_metrics.append(new_metric_row, ignore_index=True)\n",
    "    combined_metrics.loc[len(combined_metrics)] = new_metric_row\n",
    "    \n",
    "    \n",
    "    # Append evaluation metrics to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "\n",
    "# Calculate mean evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores) #sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = np.mean(precision_scores) #sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = np.mean(recall_scores) #sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = np.mean(f1_scores) #sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print('Mean Accuracy: {:.2f}'.format(mean_accuracy))\n",
    "print('Mean Precision: {:.2f}'.format(mean_precision))\n",
    "print('Mean Recall: {:.2f}'.format(mean_recall))\n",
    "print('Mean F1-Score: {:.2f}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "53d1a9ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>data balancing technique</th>\n",
       "      <th>fold</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_2</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>f1-score_1</th>\n",
       "      <th>f1-score_2</th>\n",
       "      <th>support_1</th>\n",
       "      <th>support_2</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>DF5c</td>\n",
       "      <td>SVC</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>1</td>\n",
       "      <td>0.760870</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.492958</td>\n",
       "      <td>0.62069</td>\n",
       "      <td>0.598291</td>\n",
       "      <td>0.433735</td>\n",
       "      <td>71.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>35</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>DF5c</td>\n",
       "      <td>SVC</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>2</td>\n",
       "      <td>0.707317</td>\n",
       "      <td>0.305085</td>\n",
       "      <td>0.414286</td>\n",
       "      <td>0.60000</td>\n",
       "      <td>0.522523</td>\n",
       "      <td>0.404494</td>\n",
       "      <td>70.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>29</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset model data balancing technique  fold  precision_1  precision_2  \\\n",
       "70    DF5c   SVC                    SMOTE     1     0.760870     0.333333   \n",
       "71    DF5c   SVC                    SMOTE     2     0.707317     0.305085   \n",
       "\n",
       "    recall_1  recall_2  f1-score_1  f1-score_2  support_1  support_2  TP  FP  \\\n",
       "70  0.492958   0.62069    0.598291    0.433735       71.0       29.0  35  11   \n",
       "71  0.414286   0.60000    0.522523    0.404494       70.0       30.0  29  12   \n",
       "\n",
       "    TN  FN  \n",
       "70  18  36  \n",
       "71  18  41  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_metrics[(combined_metrics['data balancing technique'] == 'SMOTE') & (combined_metrics['dataset'] == 'DF5c')].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fab885",
   "metadata": {},
   "source": [
    "### SVC with df5c data and imbalance data tackling (Random Under Sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3d9f5e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.51\n",
      "Mean Precision: 0.53\n",
      "Mean Recall: 0.51\n",
      "Mean F1-Score: 0.48\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df5' is your DataFrame with features and the target column\n",
    "# Replace 'features' with the actual list of feature columns\n",
    "features = df5c.drop(columns=['target'])  # Drop the target column to get the feature columns\n",
    "target = df5c['target']  # Target column to predict\n",
    "\n",
    "# Initialize SVC model\n",
    "model = SVC()\n",
    "\n",
    "# Initialize KFold with 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    # Apply RUS to the training data\n",
    "    rus = RandomUnderSampler(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Predict on the testing set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Model evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred.round())\n",
    "    precision = precision_score(y_test, y_pred.round(), average='weighted')\n",
    "    recall = recall_score(y_test, y_pred.round(), average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred.round(), average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred.round())\n",
    "    \n",
    "    # Convert classification report to DataFrame\n",
    "    report_df = pd.DataFrame(classification_report(y_test, y_pred.round(), output_dict=True)).transpose()\n",
    "    # Convert confusion matrix to DataFrame\n",
    "    matrix_df = pd.DataFrame(confusion_matrix(y_test, y_pred.round()))\n",
    "    \n",
    "    # Extract metrics for class 1\n",
    "    metrics_1 = report_df.loc['1', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract metrics for class 2\n",
    "    metrics_2 = report_df.loc['2', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract TP, TN, FP, FN counts from the confusion matrix DataFrame\n",
    "    TP = matrix_df.loc[0, 0]\n",
    "    TN = matrix_df.loc[1, 1]\n",
    "    FP = matrix_df.loc[1, 0]\n",
    "    FN = matrix_df.loc[0, 1]\n",
    "    \n",
    "    new_metric_row = {\n",
    "    'dataset': 'DF5c',\n",
    "    'model' : 'SVC',\n",
    "    'data balancing technique' : 'Random Under Sampler',\n",
    "    'fold' : i,\n",
    "    'precision_1': metrics_1['precision'],\n",
    "    'precision_2': metrics_2['precision'],\n",
    "    'recall_1': metrics_1['recall'],\n",
    "    'recall_2': metrics_2['recall'],\n",
    "    'f1-score_1': metrics_1['f1-score'],\n",
    "    'f1-score_2': metrics_2['f1-score'],\n",
    "    'support_1': metrics_1['support'],\n",
    "    'support_2': metrics_2['support'],\n",
    "    'TP' : TP,\n",
    "    'FP' : FP,\n",
    "    'TN' : TN,\n",
    "    'FN' : FN\n",
    "    }\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    #combined_metrics = combined_metrics.append(new_metric_row, ignore_index=True)\n",
    "    combined_metrics.loc[len(combined_metrics)] = new_metric_row\n",
    "    \n",
    "    \n",
    "    # Append evaluation metrics to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "\n",
    "# Calculate mean evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores) #sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = np.mean(precision_scores) #sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = np.mean(recall_scores) #sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = np.mean(f1_scores) #sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print('Mean Accuracy: {:.2f}'.format(mean_accuracy))\n",
    "print('Mean Precision: {:.2f}'.format(mean_precision))\n",
    "print('Mean Recall: {:.2f}'.format(mean_recall))\n",
    "print('Mean F1-Score: {:.2f}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2d1bb284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>data balancing technique</th>\n",
       "      <th>fold</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_2</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>f1-score_1</th>\n",
       "      <th>f1-score_2</th>\n",
       "      <th>support_1</th>\n",
       "      <th>support_2</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>DF5c</td>\n",
       "      <td>SVC</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>1</td>\n",
       "      <td>0.717391</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.464789</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.564103</td>\n",
       "      <td>0.385542</td>\n",
       "      <td>71.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>33</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>DF5c</td>\n",
       "      <td>SVC</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>2</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>0.303571</td>\n",
       "      <td>0.442857</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.543860</td>\n",
       "      <td>0.395349</td>\n",
       "      <td>70.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>31</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset model data balancing technique  fold  precision_1  precision_2  \\\n",
       "80    DF5c   SVC     Random Under Sampler     1     0.717391     0.296296   \n",
       "81    DF5c   SVC     Random Under Sampler     2     0.704545     0.303571   \n",
       "\n",
       "    recall_1  recall_2  f1-score_1  f1-score_2  support_1  support_2  TP  FP  \\\n",
       "80  0.464789  0.551724    0.564103    0.385542       71.0       29.0  33  13   \n",
       "81  0.442857  0.566667    0.543860    0.395349       70.0       30.0  31  13   \n",
       "\n",
       "    TN  FN  \n",
       "80  16  38  \n",
       "81  17  39  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_metrics[(combined_metrics['data balancing technique'] == 'Random Under Sampler') & (combined_metrics['dataset'] == 'DF5c')].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596f2d9a",
   "metadata": {},
   "source": [
    "### SVC with df5c data and imbalance data tackling (Random Over Sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "deeacc22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.52\n",
      "Mean Precision: 0.54\n",
      "Mean Recall: 0.52\n",
      "Mean F1-Score: 0.49\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df5' is your DataFrame with features and the target column\n",
    "# Replace 'features' with the actual list of feature columns\n",
    "features = df5c.drop(columns=['target'])  # Drop the target column to get the feature columns\n",
    "target = df5c['target']  # Target column to predict\n",
    "\n",
    "# Initialize SVC model\n",
    "model = SVC()\n",
    "\n",
    "# Initialize KFold with 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    # Apply ROS to the training data\n",
    "    ros = RandomOverSampler(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Predict on the testing set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Model evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred.round())\n",
    "    precision = precision_score(y_test, y_pred.round(), average='weighted')\n",
    "    recall = recall_score(y_test, y_pred.round(), average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred.round(), average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred.round())\n",
    "    \n",
    "    # Convert classification report to DataFrame\n",
    "    report_df = pd.DataFrame(classification_report(y_test, y_pred.round(), output_dict=True)).transpose()\n",
    "    # Convert confusion matrix to DataFrame\n",
    "    matrix_df = pd.DataFrame(confusion_matrix(y_test, y_pred.round()))\n",
    "    \n",
    "    # Extract metrics for class 1\n",
    "    metrics_1 = report_df.loc['1', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract metrics for class 2\n",
    "    metrics_2 = report_df.loc['2', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract TP, TN, FP, FN counts from the confusion matrix DataFrame\n",
    "    TP = matrix_df.loc[0, 0]\n",
    "    TN = matrix_df.loc[1, 1]\n",
    "    FP = matrix_df.loc[1, 0]\n",
    "    FN = matrix_df.loc[0, 1]\n",
    "    \n",
    "    new_metric_row = {\n",
    "    'dataset': 'DF5c',\n",
    "    'model' : 'SVC',\n",
    "    'data balancing technique' : 'Random Over Sampler',\n",
    "    'fold' : i,\n",
    "    'precision_1': metrics_1['precision'],\n",
    "    'precision_2': metrics_2['precision'],\n",
    "    'recall_1': metrics_1['recall'],\n",
    "    'recall_2': metrics_2['recall'],\n",
    "    'f1-score_1': metrics_1['f1-score'],\n",
    "    'f1-score_2': metrics_2['f1-score'],\n",
    "    'support_1': metrics_1['support'],\n",
    "    'support_2': metrics_2['support'],\n",
    "    'TP' : TP,\n",
    "    'FP' : FP,\n",
    "    'TN' : TN,\n",
    "    'FN' : FN\n",
    "    }\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    #combined_metrics = combined_metrics.append(new_metric_row, ignore_index=True)\n",
    "    combined_metrics.loc[len(combined_metrics)] = new_metric_row\n",
    "    \n",
    "    \n",
    "    # Append evaluation metrics to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "\n",
    "# Calculate mean evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores) #sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = np.mean(precision_scores) #sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = np.mean(recall_scores) #sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = np.mean(f1_scores) #sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print('Mean Accuracy: {:.2f}'.format(mean_accuracy))\n",
    "print('Mean Precision: {:.2f}'.format(mean_precision))\n",
    "print('Mean Recall: {:.2f}'.format(mean_recall))\n",
    "print('Mean F1-Score: {:.2f}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b3c845f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>data balancing technique</th>\n",
       "      <th>fold</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_2</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>f1-score_1</th>\n",
       "      <th>f1-score_2</th>\n",
       "      <th>support_1</th>\n",
       "      <th>support_2</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>DF5c</td>\n",
       "      <td>SVC</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>1</td>\n",
       "      <td>0.744186</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.450704</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.561404</td>\n",
       "      <td>0.418605</td>\n",
       "      <td>71.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>32</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>DF5c</td>\n",
       "      <td>SVC</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>2</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>0.303571</td>\n",
       "      <td>0.442857</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.543860</td>\n",
       "      <td>0.395349</td>\n",
       "      <td>70.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>31</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset model data balancing technique  fold  precision_1  precision_2  \\\n",
       "90    DF5c   SVC      Random Over Sampler     1     0.744186     0.315789   \n",
       "91    DF5c   SVC      Random Over Sampler     2     0.704545     0.303571   \n",
       "\n",
       "    recall_1  recall_2  f1-score_1  f1-score_2  support_1  support_2  TP  FP  \\\n",
       "90  0.450704  0.620690    0.561404    0.418605       71.0       29.0  32  11   \n",
       "91  0.442857  0.566667    0.543860    0.395349       70.0       30.0  31  13   \n",
       "\n",
       "    TN  FN  \n",
       "90  18  39  \n",
       "91  17  39  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_metrics[(combined_metrics['data balancing technique'] == 'Random Over Sampler') & (combined_metrics['dataset'] == 'DF5c')].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d688e2",
   "metadata": {},
   "source": [
    "### SVC with df5c data and imbalance data tackling (SMOTEENN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c044fc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.52\n",
      "Mean Precision: 0.54\n",
      "Mean Recall: 0.52\n",
      "Mean F1-Score: 0.49\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df5' is your DataFrame with features and the target column\n",
    "# Replace 'features' with the actual list of feature columns\n",
    "features = df5c.drop(columns=['target'])  # Drop the target column to get the feature columns\n",
    "target = df5c['target']  # Target column to predict\n",
    "\n",
    "# Initialize SVC model\n",
    "model = SVC()\n",
    "\n",
    "# Initialize KFold with 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    # Apply SMOTEENN to the training data\n",
    "    SMOTEEnn = SMOTEENN(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = SMOTEEnn.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Predict on the testing set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Model evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred.round())\n",
    "    precision = precision_score(y_test, y_pred.round(), average='weighted')\n",
    "    recall = recall_score(y_test, y_pred.round(), average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred.round(), average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred.round())\n",
    "    \n",
    "    # Convert classification report to DataFrame\n",
    "    report_df = pd.DataFrame(classification_report(y_test, y_pred.round(), output_dict=True)).transpose()\n",
    "    # Convert confusion matrix to DataFrame\n",
    "    matrix_df = pd.DataFrame(confusion_matrix(y_test, y_pred.round()))\n",
    "    \n",
    "    # Extract metrics for class 1\n",
    "    metrics_1 = report_df.loc['1', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract metrics for class 2\n",
    "    metrics_2 = report_df.loc['2', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract TP, TN, FP, FN counts from the confusion matrix DataFrame\n",
    "    TP = matrix_df.loc[0, 0]\n",
    "    TN = matrix_df.loc[1, 1]\n",
    "    FP = matrix_df.loc[1, 0]\n",
    "    FN = matrix_df.loc[0, 1]\n",
    "    \n",
    "    new_metric_row = {\n",
    "    'dataset': 'DF5c',\n",
    "    'model' : 'SVC',\n",
    "    'data balancing technique' : 'SMOTEENN',\n",
    "    'fold' : i,\n",
    "    'precision_1': metrics_1['precision'],\n",
    "    'precision_2': metrics_2['precision'],\n",
    "    'recall_1': metrics_1['recall'],\n",
    "    'recall_2': metrics_2['recall'],\n",
    "    'f1-score_1': metrics_1['f1-score'],\n",
    "    'f1-score_2': metrics_2['f1-score'],\n",
    "    'support_1': metrics_1['support'],\n",
    "    'support_2': metrics_2['support'],\n",
    "    'TP' : TP,\n",
    "    'FP' : FP,\n",
    "    'TN' : TN,\n",
    "    'FN' : FN\n",
    "    }\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    #combined_metrics = combined_metrics.append(new_metric_row, ignore_index=True)\n",
    "    combined_metrics.loc[len(combined_metrics)] = new_metric_row\n",
    "    \n",
    "    \n",
    "    # Append evaluation metrics to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "\n",
    "# Calculate mean evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores) #sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = np.mean(precision_scores) #sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = np.mean(recall_scores) #sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = np.mean(f1_scores) #sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print('Mean Accuracy: {:.2f}'.format(mean_accuracy))\n",
    "print('Mean Precision: {:.2f}'.format(mean_precision))\n",
    "print('Mean Recall: {:.2f}'.format(mean_recall))\n",
    "print('Mean F1-Score: {:.2f}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "81297c53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>data balancing technique</th>\n",
       "      <th>fold</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_2</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>f1-score_1</th>\n",
       "      <th>f1-score_2</th>\n",
       "      <th>support_1</th>\n",
       "      <th>support_2</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>DF5c</td>\n",
       "      <td>SVC</td>\n",
       "      <td>SMOTEENN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.449612</td>\n",
       "      <td>71.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>DF5c</td>\n",
       "      <td>SVC</td>\n",
       "      <td>SMOTEENN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>70.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dataset model data balancing technique  fold  precision_1  precision_2  \\\n",
       "100    DF5c   SVC                 SMOTEENN     1          0.0         0.29   \n",
       "101    DF5c   SVC                 SMOTEENN     2          0.0         0.30   \n",
       "\n",
       "     recall_1  recall_2  f1-score_1  f1-score_2  support_1  support_2  TP  FP  \\\n",
       "100       0.0       1.0         0.0    0.449612       71.0       29.0   0   0   \n",
       "101       0.0       1.0         0.0    0.461538       70.0       30.0   0   0   \n",
       "\n",
       "     TN  FN  \n",
       "100  29  71  \n",
       "101  30  70  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_metrics[(combined_metrics['data balancing technique'] == 'SMOTEENN') & (combined_metrics['dataset'] == 'DF5c')].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d72534",
   "metadata": {},
   "source": [
    "### SVC with df5c data and imbalance data tackling (SMOTETomek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2300ee90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.53\n",
      "Mean Precision: 0.55\n",
      "Mean Recall: 0.53\n",
      "Mean F1-Score: 0.50\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df5' is your DataFrame with features and the target column\n",
    "# Replace 'features' with the actual list of feature columns\n",
    "features = df5c.drop(columns=['target'])  # Drop the target column to get the feature columns\n",
    "target = df5c['target']  # Target column to predict\n",
    "\n",
    "# Initialize SVC model\n",
    "model = SVC()\n",
    "\n",
    "# Initialize KFold with 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    # Apply SMOTEENN to the training data\n",
    "    SMOTETOMEK = SMOTETomek(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = SMOTETOMEK.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Predict on the testing set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Model evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred.round())\n",
    "    precision = precision_score(y_test, y_pred.round(), average='weighted')\n",
    "    recall = recall_score(y_test, y_pred.round(), average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred.round(), average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred.round())\n",
    "    \n",
    "    # Convert classification report to DataFrame\n",
    "    report_df = pd.DataFrame(classification_report(y_test, y_pred.round(), output_dict=True)).transpose()\n",
    "    # Convert confusion matrix to DataFrame\n",
    "    matrix_df = pd.DataFrame(confusion_matrix(y_test, y_pred.round()))\n",
    "    \n",
    "    # Extract metrics for class 1\n",
    "    metrics_1 = report_df.loc['1', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract metrics for class 2\n",
    "    metrics_2 = report_df.loc['2', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract TP, TN, FP, FN counts from the confusion matrix DataFrame\n",
    "    TP = matrix_df.loc[0, 0]\n",
    "    TN = matrix_df.loc[1, 1]\n",
    "    FP = matrix_df.loc[1, 0]\n",
    "    FN = matrix_df.loc[0, 1]\n",
    "    \n",
    "    new_metric_row = {\n",
    "    'dataset': 'DF5c',\n",
    "    'model' : 'SVC',\n",
    "    'data balancing technique' : 'SMOTETomek',\n",
    "    'fold' : i,\n",
    "    'precision_1': metrics_1['precision'],\n",
    "    'precision_2': metrics_2['precision'],\n",
    "    'recall_1': metrics_1['recall'],\n",
    "    'recall_2': metrics_2['recall'],\n",
    "    'f1-score_1': metrics_1['f1-score'],\n",
    "    'f1-score_2': metrics_2['f1-score'],\n",
    "    'support_1': metrics_1['support'],\n",
    "    'support_2': metrics_2['support'],\n",
    "    'TP' : TP,\n",
    "    'FP' : FP,\n",
    "    'TN' : TN,\n",
    "    'FN' : FN\n",
    "    }\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    #combined_metrics = combined_metrics.append(new_metric_row, ignore_index=True)\n",
    "    combined_metrics.loc[len(combined_metrics)] = new_metric_row\n",
    "    \n",
    "    \n",
    "    # Append evaluation metrics to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "\n",
    "# Calculate mean evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores) #sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = np.mean(precision_scores) #sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = np.mean(recall_scores) #sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = np.mean(f1_scores) #sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print('Mean Accuracy: {:.2f}'.format(mean_accuracy))\n",
    "print('Mean Precision: {:.2f}'.format(mean_precision))\n",
    "print('Mean Recall: {:.2f}'.format(mean_recall))\n",
    "print('Mean F1-Score: {:.2f}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cc6d42eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>data balancing technique</th>\n",
       "      <th>fold</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_2</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>f1-score_1</th>\n",
       "      <th>f1-score_2</th>\n",
       "      <th>support_1</th>\n",
       "      <th>support_2</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>DF5c</td>\n",
       "      <td>SVC</td>\n",
       "      <td>SMOTETomek</td>\n",
       "      <td>1</td>\n",
       "      <td>0.760870</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.492958</td>\n",
       "      <td>0.62069</td>\n",
       "      <td>0.598291</td>\n",
       "      <td>0.433735</td>\n",
       "      <td>71.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>35</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>DF5c</td>\n",
       "      <td>SVC</td>\n",
       "      <td>SMOTETomek</td>\n",
       "      <td>2</td>\n",
       "      <td>0.707317</td>\n",
       "      <td>0.305085</td>\n",
       "      <td>0.414286</td>\n",
       "      <td>0.60000</td>\n",
       "      <td>0.522523</td>\n",
       "      <td>0.404494</td>\n",
       "      <td>70.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>29</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dataset model data balancing technique  fold  precision_1  precision_2  \\\n",
       "110    DF5c   SVC               SMOTETomek     1     0.760870     0.333333   \n",
       "111    DF5c   SVC               SMOTETomek     2     0.707317     0.305085   \n",
       "\n",
       "     recall_1  recall_2  f1-score_1  f1-score_2  support_1  support_2  TP  FP  \\\n",
       "110  0.492958   0.62069    0.598291    0.433735       71.0       29.0  35  11   \n",
       "111  0.414286   0.60000    0.522523    0.404494       70.0       30.0  29  12   \n",
       "\n",
       "     TN  FN  \n",
       "110  18  36  \n",
       "111  18  41  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_metrics[(combined_metrics['data balancing technique'] == 'SMOTETomek') & (combined_metrics['dataset'] == 'DF5c')].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd948ec1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc4b04f0",
   "metadata": {},
   "source": [
    "## Performance metrics for the SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1158fa25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>data balancing technique</th>\n",
       "      <th>fold</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_2</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>f1-score_1</th>\n",
       "      <th>f1-score_2</th>\n",
       "      <th>support_1</th>\n",
       "      <th>support_2</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DF5</td>\n",
       "      <td>SVC</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0.853199</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013300</td>\n",
       "      <td>0.920785</td>\n",
       "      <td>0.026250</td>\n",
       "      <td>18110.0</td>\n",
       "      <td>3158.0</td>\n",
       "      <td>18110</td>\n",
       "      <td>3116</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DF5</td>\n",
       "      <td>SVC</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>0.847168</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.008552</td>\n",
       "      <td>0.917261</td>\n",
       "      <td>0.016959</td>\n",
       "      <td>17993.0</td>\n",
       "      <td>3274.0</td>\n",
       "      <td>17993</td>\n",
       "      <td>3246</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DF5</td>\n",
       "      <td>SVC</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0.865849</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.085969</td>\n",
       "      <td>0.928102</td>\n",
       "      <td>0.158327</td>\n",
       "      <td>7274.0</td>\n",
       "      <td>1233.0</td>\n",
       "      <td>7274</td>\n",
       "      <td>1127</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DF5</td>\n",
       "      <td>SVC</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>0.858161</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069369</td>\n",
       "      <td>0.923667</td>\n",
       "      <td>0.129738</td>\n",
       "      <td>7224.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>7224</td>\n",
       "      <td>1194</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DF5</td>\n",
       "      <td>SVC</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>0.858688</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.072543</td>\n",
       "      <td>0.923972</td>\n",
       "      <td>0.135273</td>\n",
       "      <td>7225.0</td>\n",
       "      <td>1282.0</td>\n",
       "      <td>7225</td>\n",
       "      <td>1189</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DF5</td>\n",
       "      <td>SVC</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>0.854405</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.080451</td>\n",
       "      <td>0.921487</td>\n",
       "      <td>0.148921</td>\n",
       "      <td>7177.0</td>\n",
       "      <td>1330.0</td>\n",
       "      <td>7177</td>\n",
       "      <td>1223</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DF5</td>\n",
       "      <td>SVC</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>0.859034</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.093558</td>\n",
       "      <td>0.924172</td>\n",
       "      <td>0.171108</td>\n",
       "      <td>7203.0</td>\n",
       "      <td>1304.0</td>\n",
       "      <td>7203</td>\n",
       "      <td>1182</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DF5</td>\n",
       "      <td>SVC</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>1</td>\n",
       "      <td>0.974475</td>\n",
       "      <td>0.640824</td>\n",
       "      <td>0.918477</td>\n",
       "      <td>0.858070</td>\n",
       "      <td>0.945648</td>\n",
       "      <td>0.733703</td>\n",
       "      <td>7274.0</td>\n",
       "      <td>1233.0</td>\n",
       "      <td>6681</td>\n",
       "      <td>175</td>\n",
       "      <td>1058</td>\n",
       "      <td>593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DF5</td>\n",
       "      <td>SVC</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>2</td>\n",
       "      <td>0.969016</td>\n",
       "      <td>0.723997</td>\n",
       "      <td>0.943798</td>\n",
       "      <td>0.830086</td>\n",
       "      <td>0.956241</td>\n",
       "      <td>0.773420</td>\n",
       "      <td>7224.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>6818</td>\n",
       "      <td>218</td>\n",
       "      <td>1065</td>\n",
       "      <td>406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DF5</td>\n",
       "      <td>SVC</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>3</td>\n",
       "      <td>0.976091</td>\n",
       "      <td>0.618182</td>\n",
       "      <td>0.904083</td>\n",
       "      <td>0.875195</td>\n",
       "      <td>0.938708</td>\n",
       "      <td>0.724572</td>\n",
       "      <td>7225.0</td>\n",
       "      <td>1282.0</td>\n",
       "      <td>6532</td>\n",
       "      <td>160</td>\n",
       "      <td>1122</td>\n",
       "      <td>693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DF5</td>\n",
       "      <td>SVC</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>1</td>\n",
       "      <td>0.966309</td>\n",
       "      <td>0.237473</td>\n",
       "      <td>0.519627</td>\n",
       "      <td>0.891980</td>\n",
       "      <td>0.675830</td>\n",
       "      <td>0.375086</td>\n",
       "      <td>3643.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>1893</td>\n",
       "      <td>66</td>\n",
       "      <td>545</td>\n",
       "      <td>1750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DF5</td>\n",
       "      <td>SVC</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>2</td>\n",
       "      <td>0.970807</td>\n",
       "      <td>0.252127</td>\n",
       "      <td>0.540198</td>\n",
       "      <td>0.905145</td>\n",
       "      <td>0.694145</td>\n",
       "      <td>0.394396</td>\n",
       "      <td>3632.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>1962</td>\n",
       "      <td>59</td>\n",
       "      <td>563</td>\n",
       "      <td>1670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DF5</td>\n",
       "      <td>SVC</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>3</td>\n",
       "      <td>0.967871</td>\n",
       "      <td>0.254642</td>\n",
       "      <td>0.533481</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.687834</td>\n",
       "      <td>0.396968</td>\n",
       "      <td>3614.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>1928</td>\n",
       "      <td>64</td>\n",
       "      <td>576</td>\n",
       "      <td>1686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DF5</td>\n",
       "      <td>SVC</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>4</td>\n",
       "      <td>0.969439</td>\n",
       "      <td>0.258193</td>\n",
       "      <td>0.536011</td>\n",
       "      <td>0.905280</td>\n",
       "      <td>0.690332</td>\n",
       "      <td>0.401792</td>\n",
       "      <td>3610.0</td>\n",
       "      <td>644.0</td>\n",
       "      <td>1935</td>\n",
       "      <td>61</td>\n",
       "      <td>583</td>\n",
       "      <td>1675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DF5</td>\n",
       "      <td>SVC</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>5</td>\n",
       "      <td>0.968540</td>\n",
       "      <td>0.250540</td>\n",
       "      <td>0.519790</td>\n",
       "      <td>0.904836</td>\n",
       "      <td>0.676513</td>\n",
       "      <td>0.392422</td>\n",
       "      <td>3613.0</td>\n",
       "      <td>641.0</td>\n",
       "      <td>1878</td>\n",
       "      <td>61</td>\n",
       "      <td>580</td>\n",
       "      <td>1735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>DF5</td>\n",
       "      <td>SVC</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>6</td>\n",
       "      <td>0.968610</td>\n",
       "      <td>0.256901</td>\n",
       "      <td>0.538057</td>\n",
       "      <td>0.901563</td>\n",
       "      <td>0.691815</td>\n",
       "      <td>0.399861</td>\n",
       "      <td>3613.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>1944</td>\n",
       "      <td>63</td>\n",
       "      <td>577</td>\n",
       "      <td>1669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DF5</td>\n",
       "      <td>SVC</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>7</td>\n",
       "      <td>0.971373</td>\n",
       "      <td>0.274179</td>\n",
       "      <td>0.557195</td>\n",
       "      <td>0.910606</td>\n",
       "      <td>0.708171</td>\n",
       "      <td>0.421459</td>\n",
       "      <td>3593.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>2002</td>\n",
       "      <td>59</td>\n",
       "      <td>601</td>\n",
       "      <td>1591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DF5</td>\n",
       "      <td>SVC</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>8</td>\n",
       "      <td>0.967136</td>\n",
       "      <td>0.282619</td>\n",
       "      <td>0.574937</td>\n",
       "      <td>0.895522</td>\n",
       "      <td>0.721162</td>\n",
       "      <td>0.429646</td>\n",
       "      <td>3583.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>2060</td>\n",
       "      <td>70</td>\n",
       "      <td>600</td>\n",
       "      <td>1523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>DF5</td>\n",
       "      <td>SVC</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>9</td>\n",
       "      <td>0.966837</td>\n",
       "      <td>0.260358</td>\n",
       "      <td>0.527708</td>\n",
       "      <td>0.901813</td>\n",
       "      <td>0.682760</td>\n",
       "      <td>0.404061</td>\n",
       "      <td>3591.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>1895</td>\n",
       "      <td>65</td>\n",
       "      <td>597</td>\n",
       "      <td>1696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DF5</td>\n",
       "      <td>SVC</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>10</td>\n",
       "      <td>0.970784</td>\n",
       "      <td>0.254127</td>\n",
       "      <td>0.524508</td>\n",
       "      <td>0.911215</td>\n",
       "      <td>0.681050</td>\n",
       "      <td>0.397418</td>\n",
       "      <td>3611.0</td>\n",
       "      <td>642.0</td>\n",
       "      <td>1894</td>\n",
       "      <td>57</td>\n",
       "      <td>585</td>\n",
       "      <td>1717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>DF5</td>\n",
       "      <td>SVC</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>1</td>\n",
       "      <td>0.967532</td>\n",
       "      <td>0.696629</td>\n",
       "      <td>0.940708</td>\n",
       "      <td>0.811784</td>\n",
       "      <td>0.953932</td>\n",
       "      <td>0.749811</td>\n",
       "      <td>3643.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>3427</td>\n",
       "      <td>115</td>\n",
       "      <td>496</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>DF5</td>\n",
       "      <td>SVC</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>2</td>\n",
       "      <td>0.974709</td>\n",
       "      <td>0.725170</td>\n",
       "      <td>0.944383</td>\n",
       "      <td>0.856913</td>\n",
       "      <td>0.959306</td>\n",
       "      <td>0.785556</td>\n",
       "      <td>3632.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>3430</td>\n",
       "      <td>89</td>\n",
       "      <td>533</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>DF5</td>\n",
       "      <td>SVC</td>\n",
       "      <td>SMOTEENN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.977907</td>\n",
       "      <td>0.283842</td>\n",
       "      <td>0.595961</td>\n",
       "      <td>0.922441</td>\n",
       "      <td>0.740588</td>\n",
       "      <td>0.434106</td>\n",
       "      <td>9061.0</td>\n",
       "      <td>1573.0</td>\n",
       "      <td>5400</td>\n",
       "      <td>122</td>\n",
       "      <td>1451</td>\n",
       "      <td>3661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>DF5</td>\n",
       "      <td>SVC</td>\n",
       "      <td>SMOTEENN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.977869</td>\n",
       "      <td>0.290400</td>\n",
       "      <td>0.605481</td>\n",
       "      <td>0.921767</td>\n",
       "      <td>0.747884</td>\n",
       "      <td>0.441657</td>\n",
       "      <td>9049.0</td>\n",
       "      <td>1585.0</td>\n",
       "      <td>5479</td>\n",
       "      <td>124</td>\n",
       "      <td>1461</td>\n",
       "      <td>3570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>DF5</td>\n",
       "      <td>SVC</td>\n",
       "      <td>SMOTEENN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.981907</td>\n",
       "      <td>0.299197</td>\n",
       "      <td>0.602598</td>\n",
       "      <td>0.938575</td>\n",
       "      <td>0.746852</td>\n",
       "      <td>0.453749</td>\n",
       "      <td>9006.0</td>\n",
       "      <td>1628.0</td>\n",
       "      <td>5427</td>\n",
       "      <td>100</td>\n",
       "      <td>1528</td>\n",
       "      <td>3579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>DF5</td>\n",
       "      <td>SVC</td>\n",
       "      <td>SMOTEENN</td>\n",
       "      <td>4</td>\n",
       "      <td>0.978312</td>\n",
       "      <td>0.299216</td>\n",
       "      <td>0.602314</td>\n",
       "      <td>0.927096</td>\n",
       "      <td>0.745592</td>\n",
       "      <td>0.452416</td>\n",
       "      <td>8987.0</td>\n",
       "      <td>1646.0</td>\n",
       "      <td>5413</td>\n",
       "      <td>120</td>\n",
       "      <td>1526</td>\n",
       "      <td>3574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>DF5</td>\n",
       "      <td>SVC</td>\n",
       "      <td>SMOTETomek</td>\n",
       "      <td>1</td>\n",
       "      <td>0.973929</td>\n",
       "      <td>0.626796</td>\n",
       "      <td>0.911158</td>\n",
       "      <td>0.859504</td>\n",
       "      <td>0.941498</td>\n",
       "      <td>0.724933</td>\n",
       "      <td>9061.0</td>\n",
       "      <td>1573.0</td>\n",
       "      <td>8256</td>\n",
       "      <td>221</td>\n",
       "      <td>1352</td>\n",
       "      <td>805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>DF5</td>\n",
       "      <td>SVC</td>\n",
       "      <td>SMOTETomek</td>\n",
       "      <td>2</td>\n",
       "      <td>0.976142</td>\n",
       "      <td>0.604448</td>\n",
       "      <td>0.899768</td>\n",
       "      <td>0.874448</td>\n",
       "      <td>0.936400</td>\n",
       "      <td>0.714801</td>\n",
       "      <td>9049.0</td>\n",
       "      <td>1585.0</td>\n",
       "      <td>8142</td>\n",
       "      <td>199</td>\n",
       "      <td>1386</td>\n",
       "      <td>907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>DF5</td>\n",
       "      <td>SVC</td>\n",
       "      <td>SMOTETomek</td>\n",
       "      <td>3</td>\n",
       "      <td>0.974310</td>\n",
       "      <td>0.623841</td>\n",
       "      <td>0.905396</td>\n",
       "      <td>0.867936</td>\n",
       "      <td>0.938590</td>\n",
       "      <td>0.725918</td>\n",
       "      <td>9006.0</td>\n",
       "      <td>1628.0</td>\n",
       "      <td>8154</td>\n",
       "      <td>215</td>\n",
       "      <td>1413</td>\n",
       "      <td>852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>DF5</td>\n",
       "      <td>SVC</td>\n",
       "      <td>SMOTETomek</td>\n",
       "      <td>4</td>\n",
       "      <td>0.974654</td>\n",
       "      <td>0.583536</td>\n",
       "      <td>0.885724</td>\n",
       "      <td>0.874241</td>\n",
       "      <td>0.928063</td>\n",
       "      <td>0.699903</td>\n",
       "      <td>8987.0</td>\n",
       "      <td>1646.0</td>\n",
       "      <td>7960</td>\n",
       "      <td>207</td>\n",
       "      <td>1439</td>\n",
       "      <td>1027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset model data balancing technique  fold  precision_1  precision_2  \\\n",
       "0      DF5   SVC                     None     1     0.853199     1.000000   \n",
       "1      DF5   SVC                     None     2     0.847168     1.000000   \n",
       "2      DF5   SVC                     None     1     0.865849     1.000000   \n",
       "3      DF5   SVC                     None     2     0.858161     1.000000   \n",
       "4      DF5   SVC                     None     3     0.858688     1.000000   \n",
       "5      DF5   SVC                     None     4     0.854405     1.000000   \n",
       "6      DF5   SVC                     None     5     0.859034     1.000000   \n",
       "7      DF5   SVC                    SMOTE     1     0.974475     0.640824   \n",
       "8      DF5   SVC                    SMOTE     2     0.969016     0.723997   \n",
       "9      DF5   SVC                    SMOTE     3     0.976091     0.618182   \n",
       "10     DF5   SVC     Random Under Sampler     1     0.966309     0.237473   \n",
       "11     DF5   SVC     Random Under Sampler     2     0.970807     0.252127   \n",
       "12     DF5   SVC     Random Under Sampler     3     0.967871     0.254642   \n",
       "13     DF5   SVC     Random Under Sampler     4     0.969439     0.258193   \n",
       "14     DF5   SVC     Random Under Sampler     5     0.968540     0.250540   \n",
       "15     DF5   SVC     Random Under Sampler     6     0.968610     0.256901   \n",
       "16     DF5   SVC     Random Under Sampler     7     0.971373     0.274179   \n",
       "17     DF5   SVC     Random Under Sampler     8     0.967136     0.282619   \n",
       "18     DF5   SVC     Random Under Sampler     9     0.966837     0.260358   \n",
       "19     DF5   SVC     Random Under Sampler    10     0.970784     0.254127   \n",
       "20     DF5   SVC      Random Over Sampler     1     0.967532     0.696629   \n",
       "21     DF5   SVC      Random Over Sampler     2     0.974709     0.725170   \n",
       "22     DF5   SVC                 SMOTEENN     1     0.977907     0.283842   \n",
       "23     DF5   SVC                 SMOTEENN     2     0.977869     0.290400   \n",
       "24     DF5   SVC                 SMOTEENN     3     0.981907     0.299197   \n",
       "25     DF5   SVC                 SMOTEENN     4     0.978312     0.299216   \n",
       "26     DF5   SVC               SMOTETomek     1     0.973929     0.626796   \n",
       "27     DF5   SVC               SMOTETomek     2     0.976142     0.604448   \n",
       "28     DF5   SVC               SMOTETomek     3     0.974310     0.623841   \n",
       "29     DF5   SVC               SMOTETomek     4     0.974654     0.583536   \n",
       "\n",
       "    recall_1  recall_2  f1-score_1  f1-score_2  support_1  support_2     TP  \\\n",
       "0   1.000000  0.013300    0.920785    0.026250    18110.0     3158.0  18110   \n",
       "1   1.000000  0.008552    0.917261    0.016959    17993.0     3274.0  17993   \n",
       "2   1.000000  0.085969    0.928102    0.158327     7274.0     1233.0   7274   \n",
       "3   1.000000  0.069369    0.923667    0.129738     7224.0     1283.0   7224   \n",
       "4   1.000000  0.072543    0.923972    0.135273     7225.0     1282.0   7225   \n",
       "5   1.000000  0.080451    0.921487    0.148921     7177.0     1330.0   7177   \n",
       "6   1.000000  0.093558    0.924172    0.171108     7203.0     1304.0   7203   \n",
       "7   0.918477  0.858070    0.945648    0.733703     7274.0     1233.0   6681   \n",
       "8   0.943798  0.830086    0.956241    0.773420     7224.0     1283.0   6818   \n",
       "9   0.904083  0.875195    0.938708    0.724572     7225.0     1282.0   6532   \n",
       "10  0.519627  0.891980    0.675830    0.375086     3643.0      611.0   1893   \n",
       "11  0.540198  0.905145    0.694145    0.394396     3632.0      622.0   1962   \n",
       "12  0.533481  0.900000    0.687834    0.396968     3614.0      640.0   1928   \n",
       "13  0.536011  0.905280    0.690332    0.401792     3610.0      644.0   1935   \n",
       "14  0.519790  0.904836    0.676513    0.392422     3613.0      641.0   1878   \n",
       "15  0.538057  0.901563    0.691815    0.399861     3613.0      640.0   1944   \n",
       "16  0.557195  0.910606    0.708171    0.421459     3593.0      660.0   2002   \n",
       "17  0.574937  0.895522    0.721162    0.429646     3583.0      670.0   2060   \n",
       "18  0.527708  0.901813    0.682760    0.404061     3591.0      662.0   1895   \n",
       "19  0.524508  0.911215    0.681050    0.397418     3611.0      642.0   1894   \n",
       "20  0.940708  0.811784    0.953932    0.749811     3643.0      611.0   3427   \n",
       "21  0.944383  0.856913    0.959306    0.785556     3632.0      622.0   3430   \n",
       "22  0.595961  0.922441    0.740588    0.434106     9061.0     1573.0   5400   \n",
       "23  0.605481  0.921767    0.747884    0.441657     9049.0     1585.0   5479   \n",
       "24  0.602598  0.938575    0.746852    0.453749     9006.0     1628.0   5427   \n",
       "25  0.602314  0.927096    0.745592    0.452416     8987.0     1646.0   5413   \n",
       "26  0.911158  0.859504    0.941498    0.724933     9061.0     1573.0   8256   \n",
       "27  0.899768  0.874448    0.936400    0.714801     9049.0     1585.0   8142   \n",
       "28  0.905396  0.867936    0.938590    0.725918     9006.0     1628.0   8154   \n",
       "29  0.885724  0.874241    0.928063    0.699903     8987.0     1646.0   7960   \n",
       "\n",
       "      FP    TN    FN  \n",
       "0   3116    42     0  \n",
       "1   3246    28     0  \n",
       "2   1127   106     0  \n",
       "3   1194    89     0  \n",
       "4   1189    93     0  \n",
       "5   1223   107     0  \n",
       "6   1182   122     0  \n",
       "7    175  1058   593  \n",
       "8    218  1065   406  \n",
       "9    160  1122   693  \n",
       "10    66   545  1750  \n",
       "11    59   563  1670  \n",
       "12    64   576  1686  \n",
       "13    61   583  1675  \n",
       "14    61   580  1735  \n",
       "15    63   577  1669  \n",
       "16    59   601  1591  \n",
       "17    70   600  1523  \n",
       "18    65   597  1696  \n",
       "19    57   585  1717  \n",
       "20   115   496   216  \n",
       "21    89   533   202  \n",
       "22   122  1451  3661  \n",
       "23   124  1461  3570  \n",
       "24   100  1528  3579  \n",
       "25   120  1526  3574  \n",
       "26   221  1352   805  \n",
       "27   199  1386   907  \n",
       "28   215  1413   852  \n",
       "29   207  1439  1027  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8905e922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame\n",
    "combined_metrics.to_csv('Output Data/SVC.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c64b71c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
