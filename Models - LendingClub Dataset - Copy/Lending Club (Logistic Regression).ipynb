{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d2c91a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f460afa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "import numpy as np\n",
    "from pprint import pprint as pp\n",
    "import csv\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "from itertools import product\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from imblearn.pipeline import Pipeline \n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import r2_score, classification_report, confusion_matrix, accuracy_score, roc_auc_score, roc_curve, precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import homogeneity_score, silhouette_score\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import MiniBatchKMeans, DBSCAN\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17e9cee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, precision_score, recall_score, f1_score, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6238cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, precision_score, recall_score, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75e8fc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.combine import SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "378df2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0db62d0",
   "metadata": {},
   "source": [
    "### Retrieving the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10513ea6",
   "metadata": {},
   "source": [
    "#### DF 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc3d2069",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = pd.read_csv('df5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82ed7cb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>emp_title</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>issue_d</th>\n",
       "      <th>pymnt_plan</th>\n",
       "      <th>purpose</th>\n",
       "      <th>title</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>addr_state</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>earliest_cr_line</th>\n",
       "      <th>fico_range_low</th>\n",
       "      <th>fico_range_high</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>mths_since_last_delinq</th>\n",
       "      <th>mths_since_last_record</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>revol_bal</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>total_acc</th>\n",
       "      <th>out_prncp</th>\n",
       "      <th>out_prncp_inv</th>\n",
       "      <th>total_pymnt</th>\n",
       "      <th>total_pymnt_inv</th>\n",
       "      <th>total_rec_prncp</th>\n",
       "      <th>total_rec_int</th>\n",
       "      <th>total_rec_late_fee</th>\n",
       "      <th>recoveries</th>\n",
       "      <th>collection_recovery_fee</th>\n",
       "      <th>last_pymnt_d</th>\n",
       "      <th>last_pymnt_amnt</th>\n",
       "      <th>next_pymnt_d</th>\n",
       "      <th>last_credit_pull_d</th>\n",
       "      <th>last_fico_range_high</th>\n",
       "      <th>last_fico_range_low</th>\n",
       "      <th>collections_12_mths_ex_med</th>\n",
       "      <th>acc_now_delinq</th>\n",
       "      <th>chargeoff_within_12_mths</th>\n",
       "      <th>delinq_amnt</th>\n",
       "      <th>pub_rec_bankruptcies</th>\n",
       "      <th>tax_liens</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1077501.0</td>\n",
       "      <td>1296599.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>4975.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1065</td>\n",
       "      <td>162.87</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>25275</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3160</td>\n",
       "      <td>860</td>\n",
       "      <td>3</td>\n",
       "      <td>27.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>735.0</td>\n",
       "      <td>739.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13648.0</td>\n",
       "      <td>0.837</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5863.155187</td>\n",
       "      <td>5833.84</td>\n",
       "      <td>5000.00</td>\n",
       "      <td>863.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>171.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>744.0</td>\n",
       "      <td>740.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1077430.0</td>\n",
       "      <td>1314167.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1527</td>\n",
       "      <td>59.83</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>20173</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17558</td>\n",
       "      <td>309</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>740.0</td>\n",
       "      <td>744.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1687.0</td>\n",
       "      <td>0.094</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1008.710000</td>\n",
       "      <td>1008.71</td>\n",
       "      <td>456.46</td>\n",
       "      <td>435.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117.08</td>\n",
       "      <td>1.11</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>119.66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>499.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         id  member_id  loan_amnt  funded_amnt  funded_amnt_inv  \\\n",
       "0           0  1077501.0  1296599.0     5000.0       5000.0           4975.0   \n",
       "1           1  1077430.0  1314167.0     2500.0       2500.0           2500.0   \n",
       "\n",
       "   term  int_rate  installment  grade  sub_grade  emp_title  emp_length  \\\n",
       "0     0    0.1065       162.87      1          6      25275        10.0   \n",
       "1     1    0.1527        59.83      2         13      20173         1.0   \n",
       "\n",
       "   home_ownership  annual_inc  verification_status  issue_d  pymnt_plan  \\\n",
       "0               4     24000.0                    2   2011.0           0   \n",
       "1               4     30000.0                    1   2011.0           0   \n",
       "\n",
       "   purpose  title  zip_code  addr_state    dti  delinq_2yrs  earliest_cr_line  \\\n",
       "0        1   3160       860           3  27.65          0.0            1985.0   \n",
       "1        0  17558       309          10   1.00          0.0            1999.0   \n",
       "\n",
       "   fico_range_low  fico_range_high  inq_last_6mths  mths_since_last_delinq  \\\n",
       "0           735.0            739.0             1.0                   500.0   \n",
       "1           740.0            744.0             5.0                   500.0   \n",
       "\n",
       "   mths_since_last_record  open_acc  pub_rec  revol_bal  revol_util  \\\n",
       "0                   222.0       3.0      0.0    13648.0       0.837   \n",
       "1                   222.0       3.0      0.0     1687.0       0.094   \n",
       "\n",
       "   total_acc  out_prncp  out_prncp_inv  total_pymnt  total_pymnt_inv  \\\n",
       "0        9.0        0.0            0.0  5863.155187          5833.84   \n",
       "1        4.0        0.0            0.0  1008.710000          1008.71   \n",
       "\n",
       "   total_rec_prncp  total_rec_int  total_rec_late_fee  recoveries  \\\n",
       "0          5000.00         863.16                 0.0        0.00   \n",
       "1           456.46         435.17                 0.0      117.08   \n",
       "\n",
       "   collection_recovery_fee  last_pymnt_d  last_pymnt_amnt  next_pymnt_d  \\\n",
       "0                     0.00        2015.0           171.62           0.0   \n",
       "1                     1.11        2013.0           119.66           0.0   \n",
       "\n",
       "   last_credit_pull_d  last_fico_range_high  last_fico_range_low  \\\n",
       "0              2016.0                 744.0                740.0   \n",
       "1              2016.0                 499.0                  0.0   \n",
       "\n",
       "   collections_12_mths_ex_med  acc_now_delinq  chargeoff_within_12_mths  \\\n",
       "0                           0               0                         0   \n",
       "1                           0               0                         0   \n",
       "\n",
       "   delinq_amnt  pub_rec_bankruptcies  tax_liens  target  \n",
       "0          0.0                   0.0          0       1  \n",
       "1          0.0                   0.0          0       2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed385af",
   "metadata": {},
   "source": [
    "#### DF 5c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4218b67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df5c = pd.read_csv('df5c.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "026f4728",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df5c.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f9963f",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b0bea07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store evaluation metrics for each fold\n",
    "dataset_used = []\n",
    "model_used = []\n",
    "data_balancing_technique = []\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "conf_matrices = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e6d6d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combined_metrics = pd.DataFrame()\n",
    "\n",
    "combined_metrics = pd.DataFrame(columns=['dataset', 'model', 'data balancing technique', 'fold', 'precision_1','precision_2','recall_1','recall_2','f1-score_1','f1-score_2','support_1','support_2','TP','FP','TN','FN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052cda7c",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedf6e11",
   "metadata": {},
   "source": [
    "## DF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89f99b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.98\n",
      "Mean Precision: 0.98\n",
      "Mean Recall: 0.98\n",
      "Mean F1-Score: 0.98\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df5' is your DataFrame with features and the target column\n",
    "# Replace 'features' with the actual list of feature columns\n",
    "features = df5.drop(columns=['target'])  # Drop the target column to get the feature columns\n",
    "target = df5['target']  # Target column to predict\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Initialize KFold with 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the testing set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    y_pred = np.round(y_pred)\n",
    "    \n",
    "    y_pred[y_pred <= 0] = 1\n",
    "    y_pred[y_pred >= 2] = 2\n",
    "    \n",
    "    # Model evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    \n",
    "    # Convert classification report to DataFrame\n",
    "    report_df = pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).transpose()\n",
    "    # Convert confusion matrix to DataFrame\n",
    "    matrix_df = pd.DataFrame(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    # Extract metrics for class 1\n",
    "    metrics_1 = report_df.loc['1', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract metrics for class 2\n",
    "    metrics_2 = report_df.loc['2', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract TP, TN, FP, FN counts from the confusion matrix DataFrame\n",
    "    TP = matrix_df.loc[0, 0]\n",
    "    TN = matrix_df.loc[1, 1]\n",
    "    FP = matrix_df.loc[1, 0]\n",
    "    FN = matrix_df.loc[0, 1]\n",
    "    \n",
    "    new_metric_row = {\n",
    "    'dataset': 'DF5',\n",
    "    'model' : 'Logistic Regression',\n",
    "    'data balancing technique' : 'None',\n",
    "    'fold' : i,\n",
    "    'precision_1': metrics_1['precision'],\n",
    "    'precision_2': metrics_2['precision'],\n",
    "    'recall_1': metrics_1['recall'],\n",
    "    'recall_2': metrics_2['recall'],\n",
    "    'f1-score_1': metrics_1['f1-score'],\n",
    "    'f1-score_2': metrics_2['f1-score'],\n",
    "    'support_1': metrics_1['support'],\n",
    "    'support_2': metrics_2['support'],\n",
    "    'TP' : TP,\n",
    "    'FP' : FP,\n",
    "    'TN' : TN,\n",
    "    'FN' : FN\n",
    "    }\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    #combined_metrics = combined_metrics.append(new_metric_row, ignore_index=True)\n",
    "    combined_metrics.loc[len(combined_metrics)] = new_metric_row\n",
    "    \n",
    "    \n",
    "    # Append evaluation metrics to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "\n",
    "# Calculate mean evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores) #sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = np.mean(precision_scores) #sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = np.mean(recall_scores) #sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = np.mean(f1_scores) #sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print('Mean Accuracy: {:.2f}'.format(mean_accuracy))\n",
    "print('Mean Precision: {:.2f}'.format(mean_precision))\n",
    "print('Mean Recall: {:.2f}'.format(mean_recall))\n",
    "print('Mean F1-Score: {:.2f}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5cd58d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>data balancing technique</th>\n",
       "      <th>fold</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_2</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>f1-score_1</th>\n",
       "      <th>f1-score_2</th>\n",
       "      <th>support_1</th>\n",
       "      <th>support_2</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0.979465</td>\n",
       "      <td>0.967450</td>\n",
       "      <td>0.995059</td>\n",
       "      <td>0.875614</td>\n",
       "      <td>0.987200</td>\n",
       "      <td>0.919244</td>\n",
       "      <td>3643.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>3625</td>\n",
       "      <td>76</td>\n",
       "      <td>535</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>0.977802</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.994493</td>\n",
       "      <td>0.868167</td>\n",
       "      <td>0.986077</td>\n",
       "      <td>0.913706</td>\n",
       "      <td>3632.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>3612</td>\n",
       "      <td>82</td>\n",
       "      <td>540</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset                model data balancing technique  fold  precision_1  \\\n",
       "0     DF5  Logistic Regression                     None     1     0.979465   \n",
       "1     DF5  Logistic Regression                     None     2     0.977802   \n",
       "\n",
       "   precision_2  recall_1  recall_2  f1-score_1  f1-score_2  support_1  \\\n",
       "0     0.967450  0.995059  0.875614    0.987200    0.919244     3643.0   \n",
       "1     0.964286  0.994493  0.868167    0.986077    0.913706     3632.0   \n",
       "\n",
       "   support_2    TP  FP   TN  FN  \n",
       "0      611.0  3625  76  535  18  \n",
       "1      622.0  3612  82  540  20  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_metrics[(combined_metrics['data balancing technique'] == 'None') & (combined_metrics['dataset'] == 'DF5')].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd45aea",
   "metadata": {},
   "source": [
    "### Logistic Regression with df5 data and imbalance data tackling (SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4eaaba2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.98\n",
      "Mean Precision: 0.98\n",
      "Mean Recall: 0.98\n",
      "Mean F1-Score: 0.98\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df5' is your DataFrame with features and the target column\n",
    "# Replace 'features' with the actual list of feature columns\n",
    "features = df5.drop(columns=['target'])  # Drop the target column to get the feature columns\n",
    "target = df5['target']  # Target column to predict\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Initialize KFold with 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    # Apply SMOTE to the training data\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Predict on the testing set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    y_pred = np.round(y_pred)\n",
    "    \n",
    "    y_pred[y_pred <= 0] = 1\n",
    "    y_pred[y_pred >= 2] = 2\n",
    "    \n",
    "    # Model evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Convert classification report to DataFrame\n",
    "    report_df = pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).transpose()\n",
    "    # Convert confusion matrix to DataFrame\n",
    "    matrix_df = pd.DataFrame(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    # Extract metrics for class 1\n",
    "    metrics_1 = report_df.loc['1', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract metrics for class 2\n",
    "    metrics_2 = report_df.loc['2', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract TP, TN, FP, FN counts from the confusion matrix DataFrame\n",
    "    TP = matrix_df.loc[0, 0]\n",
    "    TN = matrix_df.loc[1, 1]\n",
    "    FP = matrix_df.loc[1, 0]\n",
    "    FN = matrix_df.loc[0, 1]\n",
    "    \n",
    "    new_metric_row = {\n",
    "    'dataset': 'DF5',\n",
    "    'model' : 'Logistic Regression',\n",
    "    'data balancing technique' : 'SMOTE',\n",
    "    'fold' : i,\n",
    "    'precision_1': metrics_1['precision'],\n",
    "    'precision_2': metrics_2['precision'],\n",
    "    'recall_1': metrics_1['recall'],\n",
    "    'recall_2': metrics_2['recall'],\n",
    "    'f1-score_1': metrics_1['f1-score'],\n",
    "    'f1-score_2': metrics_2['f1-score'],\n",
    "    'support_1': metrics_1['support'],\n",
    "    'support_2': metrics_2['support'],\n",
    "    'TP' : TP,\n",
    "    'FP' : FP,\n",
    "    'TN' : TN,\n",
    "    'FN' : FN\n",
    "    }\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    #combined_metrics = combined_metrics.append(new_metric_row, ignore_index=True)\n",
    "    combined_metrics.loc[len(combined_metrics)] = new_metric_row\n",
    "    \n",
    "    \n",
    "    # Append evaluation metrics to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "\n",
    "# Calculate mean evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores) #sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = np.mean(precision_scores) #sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = np.mean(recall_scores) #sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = np.mean(f1_scores) #sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print('Mean Accuracy: {:.2f}'.format(mean_accuracy))\n",
    "print('Mean Precision: {:.2f}'.format(mean_precision))\n",
    "print('Mean Recall: {:.2f}'.format(mean_recall))\n",
    "print('Mean F1-Score: {:.2f}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "031ffc3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>data balancing technique</th>\n",
       "      <th>fold</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_2</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>f1-score_1</th>\n",
       "      <th>f1-score_2</th>\n",
       "      <th>support_1</th>\n",
       "      <th>support_2</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>1</td>\n",
       "      <td>0.987370</td>\n",
       "      <td>0.923203</td>\n",
       "      <td>0.987099</td>\n",
       "      <td>0.924714</td>\n",
       "      <td>0.987234</td>\n",
       "      <td>0.923957</td>\n",
       "      <td>3643.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>3596</td>\n",
       "      <td>46</td>\n",
       "      <td>565</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>2</td>\n",
       "      <td>0.988493</td>\n",
       "      <td>0.960265</td>\n",
       "      <td>0.993392</td>\n",
       "      <td>0.932476</td>\n",
       "      <td>0.990937</td>\n",
       "      <td>0.946166</td>\n",
       "      <td>3632.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>3608</td>\n",
       "      <td>42</td>\n",
       "      <td>580</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset                model data balancing technique  fold  precision_1  \\\n",
       "10     DF5  Logistic Regression                    SMOTE     1     0.987370   \n",
       "11     DF5  Logistic Regression                    SMOTE     2     0.988493   \n",
       "\n",
       "    precision_2  recall_1  recall_2  f1-score_1  f1-score_2  support_1  \\\n",
       "10     0.923203  0.987099  0.924714    0.987234    0.923957     3643.0   \n",
       "11     0.960265  0.993392  0.932476    0.990937    0.946166     3632.0   \n",
       "\n",
       "    support_2    TP  FP   TN  FN  \n",
       "10      611.0  3596  46  565  47  \n",
       "11      622.0  3608  42  580  24  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_metrics[(combined_metrics['data balancing technique'] == 'SMOTE') & (combined_metrics['dataset'] == 'DF5')].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737bdf77",
   "metadata": {},
   "source": [
    "### Logistic Regression with df5 data and imbalance data tackling (RandomUnderSampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0efc30fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.98\n",
      "Mean Precision: 0.98\n",
      "Mean Recall: 0.98\n",
      "Mean F1-Score: 0.98\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df5' is your DataFrame with features and the target column\n",
    "# Replace 'features' with the actual list of feature columns\n",
    "features = df5.drop(columns=['target'])  # Drop the target column to get the feature columns\n",
    "target = df5['target']  # Target column to predict\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Initialize KFold with 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    # Undersampling the majority class\n",
    "    rus = RandomUnderSampler(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Predict on the testing set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    y_pred = np.round(y_pred)\n",
    "    \n",
    "    y_pred[y_pred <= 0] = 1\n",
    "    y_pred[y_pred >= 2] = 2\n",
    "    \n",
    "    # Model evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Convert classification report to DataFrame\n",
    "    report_df = pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).transpose()\n",
    "    # Convert confusion matrix to DataFrame\n",
    "    matrix_df = pd.DataFrame(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    # Extract metrics for class 1\n",
    "    metrics_1 = report_df.loc['1', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract metrics for class 2\n",
    "    metrics_2 = report_df.loc['2', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract TP, TN, FP, FN counts from the confusion matrix DataFrame\n",
    "    TP = matrix_df.loc[0, 0]\n",
    "    TN = matrix_df.loc[1, 1]\n",
    "    FP = matrix_df.loc[1, 0]\n",
    "    FN = matrix_df.loc[0, 1]\n",
    "    \n",
    "    new_metric_row = {\n",
    "    'dataset': 'DF5',\n",
    "    'model' : 'Logistic Regression',\n",
    "    'data balancing technique' : 'Random Under Sampler',\n",
    "    'fold' : i,\n",
    "    'precision_1': metrics_1['precision'],\n",
    "    'precision_2': metrics_2['precision'],\n",
    "    'recall_1': metrics_1['recall'],\n",
    "    'recall_2': metrics_2['recall'],\n",
    "    'f1-score_1': metrics_1['f1-score'],\n",
    "    'f1-score_2': metrics_2['f1-score'],\n",
    "    'support_1': metrics_1['support'],\n",
    "    'support_2': metrics_2['support'],\n",
    "    'TP' : TP,\n",
    "    'FP' : FP,\n",
    "    'TN' : TN,\n",
    "    'FN' : FN\n",
    "    }\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    #combined_metrics = combined_metrics.append(new_metric_row, ignore_index=True)\n",
    "    combined_metrics.loc[len(combined_metrics)] = new_metric_row\n",
    "    \n",
    "    \n",
    "    # Append evaluation metrics to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "\n",
    "# Calculate mean evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores) #sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = np.mean(precision_scores) #sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = np.mean(recall_scores) #sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = np.mean(f1_scores) #sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print('Mean Accuracy: {:.2f}'.format(mean_accuracy))\n",
    "print('Mean Precision: {:.2f}'.format(mean_precision))\n",
    "print('Mean Recall: {:.2f}'.format(mean_recall))\n",
    "print('Mean F1-Score: {:.2f}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d72cc02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>data balancing technique</th>\n",
       "      <th>fold</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_2</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>f1-score_1</th>\n",
       "      <th>f1-score_2</th>\n",
       "      <th>support_1</th>\n",
       "      <th>support_2</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>1</td>\n",
       "      <td>0.987849</td>\n",
       "      <td>0.895735</td>\n",
       "      <td>0.981883</td>\n",
       "      <td>0.927987</td>\n",
       "      <td>0.984857</td>\n",
       "      <td>0.911576</td>\n",
       "      <td>3643.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>3577</td>\n",
       "      <td>44</td>\n",
       "      <td>567</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>2</td>\n",
       "      <td>0.992762</td>\n",
       "      <td>0.900302</td>\n",
       "      <td>0.981828</td>\n",
       "      <td>0.958199</td>\n",
       "      <td>0.987265</td>\n",
       "      <td>0.928349</td>\n",
       "      <td>3632.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>3566</td>\n",
       "      <td>26</td>\n",
       "      <td>596</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset                model data balancing technique  fold  precision_1  \\\n",
       "20     DF5  Logistic Regression     Random Under Sampler     1     0.987849   \n",
       "21     DF5  Logistic Regression     Random Under Sampler     2     0.992762   \n",
       "\n",
       "    precision_2  recall_1  recall_2  f1-score_1  f1-score_2  support_1  \\\n",
       "20     0.895735  0.981883  0.927987    0.984857    0.911576     3643.0   \n",
       "21     0.900302  0.981828  0.958199    0.987265    0.928349     3632.0   \n",
       "\n",
       "    support_2    TP  FP   TN  FN  \n",
       "20      611.0  3577  44  567  66  \n",
       "21      622.0  3566  26  596  66  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_metrics[(combined_metrics['data balancing technique'] == 'Random Under Sampler') & (combined_metrics['dataset'] == 'DF5')].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc10646",
   "metadata": {},
   "source": [
    "### Logistic Regression with df5 data and imbalance data tackling (RandomOverSampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c500a1fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.98\n",
      "Mean Precision: 0.98\n",
      "Mean Recall: 0.98\n",
      "Mean F1-Score: 0.98\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df5' is your DataFrame with features and the target column\n",
    "# Replace 'features' with the actual list of feature columns\n",
    "features = df5.drop(columns=['target'])  # Drop the target column to get the feature columns\n",
    "target = df5['target']  # Target column to predict\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Initialize KFold with 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    # Oversampling the majority class\n",
    "    ros = RandomOverSampler(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Predict on the testing set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    y_pred = np.round(y_pred)\n",
    "    \n",
    "    y_pred[y_pred <= 0] = 1\n",
    "    y_pred[y_pred >= 2] = 2\n",
    "    \n",
    "    # Model evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Convert classification report to DataFrame\n",
    "    report_df = pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).transpose()\n",
    "    # Convert confusion matrix to DataFrame\n",
    "    matrix_df = pd.DataFrame(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    # Extract metrics for class 1\n",
    "    metrics_1 = report_df.loc['1', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract metrics for class 2\n",
    "    metrics_2 = report_df.loc['2', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract TP, TN, FP, FN counts from the confusion matrix DataFrame\n",
    "    TP = matrix_df.loc[0, 0]\n",
    "    TN = matrix_df.loc[1, 1]\n",
    "    FP = matrix_df.loc[1, 0]\n",
    "    FN = matrix_df.loc[0, 1]\n",
    "    \n",
    "    new_metric_row = {\n",
    "    'dataset': 'DF5',\n",
    "    'model' : 'Logistic Regression',\n",
    "    'data balancing technique' : 'Random Over Sampler',\n",
    "    'fold' : i,\n",
    "    'precision_1': metrics_1['precision'],\n",
    "    'precision_2': metrics_2['precision'],\n",
    "    'recall_1': metrics_1['recall'],\n",
    "    'recall_2': metrics_2['recall'],\n",
    "    'f1-score_1': metrics_1['f1-score'],\n",
    "    'f1-score_2': metrics_2['f1-score'],\n",
    "    'support_1': metrics_1['support'],\n",
    "    'support_2': metrics_2['support'],\n",
    "    'TP' : TP,\n",
    "    'FP' : FP,\n",
    "    'TN' : TN,\n",
    "    'FN' : FN\n",
    "    }\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    #combined_metrics = combined_metrics.append(new_metric_row, ignore_index=True)\n",
    "    combined_metrics.loc[len(combined_metrics)] = new_metric_row\n",
    "    \n",
    "    \n",
    "    # Append evaluation metrics to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "\n",
    "# Calculate mean evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores) #sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = np.mean(precision_scores) #sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = np.mean(recall_scores) #sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = np.mean(f1_scores) #sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print('Mean Accuracy: {:.2f}'.format(mean_accuracy))\n",
    "print('Mean Precision: {:.2f}'.format(mean_precision))\n",
    "print('Mean Recall: {:.2f}'.format(mean_recall))\n",
    "print('Mean F1-Score: {:.2f}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca7e58c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>data balancing technique</th>\n",
       "      <th>fold</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_2</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>f1-score_1</th>\n",
       "      <th>f1-score_2</th>\n",
       "      <th>support_1</th>\n",
       "      <th>support_2</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>1</td>\n",
       "      <td>0.988122</td>\n",
       "      <td>0.895899</td>\n",
       "      <td>0.981883</td>\n",
       "      <td>0.929624</td>\n",
       "      <td>0.984992</td>\n",
       "      <td>0.912450</td>\n",
       "      <td>3643.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>3577</td>\n",
       "      <td>43</td>\n",
       "      <td>568</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>2</td>\n",
       "      <td>0.992233</td>\n",
       "      <td>0.915254</td>\n",
       "      <td>0.984857</td>\n",
       "      <td>0.954984</td>\n",
       "      <td>0.988531</td>\n",
       "      <td>0.934697</td>\n",
       "      <td>3632.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>3577</td>\n",
       "      <td>28</td>\n",
       "      <td>594</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset                model data balancing technique  fold  precision_1  \\\n",
       "30     DF5  Logistic Regression      Random Over Sampler     1     0.988122   \n",
       "31     DF5  Logistic Regression      Random Over Sampler     2     0.992233   \n",
       "\n",
       "    precision_2  recall_1  recall_2  f1-score_1  f1-score_2  support_1  \\\n",
       "30     0.895899  0.981883  0.929624    0.984992    0.912450     3643.0   \n",
       "31     0.915254  0.984857  0.954984    0.988531    0.934697     3632.0   \n",
       "\n",
       "    support_2    TP  FP   TN  FN  \n",
       "30      611.0  3577  43  568  66  \n",
       "31      622.0  3577  28  594  55  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_metrics[(combined_metrics['data balancing technique'] == 'Random Over Sampler') & (combined_metrics['dataset'] == 'DF5')].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3502aa0f",
   "metadata": {},
   "source": [
    "### Logistic Regression with df5 data and imbalance data tackling (SMOTEENN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14344c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.98\n",
      "Mean Precision: 0.98\n",
      "Mean Recall: 0.98\n",
      "Mean F1-Score: 0.98\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df5' is your DataFrame with features and the target column\n",
    "# Replace 'features' with the actual list of feature columns\n",
    "features = df5.drop(columns=['target'])  # Drop the target column to get the feature columns\n",
    "target = df5['target']  # Target column to predict\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Initialize KFold with 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    # Apply SMOTEENN for combined over and undersampling\n",
    "    smote_enn = SMOTEENN(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote_enn.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Predict on the testing set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    y_pred = np.round(y_pred)\n",
    "    \n",
    "    y_pred[y_pred <= 0] = 1\n",
    "    y_pred[y_pred >= 2] = 2\n",
    "    \n",
    "    # Model evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Convert classification report to DataFrame\n",
    "    report_df = pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).transpose()\n",
    "    # Convert confusion matrix to DataFrame\n",
    "    matrix_df = pd.DataFrame(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    # Extract metrics for class 1\n",
    "    metrics_1 = report_df.loc['1', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract metrics for class 2\n",
    "    metrics_2 = report_df.loc['2', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract TP, TN, FP, FN counts from the confusion matrix DataFrame\n",
    "    TP = matrix_df.loc[0, 0]\n",
    "    TN = matrix_df.loc[1, 1]\n",
    "    FP = matrix_df.loc[1, 0]\n",
    "    FN = matrix_df.loc[0, 1]\n",
    "    \n",
    "    new_metric_row = {\n",
    "    'dataset': 'DF5',\n",
    "    'model' : 'Logistic Regression',\n",
    "    'data balancing technique' : 'SMOTEENN',\n",
    "    'fold' : i,\n",
    "    'precision_1': metrics_1['precision'],\n",
    "    'precision_2': metrics_2['precision'],\n",
    "    'recall_1': metrics_1['recall'],\n",
    "    'recall_2': metrics_2['recall'],\n",
    "    'f1-score_1': metrics_1['f1-score'],\n",
    "    'f1-score_2': metrics_2['f1-score'],\n",
    "    'support_1': metrics_1['support'],\n",
    "    'support_2': metrics_2['support'],\n",
    "    'TP' : TP,\n",
    "    'FP' : FP,\n",
    "    'TN' : TN,\n",
    "    'FN' : FN\n",
    "    }\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    #combined_metrics = combined_metrics.append(new_metric_row, ignore_index=True)\n",
    "    combined_metrics.loc[len(combined_metrics)] = new_metric_row\n",
    "    \n",
    "    \n",
    "    # Append evaluation metrics to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "\n",
    "# Calculate mean evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores) #sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = np.mean(precision_scores) #sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = np.mean(recall_scores) #sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = np.mean(f1_scores) #sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print('Mean Accuracy: {:.2f}'.format(mean_accuracy))\n",
    "print('Mean Precision: {:.2f}'.format(mean_precision))\n",
    "print('Mean Recall: {:.2f}'.format(mean_recall))\n",
    "print('Mean F1-Score: {:.2f}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "661a7658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>data balancing technique</th>\n",
       "      <th>fold</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_2</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>f1-score_1</th>\n",
       "      <th>f1-score_2</th>\n",
       "      <th>support_1</th>\n",
       "      <th>support_2</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>SMOTEENN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.990914</td>\n",
       "      <td>0.929260</td>\n",
       "      <td>0.987922</td>\n",
       "      <td>0.945990</td>\n",
       "      <td>0.989416</td>\n",
       "      <td>0.937551</td>\n",
       "      <td>3643.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>3599</td>\n",
       "      <td>33</td>\n",
       "      <td>578</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>SMOTEENN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.991141</td>\n",
       "      <td>0.919003</td>\n",
       "      <td>0.985683</td>\n",
       "      <td>0.948553</td>\n",
       "      <td>0.988404</td>\n",
       "      <td>0.933544</td>\n",
       "      <td>3632.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>3580</td>\n",
       "      <td>32</td>\n",
       "      <td>590</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset                model data balancing technique  fold  precision_1  \\\n",
       "40     DF5  Logistic Regression                 SMOTEENN     1     0.990914   \n",
       "41     DF5  Logistic Regression                 SMOTEENN     2     0.991141   \n",
       "\n",
       "    precision_2  recall_1  recall_2  f1-score_1  f1-score_2  support_1  \\\n",
       "40     0.929260  0.987922  0.945990    0.989416    0.937551     3643.0   \n",
       "41     0.919003  0.985683  0.948553    0.988404    0.933544     3632.0   \n",
       "\n",
       "    support_2    TP  FP   TN  FN  \n",
       "40      611.0  3599  33  578  44  \n",
       "41      622.0  3580  32  590  52  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_metrics[(combined_metrics['data balancing technique'] == 'SMOTEENN') & (combined_metrics['dataset'] == 'DF5')].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d61e0f",
   "metadata": {},
   "source": [
    "### Logistic Regression with df5 data and imbalance data tackling (SMOTETOMEK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "474f7eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.98\n",
      "Mean Precision: 0.98\n",
      "Mean Recall: 0.98\n",
      "Mean F1-Score: 0.98\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df5' is your DataFrame with features and the target column\n",
    "# Replace 'features' with the actual list of feature columns\n",
    "features = df5.drop(columns=['target'])  # Drop the target column to get the feature columns\n",
    "target = df5['target']  # Target column to predict\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Initialize KFold with 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    # Apply SMOTETomek for combined over and undersampling\n",
    "    SMOTE_Tomek = SMOTETomek(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = SMOTE_Tomek.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Predict on the testing set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    y_pred = np.round(y_pred)\n",
    "    \n",
    "    y_pred[y_pred <= 0] = 1\n",
    "    y_pred[y_pred >= 2] = 2\n",
    "    \n",
    "    # Model evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Convert classification report to DataFrame\n",
    "    report_df = pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).transpose()\n",
    "    # Convert confusion matrix to DataFrame\n",
    "    matrix_df = pd.DataFrame(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    # Extract metrics for class 1\n",
    "    metrics_1 = report_df.loc['1', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract metrics for class 2\n",
    "    metrics_2 = report_df.loc['2', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract TP, TN, FP, FN counts from the confusion matrix DataFrame\n",
    "    TP = matrix_df.loc[0, 0]\n",
    "    TN = matrix_df.loc[1, 1]\n",
    "    FP = matrix_df.loc[1, 0]\n",
    "    FN = matrix_df.loc[0, 1]\n",
    "    \n",
    "    new_metric_row = {\n",
    "    'dataset': 'DF5',\n",
    "    'model' : 'Logistic Regression',\n",
    "    'data balancing technique' : 'SMOTETomek',\n",
    "    'fold' : i,\n",
    "    'precision_1': metrics_1['precision'],\n",
    "    'precision_2': metrics_2['precision'],\n",
    "    'recall_1': metrics_1['recall'],\n",
    "    'recall_2': metrics_2['recall'],\n",
    "    'f1-score_1': metrics_1['f1-score'],\n",
    "    'f1-score_2': metrics_2['f1-score'],\n",
    "    'support_1': metrics_1['support'],\n",
    "    'support_2': metrics_2['support'],\n",
    "    'TP' : TP,\n",
    "    'FP' : FP,\n",
    "    'TN' : TN,\n",
    "    'FN' : FN\n",
    "    }\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    #combined_metrics = combined_metrics.append(new_metric_row, ignore_index=True)\n",
    "    combined_metrics.loc[len(combined_metrics)] = new_metric_row\n",
    "    \n",
    "    \n",
    "    # Append evaluation metrics to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "\n",
    "# Calculate mean evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores) #sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = np.mean(precision_scores) #sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = np.mean(recall_scores) #sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = np.mean(f1_scores) #sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print('Mean Accuracy: {:.2f}'.format(mean_accuracy))\n",
    "print('Mean Precision: {:.2f}'.format(mean_precision))\n",
    "print('Mean Recall: {:.2f}'.format(mean_recall))\n",
    "print('Mean F1-Score: {:.2f}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6da809c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>data balancing technique</th>\n",
       "      <th>fold</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_2</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>f1-score_1</th>\n",
       "      <th>f1-score_2</th>\n",
       "      <th>support_1</th>\n",
       "      <th>support_2</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>SMOTETomek</td>\n",
       "      <td>1</td>\n",
       "      <td>0.987648</td>\n",
       "      <td>0.926350</td>\n",
       "      <td>0.987648</td>\n",
       "      <td>0.926350</td>\n",
       "      <td>0.987648</td>\n",
       "      <td>0.926350</td>\n",
       "      <td>3643.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>3598</td>\n",
       "      <td>45</td>\n",
       "      <td>566</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>SMOTETomek</td>\n",
       "      <td>2</td>\n",
       "      <td>0.987404</td>\n",
       "      <td>0.956811</td>\n",
       "      <td>0.992841</td>\n",
       "      <td>0.926045</td>\n",
       "      <td>0.990115</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>3632.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>3606</td>\n",
       "      <td>46</td>\n",
       "      <td>576</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset                model data balancing technique  fold  precision_1  \\\n",
       "50     DF5  Logistic Regression               SMOTETomek     1     0.987648   \n",
       "51     DF5  Logistic Regression               SMOTETomek     2     0.987404   \n",
       "\n",
       "    precision_2  recall_1  recall_2  f1-score_1  f1-score_2  support_1  \\\n",
       "50     0.926350  0.987648  0.926350    0.987648    0.926350     3643.0   \n",
       "51     0.956811  0.992841  0.926045    0.990115    0.941176     3632.0   \n",
       "\n",
       "    support_2    TP  FP   TN  FN  \n",
       "50      611.0  3598  45  566  45  \n",
       "51      622.0  3606  46  576  26  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_metrics[(combined_metrics['data balancing technique'] == 'SMOTETomek') & (combined_metrics['dataset'] == 'DF5')].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f60b6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85f183d",
   "metadata": {},
   "source": [
    "## DF5c - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07b53bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.73\n",
      "Mean Precision: 0.75\n",
      "Mean Recall: 0.73\n",
      "Mean F1-Score: 0.73\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df5' is your DataFrame with features and the target column\n",
    "# Replace 'features' with the actual list of feature columns\n",
    "features = df5c.drop(columns=['target'])  # Drop the target column to get the feature columns\n",
    "target = df5c['target']  # Target column to predict\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Initialize KFold with 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the testing set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Model evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Convert classification report to DataFrame\n",
    "    report_df = pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).transpose()\n",
    "    # Convert confusion matrix to DataFrame\n",
    "    matrix_df = pd.DataFrame(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    # Extract metrics for class 1\n",
    "    metrics_1 = report_df.loc['1', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract metrics for class 2\n",
    "    metrics_2 = report_df.loc['2', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract TP, TN, FP, FN counts from the confusion matrix DataFrame\n",
    "    TP = matrix_df.loc[0, 0]\n",
    "    TN = matrix_df.loc[1, 1]\n",
    "    FP = matrix_df.loc[1, 0]\n",
    "    FN = matrix_df.loc[0, 1]\n",
    "    \n",
    "    new_metric_row = {\n",
    "    'dataset': 'DF5c',\n",
    "    'model' : 'Logistic Regression',\n",
    "    'data balancing technique' : 'None',\n",
    "    'fold' : i,\n",
    "    'precision_1': metrics_1['precision'],\n",
    "    'precision_2': metrics_2['precision'],\n",
    "    'recall_1': metrics_1['recall'],\n",
    "    'recall_2': metrics_2['recall'],\n",
    "    'f1-score_1': metrics_1['f1-score'],\n",
    "    'f1-score_2': metrics_2['f1-score'],\n",
    "    'support_1': metrics_1['support'],\n",
    "    'support_2': metrics_2['support'],\n",
    "    'TP' : TP,\n",
    "    'FP' : FP,\n",
    "    'TN' : TN,\n",
    "    'FN' : FN\n",
    "    }\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    #combined_metrics = combined_metrics.append(new_metric_row, ignore_index=True)\n",
    "    combined_metrics.loc[len(combined_metrics)] = new_metric_row\n",
    "    \n",
    "    \n",
    "    # Append evaluation metrics to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "\n",
    "# Calculate mean evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores) #sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = np.mean(precision_scores) #sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = np.mean(recall_scores) #sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = np.mean(f1_scores) #sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print('Mean Accuracy: {:.2f}'.format(mean_accuracy))\n",
    "print('Mean Precision: {:.2f}'.format(mean_precision))\n",
    "print('Mean Recall: {:.2f}'.format(mean_recall))\n",
    "print('Mean F1-Score: {:.2f}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9dbc10dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>data balancing technique</th>\n",
       "      <th>fold</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_2</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>f1-score_1</th>\n",
       "      <th>f1-score_2</th>\n",
       "      <th>support_1</th>\n",
       "      <th>support_2</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>DF5c</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0.802469</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.915493</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.855263</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>71.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>65</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>DF5c</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>0.767442</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>70.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>66</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset                model data balancing technique  fold  precision_1  \\\n",
       "60    DF5c  Logistic Regression                     None     1     0.802469   \n",
       "61    DF5c  Logistic Regression                     None     2     0.767442   \n",
       "\n",
       "    precision_2  recall_1  recall_2  f1-score_1  f1-score_2  support_1  \\\n",
       "60     0.684211  0.915493  0.448276    0.855263    0.541667       71.0   \n",
       "61     0.714286  0.942857  0.333333    0.846154    0.454545       70.0   \n",
       "\n",
       "    support_2  TP  FP  TN  FN  \n",
       "60       29.0  65  16  13   6  \n",
       "61       30.0  66  20  10   4  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_metrics[(combined_metrics['data balancing technique'] == 'None') & (combined_metrics['dataset'] == 'DF5c')].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a96351",
   "metadata": {},
   "source": [
    "### Logistic Regression with df5c data and imbalance data tackling (SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cfa40392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.73\n",
      "Mean Precision: 0.75\n",
      "Mean Recall: 0.73\n",
      "Mean F1-Score: 0.73\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df5' is your DataFrame with features and the target column\n",
    "# Replace 'features' with the actual list of feature columns\n",
    "features = df5c.drop(columns=['target'])  # Drop the target column to get the feature columns\n",
    "target = df5c['target']  # Target column to predict\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Initialize KFold with 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    # Apply SMOTE to the training data\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Predict on the testing set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Model evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Convert classification report to DataFrame\n",
    "    report_df = pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).transpose()\n",
    "    # Convert confusion matrix to DataFrame\n",
    "    matrix_df = pd.DataFrame(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    # Extract metrics for class 1\n",
    "    metrics_1 = report_df.loc['1', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract metrics for class 2\n",
    "    metrics_2 = report_df.loc['2', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract TP, TN, FP, FN counts from the confusion matrix DataFrame\n",
    "    TP = matrix_df.loc[0, 0]\n",
    "    TN = matrix_df.loc[1, 1]\n",
    "    FP = matrix_df.loc[1, 0]\n",
    "    FN = matrix_df.loc[0, 1]\n",
    "    \n",
    "    new_metric_row = {\n",
    "    'dataset': 'DF5c',\n",
    "    'model' : 'Logistic Regression',\n",
    "    'data balancing technique' : 'SMOTE',\n",
    "    'fold' : i,\n",
    "    'precision_1': metrics_1['precision'],\n",
    "    'precision_2': metrics_2['precision'],\n",
    "    'recall_1': metrics_1['recall'],\n",
    "    'recall_2': metrics_2['recall'],\n",
    "    'f1-score_1': metrics_1['f1-score'],\n",
    "    'f1-score_2': metrics_2['f1-score'],\n",
    "    'support_1': metrics_1['support'],\n",
    "    'support_2': metrics_2['support'],\n",
    "    'TP' : TP,\n",
    "    'FP' : FP,\n",
    "    'TN' : TN,\n",
    "    'FN' : FN\n",
    "    }\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    #combined_metrics = combined_metrics.append(new_metric_row, ignore_index=True)\n",
    "    combined_metrics.loc[len(combined_metrics)] = new_metric_row\n",
    "    \n",
    "    \n",
    "    # Append evaluation metrics to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "\n",
    "# Calculate mean evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores) #sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = np.mean(precision_scores) #sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = np.mean(recall_scores) #sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = np.mean(f1_scores) #sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print('Mean Accuracy: {:.2f}'.format(mean_accuracy))\n",
    "print('Mean Precision: {:.2f}'.format(mean_precision))\n",
    "print('Mean Recall: {:.2f}'.format(mean_recall))\n",
    "print('Mean F1-Score: {:.2f}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "53d1a9ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>data balancing technique</th>\n",
       "      <th>fold</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_2</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>f1-score_1</th>\n",
       "      <th>f1-score_2</th>\n",
       "      <th>support_1</th>\n",
       "      <th>support_2</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>DF5c</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>1</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.57500</td>\n",
       "      <td>0.760563</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.824427</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>71.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>54</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>DF5c</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>2</td>\n",
       "      <td>0.808824</td>\n",
       "      <td>0.53125</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.797101</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>70.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>55</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset                model data balancing technique  fold  precision_1  \\\n",
       "70    DF5c  Logistic Regression                    SMOTE     1     0.900000   \n",
       "71    DF5c  Logistic Regression                    SMOTE     2     0.808824   \n",
       "\n",
       "    precision_2  recall_1  recall_2  f1-score_1  f1-score_2  support_1  \\\n",
       "70      0.57500  0.760563  0.793103    0.824427    0.666667       71.0   \n",
       "71      0.53125  0.785714  0.566667    0.797101    0.548387       70.0   \n",
       "\n",
       "    support_2  TP  FP  TN  FN  \n",
       "70       29.0  54   6  23  17  \n",
       "71       30.0  55  13  17  15  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_metrics[(combined_metrics['data balancing technique'] == 'SMOTE') & (combined_metrics['dataset'] == 'DF5c')].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fab885",
   "metadata": {},
   "source": [
    "### Logistic Regression with df5c data and imbalance data tackling (Random Under Sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d9f5e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.72\n",
      "Mean Precision: 0.75\n",
      "Mean Recall: 0.72\n",
      "Mean F1-Score: 0.73\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df5' is your DataFrame with features and the target column\n",
    "# Replace 'features' with the actual list of feature columns\n",
    "features = df5c.drop(columns=['target'])  # Drop the target column to get the feature columns\n",
    "target = df5c['target']  # Target column to predict\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Initialize KFold with 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    # Apply RUS to the training data\n",
    "    rus = RandomUnderSampler(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Predict on the testing set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Model evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Convert classification report to DataFrame\n",
    "    report_df = pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).transpose()\n",
    "    # Convert confusion matrix to DataFrame\n",
    "    matrix_df = pd.DataFrame(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    # Extract metrics for class 1\n",
    "    metrics_1 = report_df.loc['1', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract metrics for class 2\n",
    "    metrics_2 = report_df.loc['2', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract TP, TN, FP, FN counts from the confusion matrix DataFrame\n",
    "    TP = matrix_df.loc[0, 0]\n",
    "    TN = matrix_df.loc[1, 1]\n",
    "    FP = matrix_df.loc[1, 0]\n",
    "    FN = matrix_df.loc[0, 1]\n",
    "    \n",
    "    new_metric_row = {\n",
    "    'dataset': 'DF5c',\n",
    "    'model' : 'Logistic Regression',\n",
    "    'data balancing technique' : 'Random Under Sampler',\n",
    "    'fold' : i,\n",
    "    'precision_1': metrics_1['precision'],\n",
    "    'precision_2': metrics_2['precision'],\n",
    "    'recall_1': metrics_1['recall'],\n",
    "    'recall_2': metrics_2['recall'],\n",
    "    'f1-score_1': metrics_1['f1-score'],\n",
    "    'f1-score_2': metrics_2['f1-score'],\n",
    "    'support_1': metrics_1['support'],\n",
    "    'support_2': metrics_2['support'],\n",
    "    'TP' : TP,\n",
    "    'FP' : FP,\n",
    "    'TN' : TN,\n",
    "    'FN' : FN\n",
    "    }\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    #combined_metrics = combined_metrics.append(new_metric_row, ignore_index=True)\n",
    "    combined_metrics.loc[len(combined_metrics)] = new_metric_row\n",
    "    \n",
    "    \n",
    "    # Append evaluation metrics to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "\n",
    "# Calculate mean evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores) #sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = np.mean(precision_scores) #sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = np.mean(recall_scores) #sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = np.mean(f1_scores) #sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print('Mean Accuracy: {:.2f}'.format(mean_accuracy))\n",
    "print('Mean Precision: {:.2f}'.format(mean_precision))\n",
    "print('Mean Recall: {:.2f}'.format(mean_recall))\n",
    "print('Mean F1-Score: {:.2f}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2d1bb284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>data balancing technique</th>\n",
       "      <th>fold</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_2</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>f1-score_1</th>\n",
       "      <th>f1-score_2</th>\n",
       "      <th>support_1</th>\n",
       "      <th>support_2</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>DF5c</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>1</td>\n",
       "      <td>0.898305</td>\n",
       "      <td>0.560976</td>\n",
       "      <td>0.746479</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>71.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>53</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>DF5c</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>2</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.814286</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.820144</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>70.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>57</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset                model data balancing technique  fold  precision_1  \\\n",
       "80    DF5c  Logistic Regression     Random Under Sampler     1     0.898305   \n",
       "81    DF5c  Logistic Regression     Random Under Sampler     2     0.826087   \n",
       "\n",
       "    precision_2  recall_1  recall_2  f1-score_1  f1-score_2  support_1  \\\n",
       "80     0.560976  0.746479  0.793103    0.815385    0.657143       71.0   \n",
       "81     0.580645  0.814286  0.600000    0.820144    0.590164       70.0   \n",
       "\n",
       "    support_2  TP  FP  TN  FN  \n",
       "80       29.0  53   6  23  18  \n",
       "81       30.0  57  12  18  13  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_metrics[(combined_metrics['data balancing technique'] == 'Random Under Sampler') & (combined_metrics['dataset'] == 'DF5c')].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596f2d9a",
   "metadata": {},
   "source": [
    "### Logistic Regression with df5c data and imbalance data tackling (Random Over Sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "deeacc22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.72\n",
      "Mean Precision: 0.75\n",
      "Mean Recall: 0.72\n",
      "Mean F1-Score: 0.73\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df5' is your DataFrame with features and the target column\n",
    "# Replace 'features' with the actual list of feature columns\n",
    "features = df5c.drop(columns=['target'])  # Drop the target column to get the feature columns\n",
    "target = df5c['target']  # Target column to predict\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Initialize KFold with 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    # Apply ROS to the training data\n",
    "    ros = RandomOverSampler(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Predict on the testing set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Model evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Convert classification report to DataFrame\n",
    "    report_df = pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).transpose()\n",
    "    # Convert confusion matrix to DataFrame\n",
    "    matrix_df = pd.DataFrame(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    # Extract metrics for class 1\n",
    "    metrics_1 = report_df.loc['1', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract metrics for class 2\n",
    "    metrics_2 = report_df.loc['2', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract TP, TN, FP, FN counts from the confusion matrix DataFrame\n",
    "    TP = matrix_df.loc[0, 0]\n",
    "    TN = matrix_df.loc[1, 1]\n",
    "    FP = matrix_df.loc[1, 0]\n",
    "    FN = matrix_df.loc[0, 1]\n",
    "    \n",
    "    new_metric_row = {\n",
    "    'dataset': 'DF5c',\n",
    "    'model' : 'Logistic Regression',\n",
    "    'data balancing technique' : 'Random Over Sampler',\n",
    "    'fold' : i,\n",
    "    'precision_1': metrics_1['precision'],\n",
    "    'precision_2': metrics_2['precision'],\n",
    "    'recall_1': metrics_1['recall'],\n",
    "    'recall_2': metrics_2['recall'],\n",
    "    'f1-score_1': metrics_1['f1-score'],\n",
    "    'f1-score_2': metrics_2['f1-score'],\n",
    "    'support_1': metrics_1['support'],\n",
    "    'support_2': metrics_2['support'],\n",
    "    'TP' : TP,\n",
    "    'FP' : FP,\n",
    "    'TN' : TN,\n",
    "    'FN' : FN\n",
    "    }\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    #combined_metrics = combined_metrics.append(new_metric_row, ignore_index=True)\n",
    "    combined_metrics.loc[len(combined_metrics)] = new_metric_row\n",
    "    \n",
    "    \n",
    "    # Append evaluation metrics to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "\n",
    "# Calculate mean evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores) #sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = np.mean(precision_scores) #sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = np.mean(recall_scores) #sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = np.mean(f1_scores) #sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print('Mean Accuracy: {:.2f}'.format(mean_accuracy))\n",
    "print('Mean Precision: {:.2f}'.format(mean_precision))\n",
    "print('Mean Recall: {:.2f}'.format(mean_recall))\n",
    "print('Mean F1-Score: {:.2f}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b3c845f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>data balancing technique</th>\n",
       "      <th>fold</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_2</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>f1-score_1</th>\n",
       "      <th>f1-score_2</th>\n",
       "      <th>support_1</th>\n",
       "      <th>support_2</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>DF5c</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>1</td>\n",
       "      <td>0.913793</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.746479</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.676056</td>\n",
       "      <td>71.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>53</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>DF5c</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>2</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.742424</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>70.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>49</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset                model data balancing technique  fold  precision_1  \\\n",
       "90    DF5c  Logistic Regression      Random Over Sampler     1     0.913793   \n",
       "91    DF5c  Logistic Regression      Random Over Sampler     2     0.790323   \n",
       "\n",
       "    precision_2  recall_1  recall_2  f1-score_1  f1-score_2  support_1  \\\n",
       "90     0.571429  0.746479  0.827586    0.821705    0.676056       71.0   \n",
       "91     0.447368  0.700000  0.566667    0.742424    0.500000       70.0   \n",
       "\n",
       "    support_2  TP  FP  TN  FN  \n",
       "90       29.0  53   5  24  18  \n",
       "91       30.0  49  13  17  21  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_metrics[(combined_metrics['data balancing technique'] == 'Random Over Sampler') & (combined_metrics['dataset'] == 'DF5c')].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d688e2",
   "metadata": {},
   "source": [
    "### Logistic Regression with df5c data and imbalance data tackling (SMOTEENN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c044fc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.72\n",
      "Mean Precision: 0.75\n",
      "Mean Recall: 0.72\n",
      "Mean F1-Score: 0.72\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df5' is your DataFrame with features and the target column\n",
    "# Replace 'features' with the actual list of feature columns\n",
    "features = df5c.drop(columns=['target'])  # Drop the target column to get the feature columns\n",
    "target = df5c['target']  # Target column to predict\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Initialize KFold with 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    # Apply SMOTEENN to the training data\n",
    "    SMOTEEnn = SMOTEENN(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = SMOTEEnn.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Predict on the testing set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Model evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Convert classification report to DataFrame\n",
    "    report_df = pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).transpose()\n",
    "    # Convert confusion matrix to DataFrame\n",
    "    matrix_df = pd.DataFrame(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    # Extract metrics for class 1\n",
    "    metrics_1 = report_df.loc['1', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract metrics for class 2\n",
    "    metrics_2 = report_df.loc['2', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract TP, TN, FP, FN counts from the confusion matrix DataFrame\n",
    "    TP = matrix_df.loc[0, 0]\n",
    "    TN = matrix_df.loc[1, 1]\n",
    "    FP = matrix_df.loc[1, 0]\n",
    "    FN = matrix_df.loc[0, 1]\n",
    "    \n",
    "    new_metric_row = {\n",
    "    'dataset': 'DF5c',\n",
    "    'model' : 'Logistic Regression',\n",
    "    'data balancing technique' : 'SMOTEENN',\n",
    "    'fold' : i,\n",
    "    'precision_1': metrics_1['precision'],\n",
    "    'precision_2': metrics_2['precision'],\n",
    "    'recall_1': metrics_1['recall'],\n",
    "    'recall_2': metrics_2['recall'],\n",
    "    'f1-score_1': metrics_1['f1-score'],\n",
    "    'f1-score_2': metrics_2['f1-score'],\n",
    "    'support_1': metrics_1['support'],\n",
    "    'support_2': metrics_2['support'],\n",
    "    'TP' : TP,\n",
    "    'FP' : FP,\n",
    "    'TN' : TN,\n",
    "    'FN' : FN\n",
    "    }\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    #combined_metrics = combined_metrics.append(new_metric_row, ignore_index=True)\n",
    "    combined_metrics.loc[len(combined_metrics)] = new_metric_row\n",
    "    \n",
    "    \n",
    "    # Append evaluation metrics to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "\n",
    "# Calculate mean evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores) #sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = np.mean(precision_scores) #sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = np.mean(recall_scores) #sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = np.mean(f1_scores) #sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print('Mean Accuracy: {:.2f}'.format(mean_accuracy))\n",
    "print('Mean Precision: {:.2f}'.format(mean_precision))\n",
    "print('Mean Recall: {:.2f}'.format(mean_recall))\n",
    "print('Mean F1-Score: {:.2f}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "81297c53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>data balancing technique</th>\n",
       "      <th>fold</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_2</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>f1-score_1</th>\n",
       "      <th>f1-score_2</th>\n",
       "      <th>support_1</th>\n",
       "      <th>support_2</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>DF5c</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>SMOTEENN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.661972</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.776860</td>\n",
       "      <td>0.658228</td>\n",
       "      <td>71.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>47</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>DF5c</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>SMOTEENN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.418605</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.708661</td>\n",
       "      <td>0.493151</td>\n",
       "      <td>70.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>45</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dataset                model data balancing technique  fold  precision_1  \\\n",
       "100    DF5c  Logistic Regression                 SMOTEENN     1     0.940000   \n",
       "101    DF5c  Logistic Regression                 SMOTEENN     2     0.789474   \n",
       "\n",
       "     precision_2  recall_1  recall_2  f1-score_1  f1-score_2  support_1  \\\n",
       "100     0.520000  0.661972  0.896552    0.776860    0.658228       71.0   \n",
       "101     0.418605  0.642857  0.600000    0.708661    0.493151       70.0   \n",
       "\n",
       "     support_2  TP  FP  TN  FN  \n",
       "100       29.0  47   3  26  24  \n",
       "101       30.0  45  12  18  25  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_metrics[(combined_metrics['data balancing technique'] == 'SMOTEENN') & (combined_metrics['dataset'] == 'DF5c')].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d72534",
   "metadata": {},
   "source": [
    "### Logistic Regression with df5c data and imbalance data tackling (SMOTETomek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2300ee90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.72\n",
      "Mean Precision: 0.75\n",
      "Mean Recall: 0.72\n",
      "Mean F1-Score: 0.73\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df5' is your DataFrame with features and the target column\n",
    "# Replace 'features' with the actual list of feature columns\n",
    "features = df5c.drop(columns=['target'])  # Drop the target column to get the feature columns\n",
    "target = df5c['target']  # Target column to predict\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Initialize KFold with 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    # Apply SMOTEENN to the training data\n",
    "    SMOTETOMEK = SMOTETomek(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = SMOTETOMEK.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Predict on the testing set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Model evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Convert classification report to DataFrame\n",
    "    report_df = pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).transpose()\n",
    "    # Convert confusion matrix to DataFrame\n",
    "    matrix_df = pd.DataFrame(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    # Extract metrics for class 1\n",
    "    metrics_1 = report_df.loc['1', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract metrics for class 2\n",
    "    metrics_2 = report_df.loc['2', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract TP, TN, FP, FN counts from the confusion matrix DataFrame\n",
    "    TP = matrix_df.loc[0, 0]\n",
    "    TN = matrix_df.loc[1, 1]\n",
    "    FP = matrix_df.loc[1, 0]\n",
    "    FN = matrix_df.loc[0, 1]\n",
    "    \n",
    "    new_metric_row = {\n",
    "    'dataset': 'DF5c',\n",
    "    'model' : 'Logistic Regression',\n",
    "    'data balancing technique' : 'SMOTETomek',\n",
    "    'fold' : i,\n",
    "    'precision_1': metrics_1['precision'],\n",
    "    'precision_2': metrics_2['precision'],\n",
    "    'recall_1': metrics_1['recall'],\n",
    "    'recall_2': metrics_2['recall'],\n",
    "    'f1-score_1': metrics_1['f1-score'],\n",
    "    'f1-score_2': metrics_2['f1-score'],\n",
    "    'support_1': metrics_1['support'],\n",
    "    'support_2': metrics_2['support'],\n",
    "    'TP' : TP,\n",
    "    'FP' : FP,\n",
    "    'TN' : TN,\n",
    "    'FN' : FN\n",
    "    }\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    #combined_metrics = combined_metrics.append(new_metric_row, ignore_index=True)\n",
    "    combined_metrics.loc[len(combined_metrics)] = new_metric_row\n",
    "    \n",
    "    \n",
    "    # Append evaluation metrics to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "\n",
    "# Calculate mean evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores) #sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = np.mean(precision_scores) #sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = np.mean(recall_scores) #sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = np.mean(f1_scores) #sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print('Mean Accuracy: {:.2f}'.format(mean_accuracy))\n",
    "print('Mean Precision: {:.2f}'.format(mean_precision))\n",
    "print('Mean Recall: {:.2f}'.format(mean_recall))\n",
    "print('Mean F1-Score: {:.2f}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cc6d42eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>data balancing technique</th>\n",
       "      <th>fold</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_2</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>f1-score_1</th>\n",
       "      <th>f1-score_2</th>\n",
       "      <th>support_1</th>\n",
       "      <th>support_2</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>DF5c</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>SMOTETomek</td>\n",
       "      <td>1</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.774648</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.827068</td>\n",
       "      <td>0.656716</td>\n",
       "      <td>71.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>55</td>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>DF5c</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>SMOTETomek</td>\n",
       "      <td>2</td>\n",
       "      <td>0.805970</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.788321</td>\n",
       "      <td>0.539683</td>\n",
       "      <td>70.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dataset                model data balancing technique  fold  precision_1  \\\n",
       "110    DF5c  Logistic Regression               SMOTETomek     1     0.887097   \n",
       "111    DF5c  Logistic Regression               SMOTETomek     2     0.805970   \n",
       "\n",
       "     precision_2  recall_1  recall_2  f1-score_1  f1-score_2  support_1  \\\n",
       "110     0.578947  0.774648  0.758621    0.827068    0.656716       71.0   \n",
       "111     0.515152  0.771429  0.566667    0.788321    0.539683       70.0   \n",
       "\n",
       "     support_2  TP  FP  TN  FN  \n",
       "110       29.0  55   7  22  16  \n",
       "111       30.0  54  13  17  16  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_metrics[(combined_metrics['data balancing technique'] == 'SMOTETomek') & (combined_metrics['dataset'] == 'DF5c')].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd948ec1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc4b04f0",
   "metadata": {},
   "source": [
    "## Performance metrics for the Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1158fa25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>data balancing technique</th>\n",
       "      <th>fold</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_2</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>f1-score_1</th>\n",
       "      <th>f1-score_2</th>\n",
       "      <th>support_1</th>\n",
       "      <th>support_2</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0.979465</td>\n",
       "      <td>0.967450</td>\n",
       "      <td>0.995059</td>\n",
       "      <td>0.875614</td>\n",
       "      <td>0.987200</td>\n",
       "      <td>0.919244</td>\n",
       "      <td>3643.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>3625</td>\n",
       "      <td>76</td>\n",
       "      <td>535</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>0.977802</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.994493</td>\n",
       "      <td>0.868167</td>\n",
       "      <td>0.986077</td>\n",
       "      <td>0.913706</td>\n",
       "      <td>3632.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>3612</td>\n",
       "      <td>82</td>\n",
       "      <td>540</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>0.980622</td>\n",
       "      <td>0.964407</td>\n",
       "      <td>0.994189</td>\n",
       "      <td>0.889062</td>\n",
       "      <td>0.987359</td>\n",
       "      <td>0.925203</td>\n",
       "      <td>3614.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3593</td>\n",
       "      <td>71</td>\n",
       "      <td>569</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>0.983055</td>\n",
       "      <td>0.978151</td>\n",
       "      <td>0.996399</td>\n",
       "      <td>0.903727</td>\n",
       "      <td>0.989682</td>\n",
       "      <td>0.939467</td>\n",
       "      <td>3610.0</td>\n",
       "      <td>644.0</td>\n",
       "      <td>3597</td>\n",
       "      <td>62</td>\n",
       "      <td>582</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>0.982216</td>\n",
       "      <td>0.961603</td>\n",
       "      <td>0.993634</td>\n",
       "      <td>0.898596</td>\n",
       "      <td>0.987892</td>\n",
       "      <td>0.929032</td>\n",
       "      <td>3613.0</td>\n",
       "      <td>641.0</td>\n",
       "      <td>3590</td>\n",
       "      <td>65</td>\n",
       "      <td>576</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>0.980838</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.991697</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.986237</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>3613.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3583</td>\n",
       "      <td>70</td>\n",
       "      <td>570</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>7</td>\n",
       "      <td>0.978338</td>\n",
       "      <td>0.958746</td>\n",
       "      <td>0.993042</td>\n",
       "      <td>0.880303</td>\n",
       "      <td>0.985635</td>\n",
       "      <td>0.917852</td>\n",
       "      <td>3593.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3568</td>\n",
       "      <td>79</td>\n",
       "      <td>581</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>8</td>\n",
       "      <td>0.978642</td>\n",
       "      <td>0.985025</td>\n",
       "      <td>0.997488</td>\n",
       "      <td>0.883582</td>\n",
       "      <td>0.987975</td>\n",
       "      <td>0.931550</td>\n",
       "      <td>3583.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>3574</td>\n",
       "      <td>78</td>\n",
       "      <td>592</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>9</td>\n",
       "      <td>0.981298</td>\n",
       "      <td>0.962723</td>\n",
       "      <td>0.993595</td>\n",
       "      <td>0.897281</td>\n",
       "      <td>0.987408</td>\n",
       "      <td>0.928851</td>\n",
       "      <td>3591.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>3568</td>\n",
       "      <td>68</td>\n",
       "      <td>594</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.981411</td>\n",
       "      <td>0.964706</td>\n",
       "      <td>0.994184</td>\n",
       "      <td>0.894081</td>\n",
       "      <td>0.987756</td>\n",
       "      <td>0.928052</td>\n",
       "      <td>3611.0</td>\n",
       "      <td>642.0</td>\n",
       "      <td>3590</td>\n",
       "      <td>68</td>\n",
       "      <td>574</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>1</td>\n",
       "      <td>0.987370</td>\n",
       "      <td>0.923203</td>\n",
       "      <td>0.987099</td>\n",
       "      <td>0.924714</td>\n",
       "      <td>0.987234</td>\n",
       "      <td>0.923957</td>\n",
       "      <td>3643.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>3596</td>\n",
       "      <td>46</td>\n",
       "      <td>565</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>2</td>\n",
       "      <td>0.988493</td>\n",
       "      <td>0.960265</td>\n",
       "      <td>0.993392</td>\n",
       "      <td>0.932476</td>\n",
       "      <td>0.990937</td>\n",
       "      <td>0.946166</td>\n",
       "      <td>3632.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>3608</td>\n",
       "      <td>42</td>\n",
       "      <td>580</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>3</td>\n",
       "      <td>0.988926</td>\n",
       "      <td>0.934579</td>\n",
       "      <td>0.988379</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.988652</td>\n",
       "      <td>0.936037</td>\n",
       "      <td>3614.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3572</td>\n",
       "      <td>40</td>\n",
       "      <td>600</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>4</td>\n",
       "      <td>0.987815</td>\n",
       "      <td>0.933126</td>\n",
       "      <td>0.988089</td>\n",
       "      <td>0.931677</td>\n",
       "      <td>0.987952</td>\n",
       "      <td>0.932401</td>\n",
       "      <td>3610.0</td>\n",
       "      <td>644.0</td>\n",
       "      <td>3567</td>\n",
       "      <td>44</td>\n",
       "      <td>600</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>5</td>\n",
       "      <td>0.990805</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.984224</td>\n",
       "      <td>0.948518</td>\n",
       "      <td>0.987503</td>\n",
       "      <td>0.931087</td>\n",
       "      <td>3613.0</td>\n",
       "      <td>641.0</td>\n",
       "      <td>3556</td>\n",
       "      <td>33</td>\n",
       "      <td>608</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>6</td>\n",
       "      <td>0.991408</td>\n",
       "      <td>0.944186</td>\n",
       "      <td>0.990036</td>\n",
       "      <td>0.951562</td>\n",
       "      <td>0.990722</td>\n",
       "      <td>0.947860</td>\n",
       "      <td>3613.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3577</td>\n",
       "      <td>31</td>\n",
       "      <td>609</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>7</td>\n",
       "      <td>0.989659</td>\n",
       "      <td>0.922963</td>\n",
       "      <td>0.985527</td>\n",
       "      <td>0.943939</td>\n",
       "      <td>0.987589</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>3593.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3541</td>\n",
       "      <td>37</td>\n",
       "      <td>623</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>8</td>\n",
       "      <td>0.991044</td>\n",
       "      <td>0.938235</td>\n",
       "      <td>0.988278</td>\n",
       "      <td>0.952239</td>\n",
       "      <td>0.989659</td>\n",
       "      <td>0.945185</td>\n",
       "      <td>3583.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>3541</td>\n",
       "      <td>32</td>\n",
       "      <td>638</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>9</td>\n",
       "      <td>0.989103</td>\n",
       "      <td>0.924332</td>\n",
       "      <td>0.985798</td>\n",
       "      <td>0.941088</td>\n",
       "      <td>0.987448</td>\n",
       "      <td>0.932635</td>\n",
       "      <td>3591.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>3540</td>\n",
       "      <td>39</td>\n",
       "      <td>623</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>10</td>\n",
       "      <td>0.989964</td>\n",
       "      <td>0.909910</td>\n",
       "      <td>0.983384</td>\n",
       "      <td>0.943925</td>\n",
       "      <td>0.986663</td>\n",
       "      <td>0.926606</td>\n",
       "      <td>3611.0</td>\n",
       "      <td>642.0</td>\n",
       "      <td>3551</td>\n",
       "      <td>36</td>\n",
       "      <td>606</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>1</td>\n",
       "      <td>0.987849</td>\n",
       "      <td>0.895735</td>\n",
       "      <td>0.981883</td>\n",
       "      <td>0.927987</td>\n",
       "      <td>0.984857</td>\n",
       "      <td>0.911576</td>\n",
       "      <td>3643.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>3577</td>\n",
       "      <td>44</td>\n",
       "      <td>567</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>2</td>\n",
       "      <td>0.992762</td>\n",
       "      <td>0.900302</td>\n",
       "      <td>0.981828</td>\n",
       "      <td>0.958199</td>\n",
       "      <td>0.987265</td>\n",
       "      <td>0.928349</td>\n",
       "      <td>3632.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>3566</td>\n",
       "      <td>26</td>\n",
       "      <td>596</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>3</td>\n",
       "      <td>0.989442</td>\n",
       "      <td>0.919084</td>\n",
       "      <td>0.985335</td>\n",
       "      <td>0.940625</td>\n",
       "      <td>0.987384</td>\n",
       "      <td>0.929730</td>\n",
       "      <td>3614.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3561</td>\n",
       "      <td>38</td>\n",
       "      <td>602</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>4</td>\n",
       "      <td>0.991694</td>\n",
       "      <td>0.956386</td>\n",
       "      <td>0.992244</td>\n",
       "      <td>0.953416</td>\n",
       "      <td>0.991969</td>\n",
       "      <td>0.954899</td>\n",
       "      <td>3610.0</td>\n",
       "      <td>644.0</td>\n",
       "      <td>3582</td>\n",
       "      <td>30</td>\n",
       "      <td>614</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>5</td>\n",
       "      <td>0.992192</td>\n",
       "      <td>0.917665</td>\n",
       "      <td>0.984777</td>\n",
       "      <td>0.956318</td>\n",
       "      <td>0.988471</td>\n",
       "      <td>0.936593</td>\n",
       "      <td>3613.0</td>\n",
       "      <td>641.0</td>\n",
       "      <td>3558</td>\n",
       "      <td>28</td>\n",
       "      <td>613</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>6</td>\n",
       "      <td>0.994137</td>\n",
       "      <td>0.922504</td>\n",
       "      <td>0.985608</td>\n",
       "      <td>0.967187</td>\n",
       "      <td>0.989854</td>\n",
       "      <td>0.944317</td>\n",
       "      <td>3613.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3561</td>\n",
       "      <td>21</td>\n",
       "      <td>619</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>7</td>\n",
       "      <td>0.991575</td>\n",
       "      <td>0.910405</td>\n",
       "      <td>0.982744</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.987140</td>\n",
       "      <td>0.931953</td>\n",
       "      <td>3593.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3531</td>\n",
       "      <td>30</td>\n",
       "      <td>630</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>8</td>\n",
       "      <td>0.989335</td>\n",
       "      <td>0.915942</td>\n",
       "      <td>0.983812</td>\n",
       "      <td>0.943284</td>\n",
       "      <td>0.986566</td>\n",
       "      <td>0.929412</td>\n",
       "      <td>3583.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>3525</td>\n",
       "      <td>38</td>\n",
       "      <td>632</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>9</td>\n",
       "      <td>0.992411</td>\n",
       "      <td>0.913669</td>\n",
       "      <td>0.983292</td>\n",
       "      <td>0.959215</td>\n",
       "      <td>0.987830</td>\n",
       "      <td>0.935888</td>\n",
       "      <td>3591.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>3531</td>\n",
       "      <td>27</td>\n",
       "      <td>635</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>10</td>\n",
       "      <td>0.992715</td>\n",
       "      <td>0.900585</td>\n",
       "      <td>0.981169</td>\n",
       "      <td>0.959502</td>\n",
       "      <td>0.986908</td>\n",
       "      <td>0.929110</td>\n",
       "      <td>3611.0</td>\n",
       "      <td>642.0</td>\n",
       "      <td>3543</td>\n",
       "      <td>26</td>\n",
       "      <td>616</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>1</td>\n",
       "      <td>0.988122</td>\n",
       "      <td>0.895899</td>\n",
       "      <td>0.981883</td>\n",
       "      <td>0.929624</td>\n",
       "      <td>0.984992</td>\n",
       "      <td>0.912450</td>\n",
       "      <td>3643.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>3577</td>\n",
       "      <td>43</td>\n",
       "      <td>568</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>2</td>\n",
       "      <td>0.992233</td>\n",
       "      <td>0.915254</td>\n",
       "      <td>0.984857</td>\n",
       "      <td>0.954984</td>\n",
       "      <td>0.988531</td>\n",
       "      <td>0.934697</td>\n",
       "      <td>3632.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>3577</td>\n",
       "      <td>28</td>\n",
       "      <td>594</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>3</td>\n",
       "      <td>0.995273</td>\n",
       "      <td>0.946809</td>\n",
       "      <td>0.990315</td>\n",
       "      <td>0.973437</td>\n",
       "      <td>0.992788</td>\n",
       "      <td>0.959938</td>\n",
       "      <td>3614.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3579</td>\n",
       "      <td>17</td>\n",
       "      <td>623</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>4</td>\n",
       "      <td>0.990754</td>\n",
       "      <td>0.891971</td>\n",
       "      <td>0.979501</td>\n",
       "      <td>0.948758</td>\n",
       "      <td>0.985095</td>\n",
       "      <td>0.919488</td>\n",
       "      <td>3610.0</td>\n",
       "      <td>644.0</td>\n",
       "      <td>3536</td>\n",
       "      <td>33</td>\n",
       "      <td>611</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>5</td>\n",
       "      <td>0.993559</td>\n",
       "      <td>0.904832</td>\n",
       "      <td>0.982009</td>\n",
       "      <td>0.964119</td>\n",
       "      <td>0.987751</td>\n",
       "      <td>0.933535</td>\n",
       "      <td>3613.0</td>\n",
       "      <td>641.0</td>\n",
       "      <td>3548</td>\n",
       "      <td>23</td>\n",
       "      <td>618</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>6</td>\n",
       "      <td>0.993013</td>\n",
       "      <td>0.911111</td>\n",
       "      <td>0.983393</td>\n",
       "      <td>0.960938</td>\n",
       "      <td>0.988180</td>\n",
       "      <td>0.935361</td>\n",
       "      <td>3613.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3553</td>\n",
       "      <td>25</td>\n",
       "      <td>615</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>7</td>\n",
       "      <td>0.989899</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.981909</td>\n",
       "      <td>0.945455</td>\n",
       "      <td>0.985888</td>\n",
       "      <td>0.925130</td>\n",
       "      <td>3593.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3528</td>\n",
       "      <td>36</td>\n",
       "      <td>624</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>8</td>\n",
       "      <td>0.989636</td>\n",
       "      <td>0.926794</td>\n",
       "      <td>0.986045</td>\n",
       "      <td>0.944776</td>\n",
       "      <td>0.987837</td>\n",
       "      <td>0.935698</td>\n",
       "      <td>3583.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>3533</td>\n",
       "      <td>37</td>\n",
       "      <td>633</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>9</td>\n",
       "      <td>0.991004</td>\n",
       "      <td>0.905172</td>\n",
       "      <td>0.981621</td>\n",
       "      <td>0.951662</td>\n",
       "      <td>0.986290</td>\n",
       "      <td>0.927835</td>\n",
       "      <td>3591.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>3525</td>\n",
       "      <td>32</td>\n",
       "      <td>630</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>10</td>\n",
       "      <td>0.992172</td>\n",
       "      <td>0.908284</td>\n",
       "      <td>0.982830</td>\n",
       "      <td>0.956386</td>\n",
       "      <td>0.987479</td>\n",
       "      <td>0.931715</td>\n",
       "      <td>3611.0</td>\n",
       "      <td>642.0</td>\n",
       "      <td>3549</td>\n",
       "      <td>28</td>\n",
       "      <td>614</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>SMOTEENN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.990914</td>\n",
       "      <td>0.929260</td>\n",
       "      <td>0.987922</td>\n",
       "      <td>0.945990</td>\n",
       "      <td>0.989416</td>\n",
       "      <td>0.937551</td>\n",
       "      <td>3643.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>3599</td>\n",
       "      <td>33</td>\n",
       "      <td>578</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>SMOTEENN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.991141</td>\n",
       "      <td>0.919003</td>\n",
       "      <td>0.985683</td>\n",
       "      <td>0.948553</td>\n",
       "      <td>0.988404</td>\n",
       "      <td>0.933544</td>\n",
       "      <td>3632.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>3580</td>\n",
       "      <td>32</td>\n",
       "      <td>590</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>SMOTEENN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.990283</td>\n",
       "      <td>0.927914</td>\n",
       "      <td>0.986995</td>\n",
       "      <td>0.945312</td>\n",
       "      <td>0.988636</td>\n",
       "      <td>0.936533</td>\n",
       "      <td>3614.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3567</td>\n",
       "      <td>35</td>\n",
       "      <td>605</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>SMOTEENN</td>\n",
       "      <td>4</td>\n",
       "      <td>0.990774</td>\n",
       "      <td>0.902511</td>\n",
       "      <td>0.981717</td>\n",
       "      <td>0.948758</td>\n",
       "      <td>0.986225</td>\n",
       "      <td>0.925057</td>\n",
       "      <td>3610.0</td>\n",
       "      <td>644.0</td>\n",
       "      <td>3544</td>\n",
       "      <td>33</td>\n",
       "      <td>611</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>SMOTEENN</td>\n",
       "      <td>5</td>\n",
       "      <td>0.993311</td>\n",
       "      <td>0.926426</td>\n",
       "      <td>0.986438</td>\n",
       "      <td>0.962559</td>\n",
       "      <td>0.989863</td>\n",
       "      <td>0.944147</td>\n",
       "      <td>3613.0</td>\n",
       "      <td>641.0</td>\n",
       "      <td>3564</td>\n",
       "      <td>24</td>\n",
       "      <td>617</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>SMOTEENN</td>\n",
       "      <td>6</td>\n",
       "      <td>0.991346</td>\n",
       "      <td>0.907601</td>\n",
       "      <td>0.982840</td>\n",
       "      <td>0.951562</td>\n",
       "      <td>0.987074</td>\n",
       "      <td>0.929062</td>\n",
       "      <td>3613.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3551</td>\n",
       "      <td>31</td>\n",
       "      <td>609</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>SMOTEENN</td>\n",
       "      <td>7</td>\n",
       "      <td>0.992458</td>\n",
       "      <td>0.940565</td>\n",
       "      <td>0.988867</td>\n",
       "      <td>0.959091</td>\n",
       "      <td>0.990659</td>\n",
       "      <td>0.949737</td>\n",
       "      <td>3593.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3553</td>\n",
       "      <td>27</td>\n",
       "      <td>633</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>SMOTEENN</td>\n",
       "      <td>8</td>\n",
       "      <td>0.990728</td>\n",
       "      <td>0.917867</td>\n",
       "      <td>0.984092</td>\n",
       "      <td>0.950746</td>\n",
       "      <td>0.987398</td>\n",
       "      <td>0.934018</td>\n",
       "      <td>3583.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>3526</td>\n",
       "      <td>33</td>\n",
       "      <td>637</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>SMOTEENN</td>\n",
       "      <td>9</td>\n",
       "      <td>0.991014</td>\n",
       "      <td>0.910405</td>\n",
       "      <td>0.982735</td>\n",
       "      <td>0.951662</td>\n",
       "      <td>0.986857</td>\n",
       "      <td>0.930576</td>\n",
       "      <td>3591.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>3529</td>\n",
       "      <td>32</td>\n",
       "      <td>630</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>SMOTEENN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.991643</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.985876</td>\n",
       "      <td>0.953271</td>\n",
       "      <td>0.988752</td>\n",
       "      <td>0.937931</td>\n",
       "      <td>3611.0</td>\n",
       "      <td>642.0</td>\n",
       "      <td>3560</td>\n",
       "      <td>30</td>\n",
       "      <td>612</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>SMOTETomek</td>\n",
       "      <td>1</td>\n",
       "      <td>0.987648</td>\n",
       "      <td>0.926350</td>\n",
       "      <td>0.987648</td>\n",
       "      <td>0.926350</td>\n",
       "      <td>0.987648</td>\n",
       "      <td>0.926350</td>\n",
       "      <td>3643.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>3598</td>\n",
       "      <td>45</td>\n",
       "      <td>566</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>SMOTETomek</td>\n",
       "      <td>2</td>\n",
       "      <td>0.987404</td>\n",
       "      <td>0.956811</td>\n",
       "      <td>0.992841</td>\n",
       "      <td>0.926045</td>\n",
       "      <td>0.990115</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>3632.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>3606</td>\n",
       "      <td>46</td>\n",
       "      <td>576</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>SMOTETomek</td>\n",
       "      <td>3</td>\n",
       "      <td>0.989471</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.988102</td>\n",
       "      <td>0.940625</td>\n",
       "      <td>0.988786</td>\n",
       "      <td>0.936965</td>\n",
       "      <td>3614.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3571</td>\n",
       "      <td>38</td>\n",
       "      <td>602</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>SMOTETomek</td>\n",
       "      <td>4</td>\n",
       "      <td>0.989203</td>\n",
       "      <td>0.942368</td>\n",
       "      <td>0.989751</td>\n",
       "      <td>0.939441</td>\n",
       "      <td>0.989477</td>\n",
       "      <td>0.940902</td>\n",
       "      <td>3610.0</td>\n",
       "      <td>644.0</td>\n",
       "      <td>3573</td>\n",
       "      <td>39</td>\n",
       "      <td>605</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>SMOTETomek</td>\n",
       "      <td>5</td>\n",
       "      <td>0.989725</td>\n",
       "      <td>0.924962</td>\n",
       "      <td>0.986438</td>\n",
       "      <td>0.942278</td>\n",
       "      <td>0.988079</td>\n",
       "      <td>0.933539</td>\n",
       "      <td>3613.0</td>\n",
       "      <td>641.0</td>\n",
       "      <td>3564</td>\n",
       "      <td>37</td>\n",
       "      <td>604</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>SMOTETomek</td>\n",
       "      <td>6</td>\n",
       "      <td>0.989158</td>\n",
       "      <td>0.916159</td>\n",
       "      <td>0.984777</td>\n",
       "      <td>0.939063</td>\n",
       "      <td>0.986963</td>\n",
       "      <td>0.927469</td>\n",
       "      <td>3613.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3558</td>\n",
       "      <td>39</td>\n",
       "      <td>601</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>SMOTETomek</td>\n",
       "      <td>7</td>\n",
       "      <td>0.989955</td>\n",
       "      <td>0.932735</td>\n",
       "      <td>0.987476</td>\n",
       "      <td>0.945455</td>\n",
       "      <td>0.988714</td>\n",
       "      <td>0.939052</td>\n",
       "      <td>3593.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3548</td>\n",
       "      <td>36</td>\n",
       "      <td>624</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>SMOTETomek</td>\n",
       "      <td>8</td>\n",
       "      <td>0.992784</td>\n",
       "      <td>0.990769</td>\n",
       "      <td>0.998325</td>\n",
       "      <td>0.961194</td>\n",
       "      <td>0.995547</td>\n",
       "      <td>0.975758</td>\n",
       "      <td>3583.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>3577</td>\n",
       "      <td>26</td>\n",
       "      <td>644</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>SMOTETomek</td>\n",
       "      <td>9</td>\n",
       "      <td>0.989679</td>\n",
       "      <td>0.935629</td>\n",
       "      <td>0.988026</td>\n",
       "      <td>0.944109</td>\n",
       "      <td>0.988852</td>\n",
       "      <td>0.939850</td>\n",
       "      <td>3591.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>3548</td>\n",
       "      <td>37</td>\n",
       "      <td>625</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>SMOTETomek</td>\n",
       "      <td>10</td>\n",
       "      <td>0.991141</td>\n",
       "      <td>0.951638</td>\n",
       "      <td>0.991415</td>\n",
       "      <td>0.950156</td>\n",
       "      <td>0.991278</td>\n",
       "      <td>0.950896</td>\n",
       "      <td>3611.0</td>\n",
       "      <td>642.0</td>\n",
       "      <td>3580</td>\n",
       "      <td>32</td>\n",
       "      <td>610</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset                model data balancing technique  fold  precision_1  \\\n",
       "0      DF5  Logistic Regression                     None     1     0.979465   \n",
       "1      DF5  Logistic Regression                     None     2     0.977802   \n",
       "2      DF5  Logistic Regression                     None     3     0.980622   \n",
       "3      DF5  Logistic Regression                     None     4     0.983055   \n",
       "4      DF5  Logistic Regression                     None     5     0.982216   \n",
       "5      DF5  Logistic Regression                     None     6     0.980838   \n",
       "6      DF5  Logistic Regression                     None     7     0.978338   \n",
       "7      DF5  Logistic Regression                     None     8     0.978642   \n",
       "8      DF5  Logistic Regression                     None     9     0.981298   \n",
       "9      DF5  Logistic Regression                     None    10     0.981411   \n",
       "10     DF5  Logistic Regression                    SMOTE     1     0.987370   \n",
       "11     DF5  Logistic Regression                    SMOTE     2     0.988493   \n",
       "12     DF5  Logistic Regression                    SMOTE     3     0.988926   \n",
       "13     DF5  Logistic Regression                    SMOTE     4     0.987815   \n",
       "14     DF5  Logistic Regression                    SMOTE     5     0.990805   \n",
       "15     DF5  Logistic Regression                    SMOTE     6     0.991408   \n",
       "16     DF5  Logistic Regression                    SMOTE     7     0.989659   \n",
       "17     DF5  Logistic Regression                    SMOTE     8     0.991044   \n",
       "18     DF5  Logistic Regression                    SMOTE     9     0.989103   \n",
       "19     DF5  Logistic Regression                    SMOTE    10     0.989964   \n",
       "20     DF5  Logistic Regression     Random Under Sampler     1     0.987849   \n",
       "21     DF5  Logistic Regression     Random Under Sampler     2     0.992762   \n",
       "22     DF5  Logistic Regression     Random Under Sampler     3     0.989442   \n",
       "23     DF5  Logistic Regression     Random Under Sampler     4     0.991694   \n",
       "24     DF5  Logistic Regression     Random Under Sampler     5     0.992192   \n",
       "25     DF5  Logistic Regression     Random Under Sampler     6     0.994137   \n",
       "26     DF5  Logistic Regression     Random Under Sampler     7     0.991575   \n",
       "27     DF5  Logistic Regression     Random Under Sampler     8     0.989335   \n",
       "28     DF5  Logistic Regression     Random Under Sampler     9     0.992411   \n",
       "29     DF5  Logistic Regression     Random Under Sampler    10     0.992715   \n",
       "30     DF5  Logistic Regression      Random Over Sampler     1     0.988122   \n",
       "31     DF5  Logistic Regression      Random Over Sampler     2     0.992233   \n",
       "32     DF5  Logistic Regression      Random Over Sampler     3     0.995273   \n",
       "33     DF5  Logistic Regression      Random Over Sampler     4     0.990754   \n",
       "34     DF5  Logistic Regression      Random Over Sampler     5     0.993559   \n",
       "35     DF5  Logistic Regression      Random Over Sampler     6     0.993013   \n",
       "36     DF5  Logistic Regression      Random Over Sampler     7     0.989899   \n",
       "37     DF5  Logistic Regression      Random Over Sampler     8     0.989636   \n",
       "38     DF5  Logistic Regression      Random Over Sampler     9     0.991004   \n",
       "39     DF5  Logistic Regression      Random Over Sampler    10     0.992172   \n",
       "40     DF5  Logistic Regression                 SMOTEENN     1     0.990914   \n",
       "41     DF5  Logistic Regression                 SMOTEENN     2     0.991141   \n",
       "42     DF5  Logistic Regression                 SMOTEENN     3     0.990283   \n",
       "43     DF5  Logistic Regression                 SMOTEENN     4     0.990774   \n",
       "44     DF5  Logistic Regression                 SMOTEENN     5     0.993311   \n",
       "45     DF5  Logistic Regression                 SMOTEENN     6     0.991346   \n",
       "46     DF5  Logistic Regression                 SMOTEENN     7     0.992458   \n",
       "47     DF5  Logistic Regression                 SMOTEENN     8     0.990728   \n",
       "48     DF5  Logistic Regression                 SMOTEENN     9     0.991014   \n",
       "49     DF5  Logistic Regression                 SMOTEENN    10     0.991643   \n",
       "50     DF5  Logistic Regression               SMOTETomek     1     0.987648   \n",
       "51     DF5  Logistic Regression               SMOTETomek     2     0.987404   \n",
       "52     DF5  Logistic Regression               SMOTETomek     3     0.989471   \n",
       "53     DF5  Logistic Regression               SMOTETomek     4     0.989203   \n",
       "54     DF5  Logistic Regression               SMOTETomek     5     0.989725   \n",
       "55     DF5  Logistic Regression               SMOTETomek     6     0.989158   \n",
       "56     DF5  Logistic Regression               SMOTETomek     7     0.989955   \n",
       "57     DF5  Logistic Regression               SMOTETomek     8     0.992784   \n",
       "58     DF5  Logistic Regression               SMOTETomek     9     0.989679   \n",
       "59     DF5  Logistic Regression               SMOTETomek    10     0.991141   \n",
       "\n",
       "    precision_2  recall_1  recall_2  f1-score_1  f1-score_2  support_1  \\\n",
       "0      0.967450  0.995059  0.875614    0.987200    0.919244     3643.0   \n",
       "1      0.964286  0.994493  0.868167    0.986077    0.913706     3632.0   \n",
       "2      0.964407  0.994189  0.889062    0.987359    0.925203     3614.0   \n",
       "3      0.978151  0.996399  0.903727    0.989682    0.939467     3610.0   \n",
       "4      0.961603  0.993634  0.898596    0.987892    0.929032     3613.0   \n",
       "5      0.950000  0.991697  0.890625    0.986237    0.919355     3613.0   \n",
       "6      0.958746  0.993042  0.880303    0.985635    0.917852     3593.0   \n",
       "7      0.985025  0.997488  0.883582    0.987975    0.931550     3583.0   \n",
       "8      0.962723  0.993595  0.897281    0.987408    0.928851     3591.0   \n",
       "9      0.964706  0.994184  0.894081    0.987756    0.928052     3611.0   \n",
       "10     0.923203  0.987099  0.924714    0.987234    0.923957     3643.0   \n",
       "11     0.960265  0.993392  0.932476    0.990937    0.946166     3632.0   \n",
       "12     0.934579  0.988379  0.937500    0.988652    0.936037     3614.0   \n",
       "13     0.933126  0.988089  0.931677    0.987952    0.932401     3610.0   \n",
       "14     0.914286  0.984224  0.948518    0.987503    0.931087     3613.0   \n",
       "15     0.944186  0.990036  0.951562    0.990722    0.947860     3613.0   \n",
       "16     0.922963  0.985527  0.943939    0.987589    0.933333     3593.0   \n",
       "17     0.938235  0.988278  0.952239    0.989659    0.945185     3583.0   \n",
       "18     0.924332  0.985798  0.941088    0.987448    0.932635     3591.0   \n",
       "19     0.909910  0.983384  0.943925    0.986663    0.926606     3611.0   \n",
       "20     0.895735  0.981883  0.927987    0.984857    0.911576     3643.0   \n",
       "21     0.900302  0.981828  0.958199    0.987265    0.928349     3632.0   \n",
       "22     0.919084  0.985335  0.940625    0.987384    0.929730     3614.0   \n",
       "23     0.956386  0.992244  0.953416    0.991969    0.954899     3610.0   \n",
       "24     0.917665  0.984777  0.956318    0.988471    0.936593     3613.0   \n",
       "25     0.922504  0.985608  0.967187    0.989854    0.944317     3613.0   \n",
       "26     0.910405  0.982744  0.954545    0.987140    0.931953     3593.0   \n",
       "27     0.915942  0.983812  0.943284    0.986566    0.929412     3583.0   \n",
       "28     0.913669  0.983292  0.959215    0.987830    0.935888     3591.0   \n",
       "29     0.900585  0.981169  0.959502    0.986908    0.929110     3611.0   \n",
       "30     0.895899  0.981883  0.929624    0.984992    0.912450     3643.0   \n",
       "31     0.915254  0.984857  0.954984    0.988531    0.934697     3632.0   \n",
       "32     0.946809  0.990315  0.973437    0.992788    0.959938     3614.0   \n",
       "33     0.891971  0.979501  0.948758    0.985095    0.919488     3610.0   \n",
       "34     0.904832  0.982009  0.964119    0.987751    0.933535     3613.0   \n",
       "35     0.911111  0.983393  0.960938    0.988180    0.935361     3613.0   \n",
       "36     0.905660  0.981909  0.945455    0.985888    0.925130     3593.0   \n",
       "37     0.926794  0.986045  0.944776    0.987837    0.935698     3583.0   \n",
       "38     0.905172  0.981621  0.951662    0.986290    0.927835     3591.0   \n",
       "39     0.908284  0.982830  0.956386    0.987479    0.931715     3611.0   \n",
       "40     0.929260  0.987922  0.945990    0.989416    0.937551     3643.0   \n",
       "41     0.919003  0.985683  0.948553    0.988404    0.933544     3632.0   \n",
       "42     0.927914  0.986995  0.945312    0.988636    0.936533     3614.0   \n",
       "43     0.902511  0.981717  0.948758    0.986225    0.925057     3610.0   \n",
       "44     0.926426  0.986438  0.962559    0.989863    0.944147     3613.0   \n",
       "45     0.907601  0.982840  0.951562    0.987074    0.929062     3613.0   \n",
       "46     0.940565  0.988867  0.959091    0.990659    0.949737     3593.0   \n",
       "47     0.917867  0.984092  0.950746    0.987398    0.934018     3583.0   \n",
       "48     0.910405  0.982735  0.951662    0.986857    0.930576     3591.0   \n",
       "49     0.923077  0.985876  0.953271    0.988752    0.937931     3611.0   \n",
       "50     0.926350  0.987648  0.926350    0.987648    0.926350     3643.0   \n",
       "51     0.956811  0.992841  0.926045    0.990115    0.941176     3632.0   \n",
       "52     0.933333  0.988102  0.940625    0.988786    0.936965     3614.0   \n",
       "53     0.942368  0.989751  0.939441    0.989477    0.940902     3610.0   \n",
       "54     0.924962  0.986438  0.942278    0.988079    0.933539     3613.0   \n",
       "55     0.916159  0.984777  0.939063    0.986963    0.927469     3613.0   \n",
       "56     0.932735  0.987476  0.945455    0.988714    0.939052     3593.0   \n",
       "57     0.990769  0.998325  0.961194    0.995547    0.975758     3583.0   \n",
       "58     0.935629  0.988026  0.944109    0.988852    0.939850     3591.0   \n",
       "59     0.951638  0.991415  0.950156    0.991278    0.950896     3611.0   \n",
       "\n",
       "    support_2    TP  FP   TN  FN  \n",
       "0       611.0  3625  76  535  18  \n",
       "1       622.0  3612  82  540  20  \n",
       "2       640.0  3593  71  569  21  \n",
       "3       644.0  3597  62  582  13  \n",
       "4       641.0  3590  65  576  23  \n",
       "5       640.0  3583  70  570  30  \n",
       "6       660.0  3568  79  581  25  \n",
       "7       670.0  3574  78  592   9  \n",
       "8       662.0  3568  68  594  23  \n",
       "9       642.0  3590  68  574  21  \n",
       "10      611.0  3596  46  565  47  \n",
       "11      622.0  3608  42  580  24  \n",
       "12      640.0  3572  40  600  42  \n",
       "13      644.0  3567  44  600  43  \n",
       "14      641.0  3556  33  608  57  \n",
       "15      640.0  3577  31  609  36  \n",
       "16      660.0  3541  37  623  52  \n",
       "17      670.0  3541  32  638  42  \n",
       "18      662.0  3540  39  623  51  \n",
       "19      642.0  3551  36  606  60  \n",
       "20      611.0  3577  44  567  66  \n",
       "21      622.0  3566  26  596  66  \n",
       "22      640.0  3561  38  602  53  \n",
       "23      644.0  3582  30  614  28  \n",
       "24      641.0  3558  28  613  55  \n",
       "25      640.0  3561  21  619  52  \n",
       "26      660.0  3531  30  630  62  \n",
       "27      670.0  3525  38  632  58  \n",
       "28      662.0  3531  27  635  60  \n",
       "29      642.0  3543  26  616  68  \n",
       "30      611.0  3577  43  568  66  \n",
       "31      622.0  3577  28  594  55  \n",
       "32      640.0  3579  17  623  35  \n",
       "33      644.0  3536  33  611  74  \n",
       "34      641.0  3548  23  618  65  \n",
       "35      640.0  3553  25  615  60  \n",
       "36      660.0  3528  36  624  65  \n",
       "37      670.0  3533  37  633  50  \n",
       "38      662.0  3525  32  630  66  \n",
       "39      642.0  3549  28  614  62  \n",
       "40      611.0  3599  33  578  44  \n",
       "41      622.0  3580  32  590  52  \n",
       "42      640.0  3567  35  605  47  \n",
       "43      644.0  3544  33  611  66  \n",
       "44      641.0  3564  24  617  49  \n",
       "45      640.0  3551  31  609  62  \n",
       "46      660.0  3553  27  633  40  \n",
       "47      670.0  3526  33  637  57  \n",
       "48      662.0  3529  32  630  62  \n",
       "49      642.0  3560  30  612  51  \n",
       "50      611.0  3598  45  566  45  \n",
       "51      622.0  3606  46  576  26  \n",
       "52      640.0  3571  38  602  43  \n",
       "53      644.0  3573  39  605  37  \n",
       "54      641.0  3564  37  604  49  \n",
       "55      640.0  3558  39  601  55  \n",
       "56      660.0  3548  36  624  45  \n",
       "57      670.0  3577  26  644   6  \n",
       "58      662.0  3548  37  625  43  \n",
       "59      642.0  3580  32  610  31  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8905e922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame\n",
    "combined_metrics.to_csv('Output Data/Logistic Regression.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb3d2ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
