{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d2c91a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f460afa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "import numpy as np\n",
    "from pprint import pprint as pp\n",
    "import csv\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "from itertools import product\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from imblearn.pipeline import Pipeline \n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import r2_score, classification_report, confusion_matrix, accuracy_score, roc_auc_score, roc_curve, precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import homogeneity_score, silhouette_score\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import MiniBatchKMeans, DBSCAN\n",
    "import fasttext\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17e9cee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, precision_score, recall_score, f1_score, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87969209",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import FastText\n",
    "import numpy as np\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6238cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, precision_score, recall_score, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75e8fc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.combine import SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "378df2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0db62d0",
   "metadata": {},
   "source": [
    "### Retrieving the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10513ea6",
   "metadata": {},
   "source": [
    "#### DF 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc3d2069",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df7 = pd.read_csv('df7.csv')\n",
    "df8 = pd.read_csv('df8.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82ed7cb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>term</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>emp_title</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>issue_d</th>\n",
       "      <th>pymnt_plan</th>\n",
       "      <th>purpose</th>\n",
       "      <th>title</th>\n",
       "      <th>addr_state</th>\n",
       "      <th>earliest_cr_line</th>\n",
       "      <th>last_pymnt_d</th>\n",
       "      <th>next_pymnt_d</th>\n",
       "      <th>last_credit_pull_d</th>\n",
       "      <th>collections_12_mths_ex_med</th>\n",
       "      <th>acc_now_delinq</th>\n",
       "      <th>chargeoff_within_12_mths</th>\n",
       "      <th>tax_liens</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>fico_range_low</th>\n",
       "      <th>fico_range_high</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>mths_since_last_delinq</th>\n",
       "      <th>mths_since_last_record</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>revol_bal</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>total_acc</th>\n",
       "      <th>out_prncp</th>\n",
       "      <th>out_prncp_inv</th>\n",
       "      <th>total_pymnt</th>\n",
       "      <th>total_pymnt_inv</th>\n",
       "      <th>total_rec_prncp</th>\n",
       "      <th>total_rec_int</th>\n",
       "      <th>total_rec_late_fee</th>\n",
       "      <th>recoveries</th>\n",
       "      <th>collection_recovery_fee</th>\n",
       "      <th>last_pymnt_amnt</th>\n",
       "      <th>last_fico_range_high</th>\n",
       "      <th>last_fico_range_low</th>\n",
       "      <th>delinq_amnt</th>\n",
       "      <th>pub_rec_bankruptcies</th>\n",
       "      <th>target</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1077501</td>\n",
       "      <td>36months</td>\n",
       "      <td>B</td>\n",
       "      <td>B2</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>10</td>\n",
       "      <td>RENT</td>\n",
       "      <td>Verified</td>\n",
       "      <td>2011</td>\n",
       "      <td>False</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>Computer</td>\n",
       "      <td>AZ</td>\n",
       "      <td>1985</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>C0Q1</td>\n",
       "      <td>C1Q1</td>\n",
       "      <td>C2Q2</td>\n",
       "      <td>C3Q3</td>\n",
       "      <td>C4Q2</td>\n",
       "      <td>C5Q0</td>\n",
       "      <td>C6Q7</td>\n",
       "      <td>C7Q9</td>\n",
       "      <td>C8Q0</td>\n",
       "      <td>C9Q7</td>\n",
       "      <td>C10Q7</td>\n",
       "      <td>C11Q0</td>\n",
       "      <td>C12Q3</td>\n",
       "      <td>C13Q0</td>\n",
       "      <td>C14Q0</td>\n",
       "      <td>C15Q0</td>\n",
       "      <td>C16Q6</td>\n",
       "      <td>C17Q8</td>\n",
       "      <td>C18Q0</td>\n",
       "      <td>C19Q0</td>\n",
       "      <td>C20Q0</td>\n",
       "      <td>C21Q2</td>\n",
       "      <td>C22Q3</td>\n",
       "      <td>C23Q2</td>\n",
       "      <td>C24Q3</td>\n",
       "      <td>C25Q0</td>\n",
       "      <td>C26Q0</td>\n",
       "      <td>C27Q0</td>\n",
       "      <td>C28Q1</td>\n",
       "      <td>C29Q7</td>\n",
       "      <td>C30Q7</td>\n",
       "      <td>C31Q0</td>\n",
       "      <td>C32Q0</td>\n",
       "      <td>__label__1</td>\n",
       "      <td>__label__1 1077501 36months B B2 Unknown 10  R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1077430</td>\n",
       "      <td>60months</td>\n",
       "      <td>C</td>\n",
       "      <td>C4</td>\n",
       "      <td>Ryder</td>\n",
       "      <td>1</td>\n",
       "      <td>RENT</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>2011</td>\n",
       "      <td>False</td>\n",
       "      <td>car</td>\n",
       "      <td>bike</td>\n",
       "      <td>GA</td>\n",
       "      <td>1999</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>C0Q0</td>\n",
       "      <td>C1Q0</td>\n",
       "      <td>C2Q0</td>\n",
       "      <td>C3Q7</td>\n",
       "      <td>C4Q0</td>\n",
       "      <td>C5Q0</td>\n",
       "      <td>C6Q3</td>\n",
       "      <td>C7Q0</td>\n",
       "      <td>C8Q0</td>\n",
       "      <td>C9Q7</td>\n",
       "      <td>C10Q7</td>\n",
       "      <td>C11Q3</td>\n",
       "      <td>C12Q3</td>\n",
       "      <td>C13Q0</td>\n",
       "      <td>C14Q0</td>\n",
       "      <td>C15Q0</td>\n",
       "      <td>C16Q1</td>\n",
       "      <td>C17Q1</td>\n",
       "      <td>C18Q0</td>\n",
       "      <td>C19Q0</td>\n",
       "      <td>C20Q0</td>\n",
       "      <td>C21Q0</td>\n",
       "      <td>C22Q0</td>\n",
       "      <td>C23Q0</td>\n",
       "      <td>C24Q1</td>\n",
       "      <td>C25Q0</td>\n",
       "      <td>C26Q1</td>\n",
       "      <td>C27Q1</td>\n",
       "      <td>C28Q1</td>\n",
       "      <td>C29Q0</td>\n",
       "      <td>C30Q0</td>\n",
       "      <td>C31Q0</td>\n",
       "      <td>C32Q0</td>\n",
       "      <td>__label__2</td>\n",
       "      <td>__label__2 1077430 60months C C4 Ryder  1  REN...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id      term grade sub_grade emp_title  emp_length home_ownership  \\\n",
       "0  1077501  36months     B        B2   Unknown          10           RENT   \n",
       "1  1077430  60months     C        C4     Ryder           1           RENT   \n",
       "\n",
       "  verification_status  issue_d  pymnt_plan      purpose     title addr_state  \\\n",
       "0            Verified     2011       False  credit_card  Computer         AZ   \n",
       "1     Source Verified     2011       False          car      bike         GA   \n",
       "\n",
       "   earliest_cr_line  last_pymnt_d  next_pymnt_d  last_credit_pull_d  \\\n",
       "0              1985          2015             0                2016   \n",
       "1              1999          2013             0                2016   \n",
       "\n",
       "   collections_12_mths_ex_med  acc_now_delinq  chargeoff_within_12_mths  \\\n",
       "0                       False           False                     False   \n",
       "1                       False           False                     False   \n",
       "\n",
       "   tax_liens loan_amnt funded_amnt funded_amnt_inv int_rate installment  \\\n",
       "0      False      C0Q1        C1Q1            C2Q2     C3Q3        C4Q2   \n",
       "1      False      C0Q0        C1Q0            C2Q0     C3Q7        C4Q0   \n",
       "\n",
       "  annual_inc zip_code   dti delinq_2yrs fico_range_low fico_range_high  \\\n",
       "0       C5Q0     C6Q7  C7Q9        C8Q0           C9Q7           C10Q7   \n",
       "1       C5Q0     C6Q3  C7Q0        C8Q0           C9Q7           C10Q7   \n",
       "\n",
       "  inq_last_6mths mths_since_last_delinq mths_since_last_record open_acc  \\\n",
       "0          C11Q0                  C12Q3                  C13Q0    C14Q0   \n",
       "1          C11Q3                  C12Q3                  C13Q0    C14Q0   \n",
       "\n",
       "  pub_rec revol_bal revol_util total_acc out_prncp out_prncp_inv total_pymnt  \\\n",
       "0   C15Q0     C16Q6      C17Q8     C18Q0     C19Q0         C20Q0       C21Q2   \n",
       "1   C15Q0     C16Q1      C17Q1     C18Q0     C19Q0         C20Q0       C21Q0   \n",
       "\n",
       "  total_pymnt_inv total_rec_prncp total_rec_int total_rec_late_fee recoveries  \\\n",
       "0           C22Q3           C23Q2         C24Q3              C25Q0      C26Q0   \n",
       "1           C22Q0           C23Q0         C24Q1              C25Q0      C26Q1   \n",
       "\n",
       "  collection_recovery_fee last_pymnt_amnt last_fico_range_high  \\\n",
       "0                   C27Q0           C28Q1                C29Q7   \n",
       "1                   C27Q1           C28Q1                C29Q0   \n",
       "\n",
       "  last_fico_range_low delinq_amnt pub_rec_bankruptcies      target  \\\n",
       "0               C30Q7       C31Q0                C32Q0  __label__1   \n",
       "1               C30Q0       C31Q0                C32Q0  __label__2   \n",
       "\n",
       "                                             content  \n",
       "0  __label__1 1077501 36months B B2 Unknown 10  R...  \n",
       "1  __label__2 1077430 60months C C4 Ryder  1  REN...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df8.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f9963f",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee0a55ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store evaluation metrics for each fold\n",
    "dataset_used = []\n",
    "model_used = []\n",
    "data_balancing_technique = []\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "conf_matrices = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "903b5377",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combined_metrics = pd.DataFrame()\n",
    "\n",
    "combined_metrics = pd.DataFrame(columns=['dataset', 'model', 'data balancing technique', 'fold', 'precision_1','precision_2','recall_1','recall_2','f1-score_1','f1-score_2','support_1','support_2','TP','FP','TN','FN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85270b07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e169c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ffc0c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e15316b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6dfe14f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'df7' is your DataFrame with features and the target column\n",
    "features = df7['content'].apply(lambda x: x.split(' ', 1)[1])  # Drop the target column to get the feature columns\n",
    "target = df7['target'].apply(lambda x: int(x.split(\"__label__\")[1]))  # Target column to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7f14978e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a486af82",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = ''.join([word for word in text if word not in string.punctuation])\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7d81808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into training and testing sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "350ac1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.apply(preprocess)\n",
    "X_test = X_test.apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b751911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40315    541691 6991370 122250 122250 122250 60months 0...\n",
       "15335    751654 9511120 25250 25250 25250 60months 0179...\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3bed0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [sentence.split() for sentence in X_train]\n",
    "    \n",
    "# Train the FastText model\n",
    "fasttext_model = FastText(sentences, vector_size=100, window=20, min_count=2, workers=4, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68dbc78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(sentence):\n",
    "        words = sentence.split()\n",
    "        words_vecs = [fasttext_model.wv[word] for word in words if word in fasttext_model.wv]\n",
    "        if len(words_vecs) == 0:\n",
    "            return np.zeros(100)\n",
    "        words_vecs = np.array(words_vecs)\n",
    "        return words_vecs.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "635427dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([vectorize(sentence) for sentence in X_train])\n",
    "X_test = np.array([vectorize(sentence) for sentence in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf165dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LinearRegression()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "069803f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "    \n",
    "y_pred = np.round(y_pred)\n",
    "    \n",
    "y_pred[y_pred <= 0] = 1\n",
    "y_pred[y_pred >= 2] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d872e316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred.round())\n",
    "precision = precision_score(y_test, y_pred.round(), average='weighted')\n",
    "recall = recall_score(y_test, y_pred.round(), average='weighted')\n",
    "f1 = f1_score(y_test, y_pred.round(), average='weighted')\n",
    "conf_matrix = confusion_matrix(y_test, y_pred.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7bf68209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.926766192547314 0.9249312897098703 0.926766192547314 0.9194314890353225 [[7194   80]\n",
      " [ 543  690]]\n"
     ]
    }
   ],
   "source": [
    "print(accuracy, precision, recall, f1, conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052cda7c",
   "metadata": {},
   "source": [
    "# Fast Text \n",
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedf6e11",
   "metadata": {},
   "source": [
    "## DF7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89f99b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "Mean Accuracy: 0.97\n",
      "Mean Precision: 0.97\n",
      "Mean Recall: 0.97\n",
      "Mean F1-Score: 0.97\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df7' is your DataFrame with features and the target column\n",
    "features = df8['content'].apply(lambda x: x.split(' ', 1)[1])  # Drop the target column to get the feature columns\n",
    "target = df8['target'].apply(lambda x: int(x.split(\"__label__\")[1]))  # Target column to predict\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = ''.join([word for word in text if word not in string.punctuation])\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "features = features.apply(preprocess)\n",
    "\n",
    "# Initialize KFold with 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    #X_train = X_train.apply(preprocess)\n",
    "    #X_test = X_test.apply(preprocess)\n",
    "\n",
    "    sentences = [sentence.split() for sentence in X_train]\n",
    "    \n",
    "    # Train the FastText model\n",
    "    fasttext_model = FastText(sentences, vector_size=100, window=20, min_count=2, workers=4, seed=42)\n",
    "    \n",
    "    def vectorize(sentence):\n",
    "        words = sentence.split()\n",
    "        words_vecs = [fasttext_model.wv[word] for word in words if word in fasttext_model.wv]\n",
    "        if len(words_vecs) == 0:\n",
    "            return np.zeros(100)\n",
    "        words_vecs = np.array(words_vecs)\n",
    "        return words_vecs.mean(axis=0)\n",
    "\n",
    "    X_train = np.array([vectorize(sentence) for sentence in X_train])\n",
    "    X_test = np.array([vectorize(sentence) for sentence in X_test])\n",
    "    \n",
    "    #clf = LogisticRegression()\n",
    "    clf = LinearRegression()\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    y_pred = np.round(y_pred)\n",
    "    \n",
    "    y_pred[y_pred <= 0] = 1\n",
    "    y_pred[y_pred >= 2] = 2\n",
    "    \n",
    "    # Model evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred.round())\n",
    "    precision = precision_score(y_test, y_pred.round(), average='weighted')\n",
    "    recall = recall_score(y_test, y_pred.round(), average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred.round(), average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred.round())\n",
    "    \n",
    "    \n",
    "    # Convert classification report to DataFrame\n",
    "    report_df = pd.DataFrame(classification_report(y_test, y_pred.round(), output_dict=True)).transpose()\n",
    "    # Convert confusion matrix to DataFrame\n",
    "    matrix_df = pd.DataFrame(confusion_matrix(y_test, y_pred.round()))\n",
    "    \n",
    "    # Extract metrics for class 1\n",
    "    metrics_1 = report_df.loc['1', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract metrics for class 2\n",
    "    metrics_2 = report_df.loc['2', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract TP, TN, FP, FN counts from the confusion matrix DataFrame\n",
    "    TP = matrix_df.loc[0, 0]\n",
    "    TN = matrix_df.loc[1, 1]\n",
    "    FP = matrix_df.loc[1, 0]\n",
    "    FN = matrix_df.loc[0, 1]\n",
    "    \n",
    "    new_metric_row = {\n",
    "    'dataset': 'DF8',\n",
    "    'model' : 'Fast Text - Linear Regression',\n",
    "    'data balancing technique' : 'None',\n",
    "    'fold' : i,\n",
    "    'precision_1': metrics_1['precision'],\n",
    "    'precision_2': metrics_2['precision'],\n",
    "    'recall_1': metrics_1['recall'],\n",
    "    'recall_2': metrics_2['recall'],\n",
    "    'f1-score_1': metrics_1['f1-score'],\n",
    "    'f1-score_2': metrics_2['f1-score'],\n",
    "    'support_1': metrics_1['support'],\n",
    "    'support_2': metrics_2['support'],\n",
    "    'TP' : TP,\n",
    "    'FP' : FP,\n",
    "    'TN' : TN,\n",
    "    'FN' : FN\n",
    "    }\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    #combined_metrics = combined_metrics.append(new_metric_row, ignore_index=True)\n",
    "    combined_metrics.loc[len(combined_metrics)] = new_metric_row\n",
    "    \n",
    "    \n",
    "    # Append evaluation metrics to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "    \n",
    "    print(i)\n",
    "\n",
    "# Calculate mean evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores) #sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = np.mean(precision_scores) #sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = np.mean(recall_scores) #sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = np.mean(f1_scores) #sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print('Mean Accuracy: {:.2f}'.format(mean_accuracy))\n",
    "print('Mean Precision: {:.2f}'.format(mean_precision))\n",
    "print('Mean Recall: {:.2f}'.format(mean_recall))\n",
    "print('Mean F1-Score: {:.2f}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5cd58d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>data balancing technique</th>\n",
       "      <th>fold</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_2</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>f1-score_1</th>\n",
       "      <th>f1-score_2</th>\n",
       "      <th>support_1</th>\n",
       "      <th>support_2</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DF7</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0.966543</td>\n",
       "      <td>0.993852</td>\n",
       "      <td>0.999177</td>\n",
       "      <td>0.793781</td>\n",
       "      <td>0.982589</td>\n",
       "      <td>0.882621</td>\n",
       "      <td>3643.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>3640</td>\n",
       "      <td>126</td>\n",
       "      <td>485</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DF7</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>0.970848</td>\n",
       "      <td>0.996117</td>\n",
       "      <td>0.999449</td>\n",
       "      <td>0.824759</td>\n",
       "      <td>0.984941</td>\n",
       "      <td>0.902375</td>\n",
       "      <td>3632.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>3630</td>\n",
       "      <td>109</td>\n",
       "      <td>513</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DF7</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.996101</td>\n",
       "      <td>0.999447</td>\n",
       "      <td>0.798438</td>\n",
       "      <td>0.982189</td>\n",
       "      <td>0.886383</td>\n",
       "      <td>3614.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3612</td>\n",
       "      <td>129</td>\n",
       "      <td>511</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DF7</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>0.964696</td>\n",
       "      <td>0.994175</td>\n",
       "      <td>0.999169</td>\n",
       "      <td>0.795031</td>\n",
       "      <td>0.981630</td>\n",
       "      <td>0.883520</td>\n",
       "      <td>3610.0</td>\n",
       "      <td>644.0</td>\n",
       "      <td>3607</td>\n",
       "      <td>132</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DF7</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>0.968842</td>\n",
       "      <td>0.988701</td>\n",
       "      <td>0.998339</td>\n",
       "      <td>0.819033</td>\n",
       "      <td>0.983370</td>\n",
       "      <td>0.895904</td>\n",
       "      <td>3613.0</td>\n",
       "      <td>641.0</td>\n",
       "      <td>3607</td>\n",
       "      <td>116</td>\n",
       "      <td>525</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DF7</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>0.975128</td>\n",
       "      <td>0.989170</td>\n",
       "      <td>0.998339</td>\n",
       "      <td>0.856250</td>\n",
       "      <td>0.986597</td>\n",
       "      <td>0.917923</td>\n",
       "      <td>3613.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3607</td>\n",
       "      <td>92</td>\n",
       "      <td>548</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DF7</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>7</td>\n",
       "      <td>0.965823</td>\n",
       "      <td>0.992551</td>\n",
       "      <td>0.998887</td>\n",
       "      <td>0.807576</td>\n",
       "      <td>0.982077</td>\n",
       "      <td>0.890560</td>\n",
       "      <td>3593.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3589</td>\n",
       "      <td>127</td>\n",
       "      <td>533</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DF7</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>8</td>\n",
       "      <td>0.964931</td>\n",
       "      <td>0.989011</td>\n",
       "      <td>0.998325</td>\n",
       "      <td>0.805970</td>\n",
       "      <td>0.981344</td>\n",
       "      <td>0.888158</td>\n",
       "      <td>3583.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>3577</td>\n",
       "      <td>130</td>\n",
       "      <td>540</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DF7</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>9</td>\n",
       "      <td>0.964247</td>\n",
       "      <td>0.992495</td>\n",
       "      <td>0.998886</td>\n",
       "      <td>0.799094</td>\n",
       "      <td>0.981261</td>\n",
       "      <td>0.885356</td>\n",
       "      <td>3591.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>3587</td>\n",
       "      <td>133</td>\n",
       "      <td>529</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DF7</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.969884</td>\n",
       "      <td>0.992509</td>\n",
       "      <td>0.998892</td>\n",
       "      <td>0.825545</td>\n",
       "      <td>0.984175</td>\n",
       "      <td>0.901361</td>\n",
       "      <td>3611.0</td>\n",
       "      <td>642.0</td>\n",
       "      <td>3607</td>\n",
       "      <td>112</td>\n",
       "      <td>530</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset                          model data balancing technique  fold  \\\n",
       "0     DF7  Fast Text - Linear Regression                     None     1   \n",
       "1     DF7  Fast Text - Linear Regression                     None     2   \n",
       "2     DF7  Fast Text - Linear Regression                     None     3   \n",
       "3     DF7  Fast Text - Linear Regression                     None     4   \n",
       "4     DF7  Fast Text - Linear Regression                     None     5   \n",
       "5     DF7  Fast Text - Linear Regression                     None     6   \n",
       "6     DF7  Fast Text - Linear Regression                     None     7   \n",
       "7     DF7  Fast Text - Linear Regression                     None     8   \n",
       "8     DF7  Fast Text - Linear Regression                     None     9   \n",
       "9     DF7  Fast Text - Linear Regression                     None    10   \n",
       "\n",
       "   precision_1  precision_2  recall_1  recall_2  f1-score_1  f1-score_2  \\\n",
       "0     0.966543     0.993852  0.999177  0.793781    0.982589    0.882621   \n",
       "1     0.970848     0.996117  0.999449  0.824759    0.984941    0.902375   \n",
       "2     0.965517     0.996101  0.999447  0.798438    0.982189    0.886383   \n",
       "3     0.964696     0.994175  0.999169  0.795031    0.981630    0.883520   \n",
       "4     0.968842     0.988701  0.998339  0.819033    0.983370    0.895904   \n",
       "5     0.975128     0.989170  0.998339  0.856250    0.986597    0.917923   \n",
       "6     0.965823     0.992551  0.998887  0.807576    0.982077    0.890560   \n",
       "7     0.964931     0.989011  0.998325  0.805970    0.981344    0.888158   \n",
       "8     0.964247     0.992495  0.998886  0.799094    0.981261    0.885356   \n",
       "9     0.969884     0.992509  0.998892  0.825545    0.984175    0.901361   \n",
       "\n",
       "   support_1  support_2    TP   FP   TN  FN  \n",
       "0     3643.0      611.0  3640  126  485   3  \n",
       "1     3632.0      622.0  3630  109  513   2  \n",
       "2     3614.0      640.0  3612  129  511   2  \n",
       "3     3610.0      644.0  3607  132  512   3  \n",
       "4     3613.0      641.0  3607  116  525   6  \n",
       "5     3613.0      640.0  3607   92  548   6  \n",
       "6     3593.0      660.0  3589  127  533   4  \n",
       "7     3583.0      670.0  3577  130  540   6  \n",
       "8     3591.0      662.0  3587  133  529   4  \n",
       "9     3611.0      642.0  3607  112  530   4  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_metrics[(combined_metrics['data balancing technique'] == 'None') & (combined_metrics['dataset'] == 'DF7')]#.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737bdf77",
   "metadata": {},
   "source": [
    "### FastText Linear Regression with df7 data and imbalance data tackling (RandomUnderSampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21b575ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "Mean Accuracy: 0.96\n",
      "Mean Precision: 0.96\n",
      "Mean Recall: 0.96\n",
      "Mean F1-Score: 0.96\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df7' is your DataFrame with features and the target column\n",
    "features = df8['content'].apply(lambda x: x.split(' ', 1)[1])  # Drop the target column to get the feature columns\n",
    "target = df8['target'].apply(lambda x: int(x.split(\"__label__\")[1]))  # Target column to predict\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = ''.join([word for word in text if word not in string.punctuation])\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "features = features.apply(preprocess)\n",
    "\n",
    "# Initialize KFold with 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    #X_train = X_train.apply(preprocess)\n",
    "    #X_test = X_test.apply(preprocess)\n",
    "\n",
    "    sentences = [sentence.split() for sentence in X_train]\n",
    "    \n",
    "    # Train the FastText model\n",
    "    fasttext_model = FastText(sentences, vector_size=100, window=20, min_count=2, workers=4, seed=42)\n",
    "    \n",
    "    def vectorize(sentence):\n",
    "        words = sentence.split()\n",
    "        words_vecs = [fasttext_model.wv[word] for word in words if word in fasttext_model.wv]\n",
    "        if len(words_vecs) == 0:\n",
    "            return np.zeros(100)\n",
    "        words_vecs = np.array(words_vecs)\n",
    "        return words_vecs.mean(axis=0)\n",
    "\n",
    "    X_train = np.array([vectorize(sentence) for sentence in X_train])\n",
    "    X_test = np.array([vectorize(sentence) for sentence in X_test])\n",
    "    \n",
    "    # Apply random undersampling\n",
    "    rus = RandomUnderSampler(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)\n",
    "    \n",
    "    #clf = LogisticRegression()\n",
    "    clf = LinearRegression()\n",
    "    clf.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Apply random undersampling to test data\n",
    "    X_test_resampled, y_test_resampled = rus.fit_resample(X_test, y_test)\n",
    "    \n",
    "    y_pred = clf.predict(X_test_resampled)\n",
    "    \n",
    "    y_pred = np.round(y_pred)\n",
    "    \n",
    "    y_pred[y_pred <= 0] = 1\n",
    "    y_pred[y_pred >= 2] = 2\n",
    "    \n",
    "    # Model evaluation\n",
    "    accuracy = accuracy_score(y_test_resampled, y_pred.round())\n",
    "    precision = precision_score(y_test_resampled, y_pred.round(), average='weighted')\n",
    "    recall = recall_score(y_test_resampled, y_pred.round(), average='weighted')\n",
    "    f1 = f1_score(y_test_resampled, y_pred.round(), average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test_resampled, y_pred.round())\n",
    "    \n",
    "    # Convert classification report to DataFrame\n",
    "    report_df = pd.DataFrame(classification_report(y_test_resampled, y_pred.round(), output_dict=True)).transpose()\n",
    "    # Convert confusion matrix to DataFrame\n",
    "    matrix_df = pd.DataFrame(confusion_matrix(y_test_resampled, y_pred.round()))\n",
    "    \n",
    "    # Extract metrics for class 1\n",
    "    metrics_1 = report_df.loc['1', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract metrics for class 2\n",
    "    metrics_2 = report_df.loc['2', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract TP, TN, FP, FN counts from the confusion matrix DataFrame\n",
    "    TP = matrix_df.loc[0, 0]\n",
    "    TN = matrix_df.loc[1, 1]\n",
    "    FP = matrix_df.loc[1, 0]\n",
    "    FN = matrix_df.loc[0, 1]\n",
    "    \n",
    "    new_metric_row = {\n",
    "    'dataset': 'DF8',\n",
    "    'model' : 'Fast Text - Linear Regression',\n",
    "    'data balancing technique' : 'Random Under Sampler',\n",
    "    'fold' : i,\n",
    "    'precision_1': metrics_1['precision'],\n",
    "    'precision_2': metrics_2['precision'],\n",
    "    'recall_1': metrics_1['recall'],\n",
    "    'recall_2': metrics_2['recall'],\n",
    "    'f1-score_1': metrics_1['f1-score'],\n",
    "    'f1-score_2': metrics_2['f1-score'],\n",
    "    'support_1': metrics_1['support'],\n",
    "    'support_2': metrics_2['support'],\n",
    "    'TP' : TP,\n",
    "    'FP' : FP,\n",
    "    'TN' : TN,\n",
    "    'FN' : FN\n",
    "    }\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    #combined_metrics = combined_metrics.append(new_metric_row, ignore_index=True)\n",
    "    combined_metrics.loc[len(combined_metrics)] = new_metric_row\n",
    "    \n",
    "    \n",
    "    # Append evaluation metrics to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "    \n",
    "    print(i)\n",
    "\n",
    "# Calculate mean evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores) #sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = np.mean(precision_scores) #sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = np.mean(recall_scores) #sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = np.mean(f1_scores) #sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print('Mean Accuracy: {:.2f}'.format(mean_accuracy))\n",
    "print('Mean Precision: {:.2f}'.format(mean_precision))\n",
    "print('Mean Recall: {:.2f}'.format(mean_recall))\n",
    "print('Mean F1-Score: {:.2f}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f08b12d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>data balancing technique</th>\n",
       "      <th>fold</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_2</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>f1-score_1</th>\n",
       "      <th>f1-score_2</th>\n",
       "      <th>support_1</th>\n",
       "      <th>support_2</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>1</td>\n",
       "      <td>0.917051</td>\n",
       "      <td>0.975482</td>\n",
       "      <td>0.977087</td>\n",
       "      <td>0.911620</td>\n",
       "      <td>0.946117</td>\n",
       "      <td>0.942470</td>\n",
       "      <td>611.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>597</td>\n",
       "      <td>54</td>\n",
       "      <td>557</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>2</td>\n",
       "      <td>0.941628</td>\n",
       "      <td>0.984823</td>\n",
       "      <td>0.985531</td>\n",
       "      <td>0.938907</td>\n",
       "      <td>0.963079</td>\n",
       "      <td>0.961317</td>\n",
       "      <td>622.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>613</td>\n",
       "      <td>38</td>\n",
       "      <td>584</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset                          model data balancing technique  fold  \\\n",
       "10     DF8  Fast Text - Linear Regression     Random Under Sampler     1   \n",
       "11     DF8  Fast Text - Linear Regression     Random Under Sampler     2   \n",
       "\n",
       "    precision_1  precision_2  recall_1  recall_2  f1-score_1  f1-score_2  \\\n",
       "10     0.917051     0.975482  0.977087  0.911620    0.946117    0.942470   \n",
       "11     0.941628     0.984823  0.985531  0.938907    0.963079    0.961317   \n",
       "\n",
       "    support_1  support_2   TP  FP   TN  FN  \n",
       "10      611.0      611.0  597  54  557  14  \n",
       "11      622.0      622.0  613  38  584   9  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_metrics[(combined_metrics['data balancing technique'] == 'Random Under Sampler') & (combined_metrics['dataset'] == 'DF8')].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc10646",
   "metadata": {},
   "source": [
    "### FastText Linear Regression with df7 data and imbalance data tackling (RandomOverSampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c500a1fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "Mean Accuracy: 0.96\n",
      "Mean Precision: 0.96\n",
      "Mean Recall: 0.96\n",
      "Mean F1-Score: 0.96\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df7' is your DataFrame with features and the target column\n",
    "features = df8['content'].apply(lambda x: x.split(' ', 1)[1])  # Drop the target column to get the feature columns\n",
    "target = df8['target'].apply(lambda x: int(x.split(\"__label__\")[1]))  # Target column to predict\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = ''.join([word for word in text if word not in string.punctuation])\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "features = features.apply(preprocess)\n",
    "\n",
    "# Initialize KFold with 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    #X_train = X_train.apply(preprocess)\n",
    "    #X_test = X_test.apply(preprocess)\n",
    "\n",
    "    sentences = [sentence.split() for sentence in X_train]\n",
    "    \n",
    "    # Train the FastText model\n",
    "    fasttext_model = FastText(sentences, vector_size=100, window=20, min_count=2, workers=4, seed=42)\n",
    "    \n",
    "    def vectorize(sentence):\n",
    "        words = sentence.split()\n",
    "        words_vecs = [fasttext_model.wv[word] for word in words if word in fasttext_model.wv]\n",
    "        if len(words_vecs) == 0:\n",
    "            return np.zeros(100)\n",
    "        words_vecs = np.array(words_vecs)\n",
    "        return words_vecs.mean(axis=0)\n",
    "\n",
    "    X_train = np.array([vectorize(sentence) for sentence in X_train])\n",
    "    X_test = np.array([vectorize(sentence) for sentence in X_test])\n",
    "    \n",
    "    # Apply random undersampling\n",
    "    ros = RandomOverSampler(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
    "    \n",
    "    #clf = LogisticRegression()\n",
    "    clf = LinearRegression()\n",
    "    clf.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Apply random undersampling to test data\n",
    "    X_test_resampled, y_test_resampled = rus.fit_resample(X_test, y_test)\n",
    "    \n",
    "    y_pred = clf.predict(X_test_resampled)\n",
    "    \n",
    "    y_pred = np.round(y_pred)\n",
    "    \n",
    "    y_pred[y_pred <= 0] = 1\n",
    "    y_pred[y_pred >= 2] = 2\n",
    "    \n",
    "    # Model evaluation\n",
    "    accuracy = accuracy_score(y_test_resampled, y_pred.round())\n",
    "    precision = precision_score(y_test_resampled, y_pred.round(), average='weighted')\n",
    "    recall = recall_score(y_test_resampled, y_pred.round(), average='weighted')\n",
    "    f1 = f1_score(y_test_resampled, y_pred.round(), average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test_resampled, y_pred.round())\n",
    "    \n",
    "    # Convert classification report to DataFrame\n",
    "    report_df = pd.DataFrame(classification_report(y_test_resampled, y_pred.round(), output_dict=True)).transpose()\n",
    "    # Convert confusion matrix to DataFrame\n",
    "    matrix_df = pd.DataFrame(confusion_matrix(y_test_resampled, y_pred.round()))\n",
    "    \n",
    "    # Extract metrics for class 1\n",
    "    metrics_1 = report_df.loc['1', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract metrics for class 2\n",
    "    metrics_2 = report_df.loc['2', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract TP, TN, FP, FN counts from the confusion matrix DataFrame\n",
    "    TP = matrix_df.loc[0, 0]\n",
    "    TN = matrix_df.loc[1, 1]\n",
    "    FP = matrix_df.loc[1, 0]\n",
    "    FN = matrix_df.loc[0, 1]\n",
    "    \n",
    "    new_metric_row = {\n",
    "    'dataset': 'DF7',\n",
    "    'model' : 'Fast Text - Linear Regression',\n",
    "    'data balancing technique' : 'Random Over Sampler',\n",
    "    'fold' : i,\n",
    "    'precision_1': metrics_1['precision'],\n",
    "    'precision_2': metrics_2['precision'],\n",
    "    'recall_1': metrics_1['recall'],\n",
    "    'recall_2': metrics_2['recall'],\n",
    "    'f1-score_1': metrics_1['f1-score'],\n",
    "    'f1-score_2': metrics_2['f1-score'],\n",
    "    'support_1': metrics_1['support'],\n",
    "    'support_2': metrics_2['support'],\n",
    "    'TP' : TP,\n",
    "    'FP' : FP,\n",
    "    'TN' : TN,\n",
    "    'FN' : FN\n",
    "    }\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    #combined_metrics = combined_metrics.append(new_metric_row, ignore_index=True)\n",
    "    combined_metrics.loc[len(combined_metrics)] = new_metric_row\n",
    "    \n",
    "    \n",
    "    # Append evaluation metrics to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "    \n",
    "    print(i)\n",
    "\n",
    "# Calculate mean evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores) #sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = np.mean(precision_scores) #sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = np.mean(recall_scores) #sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = np.mean(f1_scores) #sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print('Mean Accuracy: {:.2f}'.format(mean_accuracy))\n",
    "print('Mean Precision: {:.2f}'.format(mean_precision))\n",
    "print('Mean Recall: {:.2f}'.format(mean_recall))\n",
    "print('Mean F1-Score: {:.2f}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca7e58c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>data balancing technique</th>\n",
       "      <th>fold</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_2</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>f1-score_1</th>\n",
       "      <th>f1-score_2</th>\n",
       "      <th>support_1</th>\n",
       "      <th>support_2</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>DF7</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>1</td>\n",
       "      <td>0.920437</td>\n",
       "      <td>0.963855</td>\n",
       "      <td>0.965630</td>\n",
       "      <td>0.916530</td>\n",
       "      <td>0.942492</td>\n",
       "      <td>0.939597</td>\n",
       "      <td>611.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>590</td>\n",
       "      <td>51</td>\n",
       "      <td>560</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>DF7</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>2</td>\n",
       "      <td>0.945312</td>\n",
       "      <td>0.971854</td>\n",
       "      <td>0.972669</td>\n",
       "      <td>0.943730</td>\n",
       "      <td>0.958796</td>\n",
       "      <td>0.957586</td>\n",
       "      <td>622.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>605</td>\n",
       "      <td>35</td>\n",
       "      <td>587</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>DF7</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>3</td>\n",
       "      <td>0.935917</td>\n",
       "      <td>0.980296</td>\n",
       "      <td>0.981250</td>\n",
       "      <td>0.932813</td>\n",
       "      <td>0.958047</td>\n",
       "      <td>0.955965</td>\n",
       "      <td>640.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>628</td>\n",
       "      <td>43</td>\n",
       "      <td>597</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>DF7</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>4</td>\n",
       "      <td>0.919708</td>\n",
       "      <td>0.976783</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.914596</td>\n",
       "      <td>0.948081</td>\n",
       "      <td>0.944667</td>\n",
       "      <td>644.0</td>\n",
       "      <td>644.0</td>\n",
       "      <td>630</td>\n",
       "      <td>55</td>\n",
       "      <td>589</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>DF7</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>5</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.982839</td>\n",
       "      <td>0.943838</td>\n",
       "      <td>0.964040</td>\n",
       "      <td>0.962609</td>\n",
       "      <td>641.0</td>\n",
       "      <td>641.0</td>\n",
       "      <td>630</td>\n",
       "      <td>36</td>\n",
       "      <td>605</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>DF7</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>6</td>\n",
       "      <td>0.948092</td>\n",
       "      <td>0.969600</td>\n",
       "      <td>0.970313</td>\n",
       "      <td>0.946875</td>\n",
       "      <td>0.959073</td>\n",
       "      <td>0.958103</td>\n",
       "      <td>640.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>621</td>\n",
       "      <td>34</td>\n",
       "      <td>606</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>DF7</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>7</td>\n",
       "      <td>0.931232</td>\n",
       "      <td>0.983923</td>\n",
       "      <td>0.984848</td>\n",
       "      <td>0.927273</td>\n",
       "      <td>0.957290</td>\n",
       "      <td>0.954758</td>\n",
       "      <td>660.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>650</td>\n",
       "      <td>48</td>\n",
       "      <td>612</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>DF7</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>8</td>\n",
       "      <td>0.924394</td>\n",
       "      <td>0.965571</td>\n",
       "      <td>0.967164</td>\n",
       "      <td>0.920896</td>\n",
       "      <td>0.945295</td>\n",
       "      <td>0.942704</td>\n",
       "      <td>670.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>648</td>\n",
       "      <td>53</td>\n",
       "      <td>617</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>DF7</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>9</td>\n",
       "      <td>0.924747</td>\n",
       "      <td>0.963665</td>\n",
       "      <td>0.965257</td>\n",
       "      <td>0.921450</td>\n",
       "      <td>0.944568</td>\n",
       "      <td>0.942085</td>\n",
       "      <td>662.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>639</td>\n",
       "      <td>52</td>\n",
       "      <td>610</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>DF7</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>10</td>\n",
       "      <td>0.919881</td>\n",
       "      <td>0.963934</td>\n",
       "      <td>0.965732</td>\n",
       "      <td>0.915888</td>\n",
       "      <td>0.942249</td>\n",
       "      <td>0.939297</td>\n",
       "      <td>642.0</td>\n",
       "      <td>642.0</td>\n",
       "      <td>620</td>\n",
       "      <td>54</td>\n",
       "      <td>588</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset                          model data balancing technique  fold  \\\n",
       "20     DF7  Fast Text - Linear Regression      Random Over Sampler     1   \n",
       "21     DF7  Fast Text - Linear Regression      Random Over Sampler     2   \n",
       "22     DF7  Fast Text - Linear Regression      Random Over Sampler     3   \n",
       "23     DF7  Fast Text - Linear Regression      Random Over Sampler     4   \n",
       "24     DF7  Fast Text - Linear Regression      Random Over Sampler     5   \n",
       "25     DF7  Fast Text - Linear Regression      Random Over Sampler     6   \n",
       "26     DF7  Fast Text - Linear Regression      Random Over Sampler     7   \n",
       "27     DF7  Fast Text - Linear Regression      Random Over Sampler     8   \n",
       "28     DF7  Fast Text - Linear Regression      Random Over Sampler     9   \n",
       "29     DF7  Fast Text - Linear Regression      Random Over Sampler    10   \n",
       "\n",
       "    precision_1  precision_2  recall_1  recall_2  f1-score_1  f1-score_2  \\\n",
       "20     0.920437     0.963855  0.965630  0.916530    0.942492    0.939597   \n",
       "21     0.945312     0.971854  0.972669  0.943730    0.958796    0.957586   \n",
       "22     0.935917     0.980296  0.981250  0.932813    0.958047    0.955965   \n",
       "23     0.919708     0.976783  0.978261  0.914596    0.948081    0.944667   \n",
       "24     0.945946     0.982143  0.982839  0.943838    0.964040    0.962609   \n",
       "25     0.948092     0.969600  0.970313  0.946875    0.959073    0.958103   \n",
       "26     0.931232     0.983923  0.984848  0.927273    0.957290    0.954758   \n",
       "27     0.924394     0.965571  0.967164  0.920896    0.945295    0.942704   \n",
       "28     0.924747     0.963665  0.965257  0.921450    0.944568    0.942085   \n",
       "29     0.919881     0.963934  0.965732  0.915888    0.942249    0.939297   \n",
       "\n",
       "    support_1  support_2   TP  FP   TN  FN  \n",
       "20      611.0      611.0  590  51  560  21  \n",
       "21      622.0      622.0  605  35  587  17  \n",
       "22      640.0      640.0  628  43  597  12  \n",
       "23      644.0      644.0  630  55  589  14  \n",
       "24      641.0      641.0  630  36  605  11  \n",
       "25      640.0      640.0  621  34  606  19  \n",
       "26      660.0      660.0  650  48  612  10  \n",
       "27      670.0      670.0  648  53  617  22  \n",
       "28      662.0      662.0  639  52  610  23  \n",
       "29      642.0      642.0  620  54  588  22  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_metrics[(combined_metrics['data balancing technique'] == 'Random Over Sampler') & (combined_metrics['dataset'] == 'DF7')]#.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd948ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace values 'DF7' with 'DF8' in the 'dataset' column\n",
    "combined_metrics['dataset'] = combined_metrics['dataset'].replace('DF7', 'DF8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4b04f0",
   "metadata": {},
   "source": [
    "## Performance metrics for the Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1158fa25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>data balancing technique</th>\n",
       "      <th>fold</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_2</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>f1-score_1</th>\n",
       "      <th>f1-score_2</th>\n",
       "      <th>support_1</th>\n",
       "      <th>support_2</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0.966543</td>\n",
       "      <td>0.993852</td>\n",
       "      <td>0.999177</td>\n",
       "      <td>0.793781</td>\n",
       "      <td>0.982589</td>\n",
       "      <td>0.882621</td>\n",
       "      <td>3643.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>3640</td>\n",
       "      <td>126</td>\n",
       "      <td>485</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>0.970848</td>\n",
       "      <td>0.996117</td>\n",
       "      <td>0.999449</td>\n",
       "      <td>0.824759</td>\n",
       "      <td>0.984941</td>\n",
       "      <td>0.902375</td>\n",
       "      <td>3632.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>3630</td>\n",
       "      <td>109</td>\n",
       "      <td>513</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.996101</td>\n",
       "      <td>0.999447</td>\n",
       "      <td>0.798438</td>\n",
       "      <td>0.982189</td>\n",
       "      <td>0.886383</td>\n",
       "      <td>3614.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3612</td>\n",
       "      <td>129</td>\n",
       "      <td>511</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>0.964696</td>\n",
       "      <td>0.994175</td>\n",
       "      <td>0.999169</td>\n",
       "      <td>0.795031</td>\n",
       "      <td>0.981630</td>\n",
       "      <td>0.883520</td>\n",
       "      <td>3610.0</td>\n",
       "      <td>644.0</td>\n",
       "      <td>3607</td>\n",
       "      <td>132</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>0.968842</td>\n",
       "      <td>0.988701</td>\n",
       "      <td>0.998339</td>\n",
       "      <td>0.819033</td>\n",
       "      <td>0.983370</td>\n",
       "      <td>0.895904</td>\n",
       "      <td>3613.0</td>\n",
       "      <td>641.0</td>\n",
       "      <td>3607</td>\n",
       "      <td>116</td>\n",
       "      <td>525</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>0.975128</td>\n",
       "      <td>0.989170</td>\n",
       "      <td>0.998339</td>\n",
       "      <td>0.856250</td>\n",
       "      <td>0.986597</td>\n",
       "      <td>0.917923</td>\n",
       "      <td>3613.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3607</td>\n",
       "      <td>92</td>\n",
       "      <td>548</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>7</td>\n",
       "      <td>0.965823</td>\n",
       "      <td>0.992551</td>\n",
       "      <td>0.998887</td>\n",
       "      <td>0.807576</td>\n",
       "      <td>0.982077</td>\n",
       "      <td>0.890560</td>\n",
       "      <td>3593.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3589</td>\n",
       "      <td>127</td>\n",
       "      <td>533</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>8</td>\n",
       "      <td>0.964931</td>\n",
       "      <td>0.989011</td>\n",
       "      <td>0.998325</td>\n",
       "      <td>0.805970</td>\n",
       "      <td>0.981344</td>\n",
       "      <td>0.888158</td>\n",
       "      <td>3583.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>3577</td>\n",
       "      <td>130</td>\n",
       "      <td>540</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>9</td>\n",
       "      <td>0.964247</td>\n",
       "      <td>0.992495</td>\n",
       "      <td>0.998886</td>\n",
       "      <td>0.799094</td>\n",
       "      <td>0.981261</td>\n",
       "      <td>0.885356</td>\n",
       "      <td>3591.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>3587</td>\n",
       "      <td>133</td>\n",
       "      <td>529</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.969884</td>\n",
       "      <td>0.992509</td>\n",
       "      <td>0.998892</td>\n",
       "      <td>0.825545</td>\n",
       "      <td>0.984175</td>\n",
       "      <td>0.901361</td>\n",
       "      <td>3611.0</td>\n",
       "      <td>642.0</td>\n",
       "      <td>3607</td>\n",
       "      <td>112</td>\n",
       "      <td>530</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>1</td>\n",
       "      <td>0.917051</td>\n",
       "      <td>0.975482</td>\n",
       "      <td>0.977087</td>\n",
       "      <td>0.911620</td>\n",
       "      <td>0.946117</td>\n",
       "      <td>0.942470</td>\n",
       "      <td>611.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>597</td>\n",
       "      <td>54</td>\n",
       "      <td>557</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>2</td>\n",
       "      <td>0.941628</td>\n",
       "      <td>0.984823</td>\n",
       "      <td>0.985531</td>\n",
       "      <td>0.938907</td>\n",
       "      <td>0.963079</td>\n",
       "      <td>0.961317</td>\n",
       "      <td>622.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>613</td>\n",
       "      <td>38</td>\n",
       "      <td>584</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>3</td>\n",
       "      <td>0.945455</td>\n",
       "      <td>0.974194</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.943750</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.958730</td>\n",
       "      <td>640.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>624</td>\n",
       "      <td>36</td>\n",
       "      <td>604</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>4</td>\n",
       "      <td>0.918129</td>\n",
       "      <td>0.973510</td>\n",
       "      <td>0.975155</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.945783</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>644.0</td>\n",
       "      <td>644.0</td>\n",
       "      <td>628</td>\n",
       "      <td>56</td>\n",
       "      <td>588</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>5</td>\n",
       "      <td>0.943683</td>\n",
       "      <td>0.966400</td>\n",
       "      <td>0.967239</td>\n",
       "      <td>0.942278</td>\n",
       "      <td>0.955316</td>\n",
       "      <td>0.954186</td>\n",
       "      <td>641.0</td>\n",
       "      <td>641.0</td>\n",
       "      <td>620</td>\n",
       "      <td>37</td>\n",
       "      <td>604</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>6</td>\n",
       "      <td>0.930370</td>\n",
       "      <td>0.980165</td>\n",
       "      <td>0.981250</td>\n",
       "      <td>0.926562</td>\n",
       "      <td>0.955133</td>\n",
       "      <td>0.952610</td>\n",
       "      <td>640.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>628</td>\n",
       "      <td>47</td>\n",
       "      <td>593</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>7</td>\n",
       "      <td>0.927641</td>\n",
       "      <td>0.969793</td>\n",
       "      <td>0.971212</td>\n",
       "      <td>0.924242</td>\n",
       "      <td>0.948927</td>\n",
       "      <td>0.946470</td>\n",
       "      <td>660.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>641</td>\n",
       "      <td>50</td>\n",
       "      <td>610</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>8</td>\n",
       "      <td>0.930100</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>0.973134</td>\n",
       "      <td>0.926866</td>\n",
       "      <td>0.951131</td>\n",
       "      <td>0.948816</td>\n",
       "      <td>670.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>652</td>\n",
       "      <td>49</td>\n",
       "      <td>621</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>9</td>\n",
       "      <td>0.917143</td>\n",
       "      <td>0.967949</td>\n",
       "      <td>0.969789</td>\n",
       "      <td>0.912387</td>\n",
       "      <td>0.942731</td>\n",
       "      <td>0.939347</td>\n",
       "      <td>662.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>642</td>\n",
       "      <td>58</td>\n",
       "      <td>604</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>10</td>\n",
       "      <td>0.938531</td>\n",
       "      <td>0.974068</td>\n",
       "      <td>0.975078</td>\n",
       "      <td>0.936137</td>\n",
       "      <td>0.956455</td>\n",
       "      <td>0.954726</td>\n",
       "      <td>642.0</td>\n",
       "      <td>642.0</td>\n",
       "      <td>626</td>\n",
       "      <td>41</td>\n",
       "      <td>601</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>1</td>\n",
       "      <td>0.920437</td>\n",
       "      <td>0.963855</td>\n",
       "      <td>0.965630</td>\n",
       "      <td>0.916530</td>\n",
       "      <td>0.942492</td>\n",
       "      <td>0.939597</td>\n",
       "      <td>611.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>590</td>\n",
       "      <td>51</td>\n",
       "      <td>560</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>2</td>\n",
       "      <td>0.945312</td>\n",
       "      <td>0.971854</td>\n",
       "      <td>0.972669</td>\n",
       "      <td>0.943730</td>\n",
       "      <td>0.958796</td>\n",
       "      <td>0.957586</td>\n",
       "      <td>622.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>605</td>\n",
       "      <td>35</td>\n",
       "      <td>587</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>3</td>\n",
       "      <td>0.935917</td>\n",
       "      <td>0.980296</td>\n",
       "      <td>0.981250</td>\n",
       "      <td>0.932813</td>\n",
       "      <td>0.958047</td>\n",
       "      <td>0.955965</td>\n",
       "      <td>640.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>628</td>\n",
       "      <td>43</td>\n",
       "      <td>597</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>4</td>\n",
       "      <td>0.919708</td>\n",
       "      <td>0.976783</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.914596</td>\n",
       "      <td>0.948081</td>\n",
       "      <td>0.944667</td>\n",
       "      <td>644.0</td>\n",
       "      <td>644.0</td>\n",
       "      <td>630</td>\n",
       "      <td>55</td>\n",
       "      <td>589</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>5</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.982839</td>\n",
       "      <td>0.943838</td>\n",
       "      <td>0.964040</td>\n",
       "      <td>0.962609</td>\n",
       "      <td>641.0</td>\n",
       "      <td>641.0</td>\n",
       "      <td>630</td>\n",
       "      <td>36</td>\n",
       "      <td>605</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>6</td>\n",
       "      <td>0.948092</td>\n",
       "      <td>0.969600</td>\n",
       "      <td>0.970313</td>\n",
       "      <td>0.946875</td>\n",
       "      <td>0.959073</td>\n",
       "      <td>0.958103</td>\n",
       "      <td>640.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>621</td>\n",
       "      <td>34</td>\n",
       "      <td>606</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>7</td>\n",
       "      <td>0.931232</td>\n",
       "      <td>0.983923</td>\n",
       "      <td>0.984848</td>\n",
       "      <td>0.927273</td>\n",
       "      <td>0.957290</td>\n",
       "      <td>0.954758</td>\n",
       "      <td>660.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>650</td>\n",
       "      <td>48</td>\n",
       "      <td>612</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>8</td>\n",
       "      <td>0.924394</td>\n",
       "      <td>0.965571</td>\n",
       "      <td>0.967164</td>\n",
       "      <td>0.920896</td>\n",
       "      <td>0.945295</td>\n",
       "      <td>0.942704</td>\n",
       "      <td>670.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>648</td>\n",
       "      <td>53</td>\n",
       "      <td>617</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>9</td>\n",
       "      <td>0.924747</td>\n",
       "      <td>0.963665</td>\n",
       "      <td>0.965257</td>\n",
       "      <td>0.921450</td>\n",
       "      <td>0.944568</td>\n",
       "      <td>0.942085</td>\n",
       "      <td>662.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>639</td>\n",
       "      <td>52</td>\n",
       "      <td>610</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>10</td>\n",
       "      <td>0.919881</td>\n",
       "      <td>0.963934</td>\n",
       "      <td>0.965732</td>\n",
       "      <td>0.915888</td>\n",
       "      <td>0.942249</td>\n",
       "      <td>0.939297</td>\n",
       "      <td>642.0</td>\n",
       "      <td>642.0</td>\n",
       "      <td>620</td>\n",
       "      <td>54</td>\n",
       "      <td>588</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset                          model data balancing technique  fold  \\\n",
       "0      DF8  Fast Text - Linear Regression                     None     1   \n",
       "1      DF8  Fast Text - Linear Regression                     None     2   \n",
       "2      DF8  Fast Text - Linear Regression                     None     3   \n",
       "3      DF8  Fast Text - Linear Regression                     None     4   \n",
       "4      DF8  Fast Text - Linear Regression                     None     5   \n",
       "5      DF8  Fast Text - Linear Regression                     None     6   \n",
       "6      DF8  Fast Text - Linear Regression                     None     7   \n",
       "7      DF8  Fast Text - Linear Regression                     None     8   \n",
       "8      DF8  Fast Text - Linear Regression                     None     9   \n",
       "9      DF8  Fast Text - Linear Regression                     None    10   \n",
       "10     DF8  Fast Text - Linear Regression     Random Under Sampler     1   \n",
       "11     DF8  Fast Text - Linear Regression     Random Under Sampler     2   \n",
       "12     DF8  Fast Text - Linear Regression     Random Under Sampler     3   \n",
       "13     DF8  Fast Text - Linear Regression     Random Under Sampler     4   \n",
       "14     DF8  Fast Text - Linear Regression     Random Under Sampler     5   \n",
       "15     DF8  Fast Text - Linear Regression     Random Under Sampler     6   \n",
       "16     DF8  Fast Text - Linear Regression     Random Under Sampler     7   \n",
       "17     DF8  Fast Text - Linear Regression     Random Under Sampler     8   \n",
       "18     DF8  Fast Text - Linear Regression     Random Under Sampler     9   \n",
       "19     DF8  Fast Text - Linear Regression     Random Under Sampler    10   \n",
       "20     DF8  Fast Text - Linear Regression      Random Over Sampler     1   \n",
       "21     DF8  Fast Text - Linear Regression      Random Over Sampler     2   \n",
       "22     DF8  Fast Text - Linear Regression      Random Over Sampler     3   \n",
       "23     DF8  Fast Text - Linear Regression      Random Over Sampler     4   \n",
       "24     DF8  Fast Text - Linear Regression      Random Over Sampler     5   \n",
       "25     DF8  Fast Text - Linear Regression      Random Over Sampler     6   \n",
       "26     DF8  Fast Text - Linear Regression      Random Over Sampler     7   \n",
       "27     DF8  Fast Text - Linear Regression      Random Over Sampler     8   \n",
       "28     DF8  Fast Text - Linear Regression      Random Over Sampler     9   \n",
       "29     DF8  Fast Text - Linear Regression      Random Over Sampler    10   \n",
       "\n",
       "    precision_1  precision_2  recall_1  recall_2  f1-score_1  f1-score_2  \\\n",
       "0      0.966543     0.993852  0.999177  0.793781    0.982589    0.882621   \n",
       "1      0.970848     0.996117  0.999449  0.824759    0.984941    0.902375   \n",
       "2      0.965517     0.996101  0.999447  0.798438    0.982189    0.886383   \n",
       "3      0.964696     0.994175  0.999169  0.795031    0.981630    0.883520   \n",
       "4      0.968842     0.988701  0.998339  0.819033    0.983370    0.895904   \n",
       "5      0.975128     0.989170  0.998339  0.856250    0.986597    0.917923   \n",
       "6      0.965823     0.992551  0.998887  0.807576    0.982077    0.890560   \n",
       "7      0.964931     0.989011  0.998325  0.805970    0.981344    0.888158   \n",
       "8      0.964247     0.992495  0.998886  0.799094    0.981261    0.885356   \n",
       "9      0.969884     0.992509  0.998892  0.825545    0.984175    0.901361   \n",
       "10     0.917051     0.975482  0.977087  0.911620    0.946117    0.942470   \n",
       "11     0.941628     0.984823  0.985531  0.938907    0.963079    0.961317   \n",
       "12     0.945455     0.974194  0.975000  0.943750    0.960000    0.958730   \n",
       "13     0.918129     0.973510  0.975155  0.913043    0.945783    0.942308   \n",
       "14     0.943683     0.966400  0.967239  0.942278    0.955316    0.954186   \n",
       "15     0.930370     0.980165  0.981250  0.926562    0.955133    0.952610   \n",
       "16     0.927641     0.969793  0.971212  0.924242    0.948927    0.946470   \n",
       "17     0.930100     0.971831  0.973134  0.926866    0.951131    0.948816   \n",
       "18     0.917143     0.967949  0.969789  0.912387    0.942731    0.939347   \n",
       "19     0.938531     0.974068  0.975078  0.936137    0.956455    0.954726   \n",
       "20     0.920437     0.963855  0.965630  0.916530    0.942492    0.939597   \n",
       "21     0.945312     0.971854  0.972669  0.943730    0.958796    0.957586   \n",
       "22     0.935917     0.980296  0.981250  0.932813    0.958047    0.955965   \n",
       "23     0.919708     0.976783  0.978261  0.914596    0.948081    0.944667   \n",
       "24     0.945946     0.982143  0.982839  0.943838    0.964040    0.962609   \n",
       "25     0.948092     0.969600  0.970313  0.946875    0.959073    0.958103   \n",
       "26     0.931232     0.983923  0.984848  0.927273    0.957290    0.954758   \n",
       "27     0.924394     0.965571  0.967164  0.920896    0.945295    0.942704   \n",
       "28     0.924747     0.963665  0.965257  0.921450    0.944568    0.942085   \n",
       "29     0.919881     0.963934  0.965732  0.915888    0.942249    0.939297   \n",
       "\n",
       "    support_1  support_2    TP   FP   TN  FN  \n",
       "0      3643.0      611.0  3640  126  485   3  \n",
       "1      3632.0      622.0  3630  109  513   2  \n",
       "2      3614.0      640.0  3612  129  511   2  \n",
       "3      3610.0      644.0  3607  132  512   3  \n",
       "4      3613.0      641.0  3607  116  525   6  \n",
       "5      3613.0      640.0  3607   92  548   6  \n",
       "6      3593.0      660.0  3589  127  533   4  \n",
       "7      3583.0      670.0  3577  130  540   6  \n",
       "8      3591.0      662.0  3587  133  529   4  \n",
       "9      3611.0      642.0  3607  112  530   4  \n",
       "10      611.0      611.0   597   54  557  14  \n",
       "11      622.0      622.0   613   38  584   9  \n",
       "12      640.0      640.0   624   36  604  16  \n",
       "13      644.0      644.0   628   56  588  16  \n",
       "14      641.0      641.0   620   37  604  21  \n",
       "15      640.0      640.0   628   47  593  12  \n",
       "16      660.0      660.0   641   50  610  19  \n",
       "17      670.0      670.0   652   49  621  18  \n",
       "18      662.0      662.0   642   58  604  20  \n",
       "19      642.0      642.0   626   41  601  16  \n",
       "20      611.0      611.0   590   51  560  21  \n",
       "21      622.0      622.0   605   35  587  17  \n",
       "22      640.0      640.0   628   43  597  12  \n",
       "23      644.0      644.0   630   55  589  14  \n",
       "24      641.0      641.0   630   36  605  11  \n",
       "25      640.0      640.0   621   34  606  19  \n",
       "26      660.0      660.0   650   48  612  10  \n",
       "27      670.0      670.0   648   53  617  22  \n",
       "28      662.0      662.0   639   52  610  23  \n",
       "29      642.0      642.0   620   54  588  22  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "348e4fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame\n",
    "combined_metrics.to_csv('Output Data/Fast Text - Linear Regression2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5329717",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
