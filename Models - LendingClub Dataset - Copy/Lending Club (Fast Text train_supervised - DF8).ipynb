{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d2c91a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f460afa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "import numpy as np\n",
    "from pprint import pprint as pp\n",
    "import csv\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "from itertools import product\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from imblearn.pipeline import Pipeline \n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import r2_score, classification_report, confusion_matrix, accuracy_score, roc_auc_score, roc_curve, precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import homogeneity_score, silhouette_score\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import MiniBatchKMeans, DBSCAN\n",
    "import fasttext\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17e9cee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, precision_score, recall_score, f1_score, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6238cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, precision_score, recall_score, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75e8fc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.combine import SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "378df2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0db62d0",
   "metadata": {},
   "source": [
    "### Retrieving the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10513ea6",
   "metadata": {},
   "source": [
    "#### DF 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc3d2069",
   "metadata": {},
   "outputs": [],
   "source": [
    "df8 = pd.read_csv('df8.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a74cd9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'content' column from df8\n",
    "df8.drop(columns=['content'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82ed7cb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>term</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>emp_title</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>issue_d</th>\n",
       "      <th>pymnt_plan</th>\n",
       "      <th>purpose</th>\n",
       "      <th>title</th>\n",
       "      <th>addr_state</th>\n",
       "      <th>earliest_cr_line</th>\n",
       "      <th>last_pymnt_d</th>\n",
       "      <th>next_pymnt_d</th>\n",
       "      <th>last_credit_pull_d</th>\n",
       "      <th>collections_12_mths_ex_med</th>\n",
       "      <th>acc_now_delinq</th>\n",
       "      <th>chargeoff_within_12_mths</th>\n",
       "      <th>tax_liens</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>fico_range_low</th>\n",
       "      <th>fico_range_high</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>mths_since_last_delinq</th>\n",
       "      <th>mths_since_last_record</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>revol_bal</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>total_acc</th>\n",
       "      <th>out_prncp</th>\n",
       "      <th>out_prncp_inv</th>\n",
       "      <th>total_pymnt</th>\n",
       "      <th>total_pymnt_inv</th>\n",
       "      <th>total_rec_prncp</th>\n",
       "      <th>total_rec_int</th>\n",
       "      <th>total_rec_late_fee</th>\n",
       "      <th>recoveries</th>\n",
       "      <th>collection_recovery_fee</th>\n",
       "      <th>last_pymnt_amnt</th>\n",
       "      <th>last_fico_range_high</th>\n",
       "      <th>last_fico_range_low</th>\n",
       "      <th>delinq_amnt</th>\n",
       "      <th>pub_rec_bankruptcies</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1077501</td>\n",
       "      <td>36months</td>\n",
       "      <td>B</td>\n",
       "      <td>B2</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>10</td>\n",
       "      <td>RENT</td>\n",
       "      <td>Verified</td>\n",
       "      <td>2011</td>\n",
       "      <td>False</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>Computer</td>\n",
       "      <td>AZ</td>\n",
       "      <td>1985</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>C0Q1</td>\n",
       "      <td>C1Q1</td>\n",
       "      <td>C2Q2</td>\n",
       "      <td>C3Q3</td>\n",
       "      <td>C4Q2</td>\n",
       "      <td>C5Q0</td>\n",
       "      <td>C6Q7</td>\n",
       "      <td>C7Q9</td>\n",
       "      <td>C8Q0</td>\n",
       "      <td>C9Q7</td>\n",
       "      <td>C10Q7</td>\n",
       "      <td>C11Q0</td>\n",
       "      <td>C12Q3</td>\n",
       "      <td>C13Q0</td>\n",
       "      <td>C14Q0</td>\n",
       "      <td>C15Q0</td>\n",
       "      <td>C16Q6</td>\n",
       "      <td>C17Q8</td>\n",
       "      <td>C18Q0</td>\n",
       "      <td>C19Q0</td>\n",
       "      <td>C20Q0</td>\n",
       "      <td>C21Q2</td>\n",
       "      <td>C22Q3</td>\n",
       "      <td>C23Q2</td>\n",
       "      <td>C24Q3</td>\n",
       "      <td>C25Q0</td>\n",
       "      <td>C26Q0</td>\n",
       "      <td>C27Q0</td>\n",
       "      <td>C28Q1</td>\n",
       "      <td>C29Q7</td>\n",
       "      <td>C30Q7</td>\n",
       "      <td>C31Q0</td>\n",
       "      <td>C32Q0</td>\n",
       "      <td>__label__1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1077430</td>\n",
       "      <td>60months</td>\n",
       "      <td>C</td>\n",
       "      <td>C4</td>\n",
       "      <td>Ryder</td>\n",
       "      <td>1</td>\n",
       "      <td>RENT</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>2011</td>\n",
       "      <td>False</td>\n",
       "      <td>car</td>\n",
       "      <td>bike</td>\n",
       "      <td>GA</td>\n",
       "      <td>1999</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>C0Q0</td>\n",
       "      <td>C1Q0</td>\n",
       "      <td>C2Q0</td>\n",
       "      <td>C3Q7</td>\n",
       "      <td>C4Q0</td>\n",
       "      <td>C5Q0</td>\n",
       "      <td>C6Q3</td>\n",
       "      <td>C7Q0</td>\n",
       "      <td>C8Q0</td>\n",
       "      <td>C9Q7</td>\n",
       "      <td>C10Q7</td>\n",
       "      <td>C11Q3</td>\n",
       "      <td>C12Q3</td>\n",
       "      <td>C13Q0</td>\n",
       "      <td>C14Q0</td>\n",
       "      <td>C15Q0</td>\n",
       "      <td>C16Q1</td>\n",
       "      <td>C17Q1</td>\n",
       "      <td>C18Q0</td>\n",
       "      <td>C19Q0</td>\n",
       "      <td>C20Q0</td>\n",
       "      <td>C21Q0</td>\n",
       "      <td>C22Q0</td>\n",
       "      <td>C23Q0</td>\n",
       "      <td>C24Q1</td>\n",
       "      <td>C25Q0</td>\n",
       "      <td>C26Q1</td>\n",
       "      <td>C27Q1</td>\n",
       "      <td>C28Q1</td>\n",
       "      <td>C29Q0</td>\n",
       "      <td>C30Q0</td>\n",
       "      <td>C31Q0</td>\n",
       "      <td>C32Q0</td>\n",
       "      <td>__label__2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       id      term grade sub_grade emp_title  emp_length  \\\n",
       "0           0  1077501  36months     B        B2   Unknown          10   \n",
       "1           1  1077430  60months     C        C4     Ryder           1   \n",
       "\n",
       "  home_ownership verification_status  issue_d  pymnt_plan      purpose  \\\n",
       "0           RENT            Verified     2011       False  credit_card   \n",
       "1           RENT     Source Verified     2011       False          car   \n",
       "\n",
       "      title addr_state  earliest_cr_line  last_pymnt_d  next_pymnt_d  \\\n",
       "0  Computer         AZ              1985          2015             0   \n",
       "1      bike         GA              1999          2013             0   \n",
       "\n",
       "   last_credit_pull_d  collections_12_mths_ex_med  acc_now_delinq  \\\n",
       "0                2016                       False           False   \n",
       "1                2016                       False           False   \n",
       "\n",
       "   chargeoff_within_12_mths  tax_liens loan_amnt funded_amnt funded_amnt_inv  \\\n",
       "0                     False      False      C0Q1        C1Q1            C2Q2   \n",
       "1                     False      False      C0Q0        C1Q0            C2Q0   \n",
       "\n",
       "  int_rate installment annual_inc zip_code   dti delinq_2yrs fico_range_low  \\\n",
       "0     C3Q3        C4Q2       C5Q0     C6Q7  C7Q9        C8Q0           C9Q7   \n",
       "1     C3Q7        C4Q0       C5Q0     C6Q3  C7Q0        C8Q0           C9Q7   \n",
       "\n",
       "  fico_range_high inq_last_6mths mths_since_last_delinq  \\\n",
       "0           C10Q7          C11Q0                  C12Q3   \n",
       "1           C10Q7          C11Q3                  C12Q3   \n",
       "\n",
       "  mths_since_last_record open_acc pub_rec revol_bal revol_util total_acc  \\\n",
       "0                  C13Q0    C14Q0   C15Q0     C16Q6      C17Q8     C18Q0   \n",
       "1                  C13Q0    C14Q0   C15Q0     C16Q1      C17Q1     C18Q0   \n",
       "\n",
       "  out_prncp out_prncp_inv total_pymnt total_pymnt_inv total_rec_prncp  \\\n",
       "0     C19Q0         C20Q0       C21Q2           C22Q3           C23Q2   \n",
       "1     C19Q0         C20Q0       C21Q0           C22Q0           C23Q0   \n",
       "\n",
       "  total_rec_int total_rec_late_fee recoveries collection_recovery_fee  \\\n",
       "0         C24Q3              C25Q0      C26Q0                   C27Q0   \n",
       "1         C24Q1              C25Q0      C26Q1                   C27Q1   \n",
       "\n",
       "  last_pymnt_amnt last_fico_range_high last_fico_range_low delinq_amnt  \\\n",
       "0           C28Q1                C29Q7               C30Q7       C31Q0   \n",
       "1           C28Q1                C29Q0               C30Q0       C31Q0   \n",
       "\n",
       "  pub_rec_bankruptcies      target  \n",
       "0                C32Q0  __label__1  \n",
       "1                C32Q0  __label__2  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df8.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f9963f",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b0bea07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store evaluation metrics for each fold\n",
    "dataset_used = []\n",
    "model_used = []\n",
    "data_balancing_technique = []\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "conf_matrices = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e6d6d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combined_metrics = pd.DataFrame()\n",
    "\n",
    "combined_metrics = pd.DataFrame(columns=['dataset', 'model', 'data balancing technique', 'fold', 'precision_1','precision_2','recall_1','recall_2','f1-score_1','f1-score_2','support_1','support_2','TP','FP','TN','FN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052cda7c",
   "metadata": {},
   "source": [
    "# Fast Text \n",
    "### train_supervised"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedf6e11",
   "metadata": {},
   "source": [
    "## DF8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "89f99b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "Mean Accuracy: 0.99\n",
      "Mean Precision: 0.99\n",
      "Mean Recall: 0.99\n",
      "Mean F1-Score: 0.99\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df2' is your DataFrame with features and the target column\n",
    "# Replace 'features' with the actual list of feature columns\n",
    "features = df8.drop(columns=['target'])  # Drop the target column to get the feature columns\n",
    "target = df8['target'].astype(str)\n",
    "\n",
    "# Define hyperparameters\n",
    "dim = 300  # Dimension of word vectors\n",
    "min_count = 1  # Minimum frequency of words\n",
    "loss = 'ns'  # Hierarchical softmax loss #'hs', 'ns', 'softmax'\n",
    "epoch = 100  # Number of training epochs\n",
    "bucket = 2000000  # Number of buckets used for hashing n-grams\n",
    "word_ngrams = 1  # Maximum length of word n-grams\n",
    "lr = 0.5 #0.1, 0.01, 0.001 #learning rate\n",
    "\n",
    "# Initialize KFold with 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    # Create a new column \"content\" by concatenating values from selected columns\n",
    "    X_train['content'] = y_train + ' ' + X_train.apply(lambda row: ' '.join(str(val) for val in row), axis=1)\n",
    "    X_test['content'] = X_test.apply(lambda row: ' '.join(str(val) for val in row), axis=1)\n",
    "    \n",
    "    X_train = X_train['content']\n",
    "    X_test = X_test['content']\n",
    "    \n",
    "    X_train_list = [value for value in X_train]\n",
    "    \n",
    "    # Save training data to a file\n",
    "    with open(\"train_german_fast_text.txt\", \"w\", encoding='utf-8', errors='ignore') as f:\n",
    "        for line in X_train_list:\n",
    "            f.write(line + \"\\n\")\n",
    "\n",
    "    # Training data file path\n",
    "    train_data_path = \"train_german_fast_text.txt\"\n",
    "    \n",
    "    # Train the supervised model\n",
    "    model = fasttext.train_supervised(input=train_data_path, dim=dim, minCount=min_count,bucket=bucket, loss=loss, epoch=epoch, wordNgrams=word_ngrams)#lr=lr, \n",
    "                                       #lr=lr,bucket=bucket,\n",
    "    \n",
    "    # Predict on the testing set\n",
    "    # Initialize an empty list to store the predicted labels\n",
    "    y_pred_list = []\n",
    "\n",
    "    # Iterate over each data point in X_test and predict the label\n",
    "    for text in X_test:\n",
    "        # Predict the label for the current text\n",
    "        predicted_label, _ = model.predict(text)\n",
    "        # Append the predicted label to the list\n",
    "        y_pred_list.append(predicted_label[0])\n",
    "\n",
    "    # Convert the list of predicted labels to a pandas Series\n",
    "    y_pred = pd.Series(y_pred_list)\n",
    "    \n",
    "    # Extract the numeric label using a lambda function\n",
    "    #y_test = y_test.apply(lambda x: int(x.split(\"__label__\")[1]) if len(x.split(\"__label__\")) > 1 else )\n",
    "    y_test = y_test.apply(lambda x: int(x.split(\"__label__\")[1]))  ## uncomment for next run\n",
    "    y_pred = y_pred.apply(lambda x: int(x.split(\"__label__\")[1]))\n",
    "    \n",
    "    # Model evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred.round())\n",
    "    precision = precision_score(y_test, y_pred.round(), average='weighted')\n",
    "    recall = recall_score(y_test, y_pred.round(), average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred.round(), average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred.round())\n",
    "    \n",
    "    \n",
    "    # Convert classification report to DataFrame\n",
    "    report_df = pd.DataFrame(classification_report(y_test, y_pred.round(), output_dict=True)).transpose()\n",
    "    # Convert confusion matrix to DataFrame\n",
    "    matrix_df = pd.DataFrame(confusion_matrix(y_test, y_pred.round()))\n",
    "    \n",
    "    # Extract metrics for class 1\n",
    "    metrics_1 = report_df.loc['1', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract metrics for class 2\n",
    "    metrics_2 = report_df.loc['2', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract TP, TN, FP, FN counts from the confusion matrix DataFrame\n",
    "    TP = matrix_df.loc[0, 0]\n",
    "    TN = matrix_df.loc[1, 1]\n",
    "    FP = matrix_df.loc[1, 0]\n",
    "    FN = matrix_df.loc[0, 1]\n",
    "    \n",
    "    new_metric_row = {\n",
    "    'dataset': 'DF8',\n",
    "    'model' : 'Fast Text - train_supervised',\n",
    "    'data balancing technique' : 'None',\n",
    "    'fold' : i,\n",
    "    'precision_1': metrics_1['precision'],\n",
    "    'precision_2': metrics_2['precision'],\n",
    "    'recall_1': metrics_1['recall'],\n",
    "    'recall_2': metrics_2['recall'],\n",
    "    'f1-score_1': metrics_1['f1-score'],\n",
    "    'f1-score_2': metrics_2['f1-score'],\n",
    "    'support_1': metrics_1['support'],\n",
    "    'support_2': metrics_2['support'],\n",
    "    'TP' : TP,\n",
    "    'FP' : FP,\n",
    "    'TN' : TN,\n",
    "    'FN' : FN\n",
    "    }\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    #combined_metrics = combined_metrics.append(new_metric_row, ignore_index=True)\n",
    "    combined_metrics.loc[len(combined_metrics)] = new_metric_row\n",
    "    \n",
    "    \n",
    "    # Append evaluation metrics to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "    \n",
    "    print(i)\n",
    "\n",
    "# Calculate mean evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores) #sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = np.mean(precision_scores) #sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = np.mean(recall_scores) #sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = np.mean(f1_scores) #sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print('Mean Accuracy: {:.2f}'.format(mean_accuracy))\n",
    "print('Mean Precision: {:.2f}'.format(mean_precision))\n",
    "print('Mean Recall: {:.2f}'.format(mean_recall))\n",
    "print('Mean F1-Score: {:.2f}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e5cd58d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>data balancing technique</th>\n",
       "      <th>fold</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_2</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>f1-score_1</th>\n",
       "      <th>f1-score_2</th>\n",
       "      <th>support_1</th>\n",
       "      <th>support_2</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0.990191</td>\n",
       "      <td>0.984589</td>\n",
       "      <td>0.997530</td>\n",
       "      <td>0.941080</td>\n",
       "      <td>0.993847</td>\n",
       "      <td>0.962343</td>\n",
       "      <td>3643.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>3634</td>\n",
       "      <td>36</td>\n",
       "      <td>575</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>0.992341</td>\n",
       "      <td>0.993311</td>\n",
       "      <td>0.998899</td>\n",
       "      <td>0.954984</td>\n",
       "      <td>0.995609</td>\n",
       "      <td>0.973770</td>\n",
       "      <td>3632.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>3628</td>\n",
       "      <td>28</td>\n",
       "      <td>594</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset                         model data balancing technique  fold  \\\n",
       "0     DF8  Fast Text - train_supervised                     None     1   \n",
       "1     DF8  Fast Text - train_supervised                     None     2   \n",
       "\n",
       "   precision_1  precision_2  recall_1  recall_2  f1-score_1  f1-score_2  \\\n",
       "0     0.990191     0.984589  0.997530  0.941080    0.993847    0.962343   \n",
       "1     0.992341     0.993311  0.998899  0.954984    0.995609    0.973770   \n",
       "\n",
       "   support_1  support_2    TP  FP   TN  FN  \n",
       "0     3643.0      611.0  3634  36  575   9  \n",
       "1     3632.0      622.0  3628  28  594   4  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_metrics[(combined_metrics['data balancing technique'] == 'None') & (combined_metrics['dataset'] == 'DF8')].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737bdf77",
   "metadata": {},
   "source": [
    "### FastText train_supervised with df4 data and imbalance data tackling (RandomUnderSampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0efc30fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "Mean Accuracy: 0.99\n",
      "Mean Precision: 0.99\n",
      "Mean Recall: 0.99\n",
      "Mean F1-Score: 0.99\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df8' is your DataFrame with features and the target column\n",
    "# Replace 'features' with the actual list of feature columns\n",
    "features = df8.drop(columns=['target'])  # Drop the target column to get the feature columns\n",
    "target = df8['target'].astype(str)\n",
    "\n",
    "# Define hyperparameters\n",
    "dim = 300  # Dimension of word vectors\n",
    "min_count = 1  # Minimum frequency of words\n",
    "loss = 'ns'  # Hierarchical softmax loss #'hs', 'ns', 'softmax'\n",
    "epoch = 100  # Number of training epochs\n",
    "bucket = 2000000  # Number of buckets used for hashing n-grams\n",
    "word_ngrams = 1  # Maximum length of word n-grams\n",
    "lr = 0.5 #0.1, 0.01, 0.001 #learning rate\n",
    "\n",
    "# Initialize KFold with 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    # Oversampling the minority class using SMOTE\n",
    "    rus = RandomUnderSampler(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Create a new column \"content\" by concatenating values from selected columns\n",
    "    X_train_resampled['content'] = y_train_resampled + ' ' + X_train_resampled.apply(lambda row: ' '.join(str(val) for val in row), axis=1)\n",
    "    X_test['content'] = X_test.apply(lambda row: ' '.join(str(val) for val in row), axis=1)\n",
    "    \n",
    "    X_train = X_train_resampled['content']\n",
    "    X_test = X_test['content']\n",
    "    \n",
    "    X_train_list = [value for value in X_train]\n",
    "    \n",
    "    # Save training data to a file\n",
    "    with open(\"train_german_fast_text.txt\", \"w\", encoding='utf-8', errors='ignore') as f:\n",
    "        for line in X_train_list:\n",
    "            f.write(line + \"\\n\")\n",
    "\n",
    "    # Training data file path\n",
    "    train_data_path = \"train_german_fast_text.txt\"\n",
    "    \n",
    "    # Train the supervised model\n",
    "    model = fasttext.train_supervised(input=train_data_path, dim=dim, minCount=min_count,bucket=bucket, loss=loss, epoch=epoch, wordNgrams=word_ngrams)#lr=lr, \n",
    "                                       #lr=lr,bucket=bucket,\n",
    "    \n",
    "    # Predict on the testing set\n",
    "    # Initialize an empty list to store the predicted labels\n",
    "    y_pred_list = []\n",
    "\n",
    "    # Iterate over each data point in X_test and predict the label\n",
    "    for text in X_test:\n",
    "        # Predict the label for the current text\n",
    "        predicted_label, _ = model.predict(text)\n",
    "        # Append the predicted label to the list\n",
    "        y_pred_list.append(predicted_label[0])\n",
    "\n",
    "    # Convert the list of predicted labels to a pandas Series\n",
    "    y_pred = pd.Series(y_pred_list)\n",
    "    \n",
    "    # Extract the numeric label using a lambda function\n",
    "    y_test = y_test.apply(lambda x: int(x.split(\"__label__\")[1]))  ## uncomment for next run\n",
    "    y_pred = y_pred.apply(lambda x: int(x.split(\"__label__\")[1]))\n",
    "    \n",
    "    # Model evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred.round())\n",
    "    precision = precision_score(y_test, y_pred.round(), average='weighted')\n",
    "    recall = recall_score(y_test, y_pred.round(), average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred.round(), average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred.round())\n",
    "    \n",
    "    \n",
    "    # Convert classification report to DataFrame\n",
    "    report_df = pd.DataFrame(classification_report(y_test, y_pred.round(), output_dict=True)).transpose()\n",
    "    # Convert confusion matrix to DataFrame\n",
    "    matrix_df = pd.DataFrame(confusion_matrix(y_test, y_pred.round()))\n",
    "    \n",
    "    # Extract metrics for class 1\n",
    "    metrics_1 = report_df.loc['1', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract metrics for class 2\n",
    "    metrics_2 = report_df.loc['2', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract TP, TN, FP, FN counts from the confusion matrix DataFrame\n",
    "    TP = matrix_df.loc[0, 0]\n",
    "    TN = matrix_df.loc[1, 1]\n",
    "    FP = matrix_df.loc[1, 0]\n",
    "    FN = matrix_df.loc[0, 1]\n",
    "    \n",
    "    new_metric_row = {\n",
    "    'dataset': 'DF8',\n",
    "    'model' : 'Fast Text - train_supervised',\n",
    "    'data balancing technique' : 'Random Under Sampler',\n",
    "    'fold' : i,\n",
    "    'precision_1': metrics_1['precision'],\n",
    "    'precision_2': metrics_2['precision'],\n",
    "    'recall_1': metrics_1['recall'],\n",
    "    'recall_2': metrics_2['recall'],\n",
    "    'f1-score_1': metrics_1['f1-score'],\n",
    "    'f1-score_2': metrics_2['f1-score'],\n",
    "    'support_1': metrics_1['support'],\n",
    "    'support_2': metrics_2['support'],\n",
    "    'TP' : TP,\n",
    "    'FP' : FP,\n",
    "    'TN' : TN,\n",
    "    'FN' : FN\n",
    "    }\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    #combined_metrics = combined_metrics.append(new_metric_row, ignore_index=True)\n",
    "    combined_metrics.loc[len(combined_metrics)] = new_metric_row\n",
    "    \n",
    "    \n",
    "    # Append evaluation metrics to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "    \n",
    "    print(i)\n",
    "\n",
    "# Calculate mean evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores) #sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = np.mean(precision_scores) #sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = np.mean(recall_scores) #sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = np.mean(f1_scores) #sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print('Mean Accuracy: {:.2f}'.format(mean_accuracy))\n",
    "print('Mean Precision: {:.2f}'.format(mean_precision))\n",
    "print('Mean Recall: {:.2f}'.format(mean_recall))\n",
    "print('Mean F1-Score: {:.2f}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2d72cc02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>data balancing technique</th>\n",
       "      <th>fold</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_2</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>f1-score_1</th>\n",
       "      <th>f1-score_2</th>\n",
       "      <th>support_1</th>\n",
       "      <th>support_2</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>1</td>\n",
       "      <td>0.994455</td>\n",
       "      <td>0.913447</td>\n",
       "      <td>0.984628</td>\n",
       "      <td>0.967267</td>\n",
       "      <td>0.989517</td>\n",
       "      <td>0.939587</td>\n",
       "      <td>3643.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>3587</td>\n",
       "      <td>20</td>\n",
       "      <td>591</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>2</td>\n",
       "      <td>0.995834</td>\n",
       "      <td>0.929556</td>\n",
       "      <td>0.987335</td>\n",
       "      <td>0.975884</td>\n",
       "      <td>0.991566</td>\n",
       "      <td>0.952157</td>\n",
       "      <td>3632.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>3586</td>\n",
       "      <td>15</td>\n",
       "      <td>607</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>3</td>\n",
       "      <td>0.995822</td>\n",
       "      <td>0.941265</td>\n",
       "      <td>0.989209</td>\n",
       "      <td>0.976562</td>\n",
       "      <td>0.992504</td>\n",
       "      <td>0.958589</td>\n",
       "      <td>3614.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3575</td>\n",
       "      <td>15</td>\n",
       "      <td>625</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>4</td>\n",
       "      <td>0.993863</td>\n",
       "      <td>0.929746</td>\n",
       "      <td>0.986981</td>\n",
       "      <td>0.965839</td>\n",
       "      <td>0.990410</td>\n",
       "      <td>0.947449</td>\n",
       "      <td>3610.0</td>\n",
       "      <td>644.0</td>\n",
       "      <td>3563</td>\n",
       "      <td>22</td>\n",
       "      <td>622</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>5</td>\n",
       "      <td>0.996350</td>\n",
       "      <td>0.907514</td>\n",
       "      <td>0.982286</td>\n",
       "      <td>0.979719</td>\n",
       "      <td>0.989268</td>\n",
       "      <td>0.942236</td>\n",
       "      <td>3613.0</td>\n",
       "      <td>641.0</td>\n",
       "      <td>3549</td>\n",
       "      <td>13</td>\n",
       "      <td>628</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>6</td>\n",
       "      <td>0.995784</td>\n",
       "      <td>0.899281</td>\n",
       "      <td>0.980626</td>\n",
       "      <td>0.976562</td>\n",
       "      <td>0.988147</td>\n",
       "      <td>0.936330</td>\n",
       "      <td>3613.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3543</td>\n",
       "      <td>15</td>\n",
       "      <td>625</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>7</td>\n",
       "      <td>0.995200</td>\n",
       "      <td>0.904360</td>\n",
       "      <td>0.981074</td>\n",
       "      <td>0.974242</td>\n",
       "      <td>0.988087</td>\n",
       "      <td>0.938001</td>\n",
       "      <td>3593.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3525</td>\n",
       "      <td>17</td>\n",
       "      <td>643</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>8</td>\n",
       "      <td>0.994091</td>\n",
       "      <td>0.928469</td>\n",
       "      <td>0.986045</td>\n",
       "      <td>0.968657</td>\n",
       "      <td>0.990052</td>\n",
       "      <td>0.948137</td>\n",
       "      <td>3583.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>3533</td>\n",
       "      <td>21</td>\n",
       "      <td>649</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>9</td>\n",
       "      <td>0.993548</td>\n",
       "      <td>0.928779</td>\n",
       "      <td>0.986355</td>\n",
       "      <td>0.965257</td>\n",
       "      <td>0.989939</td>\n",
       "      <td>0.946667</td>\n",
       "      <td>3591.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>3542</td>\n",
       "      <td>23</td>\n",
       "      <td>639</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>10</td>\n",
       "      <td>0.997483</td>\n",
       "      <td>0.933628</td>\n",
       "      <td>0.987538</td>\n",
       "      <td>0.985981</td>\n",
       "      <td>0.992485</td>\n",
       "      <td>0.959091</td>\n",
       "      <td>3611.0</td>\n",
       "      <td>642.0</td>\n",
       "      <td>3566</td>\n",
       "      <td>9</td>\n",
       "      <td>633</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset                         model data balancing technique  fold  \\\n",
       "10     DF8  Fast Text - train_supervised     Random Under Sampler     1   \n",
       "11     DF8  Fast Text - train_supervised     Random Under Sampler     2   \n",
       "12     DF8  Fast Text - train_supervised     Random Under Sampler     3   \n",
       "13     DF8  Fast Text - train_supervised     Random Under Sampler     4   \n",
       "14     DF8  Fast Text - train_supervised     Random Under Sampler     5   \n",
       "15     DF8  Fast Text - train_supervised     Random Under Sampler     6   \n",
       "16     DF8  Fast Text - train_supervised     Random Under Sampler     7   \n",
       "17     DF8  Fast Text - train_supervised     Random Under Sampler     8   \n",
       "18     DF8  Fast Text - train_supervised     Random Under Sampler     9   \n",
       "19     DF8  Fast Text - train_supervised     Random Under Sampler    10   \n",
       "\n",
       "    precision_1  precision_2  recall_1  recall_2  f1-score_1  f1-score_2  \\\n",
       "10     0.994455     0.913447  0.984628  0.967267    0.989517    0.939587   \n",
       "11     0.995834     0.929556  0.987335  0.975884    0.991566    0.952157   \n",
       "12     0.995822     0.941265  0.989209  0.976562    0.992504    0.958589   \n",
       "13     0.993863     0.929746  0.986981  0.965839    0.990410    0.947449   \n",
       "14     0.996350     0.907514  0.982286  0.979719    0.989268    0.942236   \n",
       "15     0.995784     0.899281  0.980626  0.976562    0.988147    0.936330   \n",
       "16     0.995200     0.904360  0.981074  0.974242    0.988087    0.938001   \n",
       "17     0.994091     0.928469  0.986045  0.968657    0.990052    0.948137   \n",
       "18     0.993548     0.928779  0.986355  0.965257    0.989939    0.946667   \n",
       "19     0.997483     0.933628  0.987538  0.985981    0.992485    0.959091   \n",
       "\n",
       "    support_1  support_2    TP  FP   TN  FN  \n",
       "10     3643.0      611.0  3587  20  591  56  \n",
       "11     3632.0      622.0  3586  15  607  46  \n",
       "12     3614.0      640.0  3575  15  625  39  \n",
       "13     3610.0      644.0  3563  22  622  47  \n",
       "14     3613.0      641.0  3549  13  628  64  \n",
       "15     3613.0      640.0  3543  15  625  70  \n",
       "16     3593.0      660.0  3525  17  643  68  \n",
       "17     3583.0      670.0  3533  21  649  50  \n",
       "18     3591.0      662.0  3542  23  639  49  \n",
       "19     3611.0      642.0  3566   9  633  45  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_metrics[(combined_metrics['data balancing technique'] == 'Random Under Sampler') & (combined_metrics['dataset'] == 'DF8')]#.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc10646",
   "metadata": {},
   "source": [
    "### FastText train_supervised with df2 data and imbalance data tackling (RandomOverSampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c500a1fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "Mean Accuracy: 0.99\n",
      "Mean Precision: 0.99\n",
      "Mean Recall: 0.99\n",
      "Mean F1-Score: 0.99\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df8' is your DataFrame with features and the target column\n",
    "# Replace 'features' with the actual list of feature columns\n",
    "features = df8.drop(columns=['target'])  # Drop the target column to get the feature columns\n",
    "target = df8['target'].astype(str)\n",
    "\n",
    "# Define hyperparameters\n",
    "dim = 300  # Dimension of word vectors\n",
    "min_count = 1  # Minimum frequency of words\n",
    "loss = 'ns'  # Hierarchical softmax loss #'hs', 'ns', 'softmax'\n",
    "epoch = 100  # Number of training epochs\n",
    "bucket = 2000000  # Number of buckets used for hashing n-grams\n",
    "word_ngrams = 1  # Maximum length of word n-grams\n",
    "lr = 0.5 #0.1, 0.01, 0.001 #learning rate\n",
    "\n",
    "# Initialize KFold with 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    # Oversampling the minority class using SMOTE\n",
    "    ros = RandomOverSampler(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Create a new column \"content\" by concatenating values from selected columns\n",
    "    X_train_resampled['content'] = y_train_resampled + ' ' + X_train_resampled.apply(lambda row: ' '.join(str(val) for val in row), axis=1)\n",
    "    X_test['content'] = X_test.apply(lambda row: ' '.join(str(val) for val in row), axis=1)\n",
    "    \n",
    "    X_train = X_train_resampled['content']\n",
    "    X_test = X_test['content']\n",
    "    \n",
    "    X_train_list = [value for value in X_train]\n",
    "    \n",
    "    # Save training data to a file\n",
    "    with open(\"train_german_fast_text.txt\", \"w\", encoding='utf-8', errors='ignore') as f:\n",
    "        for line in X_train_list:\n",
    "            f.write(line + \"\\n\")\n",
    "\n",
    "    # Training data file path\n",
    "    train_data_path = \"train_german_fast_text.txt\"\n",
    "    \n",
    "    # Train the supervised model\n",
    "    model = fasttext.train_supervised(input=train_data_path, dim=dim, minCount=min_count,bucket=bucket, loss=loss, epoch=epoch, wordNgrams=word_ngrams)#lr=lr, \n",
    "                                       #lr=lr,bucket=bucket,\n",
    "    \n",
    "    # Predict on the testing set\n",
    "    # Initialize an empty list to store the predicted labels\n",
    "    y_pred_list = []\n",
    "\n",
    "    # Iterate over each data point in X_test and predict the label\n",
    "    for text in X_test:\n",
    "        # Predict the label for the current text\n",
    "        predicted_label, _ = model.predict(text)\n",
    "        # Append the predicted label to the list\n",
    "        y_pred_list.append(predicted_label[0])\n",
    "\n",
    "    # Convert the list of predicted labels to a pandas Series\n",
    "    y_pred = pd.Series(y_pred_list)\n",
    "    \n",
    "    # Extract the numeric label using a lambda function\n",
    "    y_test = y_test.apply(lambda x: int(x.split(\"__label__\")[1]))  ## uncomment for next run\n",
    "    y_pred = y_pred.apply(lambda x: int(x.split(\"__label__\")[1]))\n",
    "    \n",
    "    # Model evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred.round())\n",
    "    precision = precision_score(y_test, y_pred.round(), average='weighted')\n",
    "    recall = recall_score(y_test, y_pred.round(), average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred.round(), average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred.round())\n",
    "    \n",
    "    \n",
    "    # Convert classification report to DataFrame\n",
    "    report_df = pd.DataFrame(classification_report(y_test, y_pred.round(), output_dict=True)).transpose()\n",
    "    # Convert confusion matrix to DataFrame\n",
    "    matrix_df = pd.DataFrame(confusion_matrix(y_test, y_pred.round()))\n",
    "    \n",
    "    # Extract metrics for class 1\n",
    "    metrics_1 = report_df.loc['1', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract metrics for class 2\n",
    "    metrics_2 = report_df.loc['2', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract TP, TN, FP, FN counts from the confusion matrix DataFrame\n",
    "    TP = matrix_df.loc[0, 0]\n",
    "    TN = matrix_df.loc[1, 1]\n",
    "    FP = matrix_df.loc[1, 0]\n",
    "    FN = matrix_df.loc[0, 1]\n",
    "    \n",
    "    new_metric_row = {\n",
    "    'dataset': 'DF8',\n",
    "    'model' : 'Fast Text - train_supervised',\n",
    "    'data balancing technique' : 'Random Over Sampler',\n",
    "    'fold' : i,\n",
    "    'precision_1': metrics_1['precision'],\n",
    "    'precision_2': metrics_2['precision'],\n",
    "    'recall_1': metrics_1['recall'],\n",
    "    'recall_2': metrics_2['recall'],\n",
    "    'f1-score_1': metrics_1['f1-score'],\n",
    "    'f1-score_2': metrics_2['f1-score'],\n",
    "    'support_1': metrics_1['support'],\n",
    "    'support_2': metrics_2['support'],\n",
    "    'TP' : TP,\n",
    "    'FP' : FP,\n",
    "    'TN' : TN,\n",
    "    'FN' : FN\n",
    "    }\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    #combined_metrics = combined_metrics.append(new_metric_row, ignore_index=True)\n",
    "    combined_metrics.loc[len(combined_metrics)] = new_metric_row\n",
    "    \n",
    "    \n",
    "    # Append evaluation metrics to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "    \n",
    "    print(i)\n",
    "\n",
    "# Calculate mean evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores) #sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = np.mean(precision_scores) #sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = np.mean(recall_scores) #sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = np.mean(f1_scores) #sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print('Mean Accuracy: {:.2f}'.format(mean_accuracy))\n",
    "print('Mean Precision: {:.2f}'.format(mean_precision))\n",
    "print('Mean Recall: {:.2f}'.format(mean_recall))\n",
    "print('Mean F1-Score: {:.2f}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca7e58c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>data balancing technique</th>\n",
       "      <th>fold</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_2</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>f1-score_1</th>\n",
       "      <th>f1-score_2</th>\n",
       "      <th>support_1</th>\n",
       "      <th>support_2</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>1</td>\n",
       "      <td>0.990461</td>\n",
       "      <td>0.984615</td>\n",
       "      <td>0.997530</td>\n",
       "      <td>0.942717</td>\n",
       "      <td>0.993982</td>\n",
       "      <td>0.963211</td>\n",
       "      <td>3643.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>3634</td>\n",
       "      <td>35</td>\n",
       "      <td>576</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>2</td>\n",
       "      <td>0.992879</td>\n",
       "      <td>0.988391</td>\n",
       "      <td>0.998073</td>\n",
       "      <td>0.958199</td>\n",
       "      <td>0.995469</td>\n",
       "      <td>0.973061</td>\n",
       "      <td>3632.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>3625</td>\n",
       "      <td>26</td>\n",
       "      <td>596</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset                         model data balancing technique  fold  \\\n",
       "20     DF8  Fast Text - train_supervised      Random Over Sampler     1   \n",
       "21     DF8  Fast Text - train_supervised      Random Over Sampler     2   \n",
       "\n",
       "    precision_1  precision_2  recall_1  recall_2  f1-score_1  f1-score_2  \\\n",
       "20     0.990461     0.984615  0.997530  0.942717    0.993982    0.963211   \n",
       "21     0.992879     0.988391  0.998073  0.958199    0.995469    0.973061   \n",
       "\n",
       "    support_1  support_2    TP  FP   TN  FN  \n",
       "20     3643.0      611.0  3634  35  576   9  \n",
       "21     3632.0      622.0  3625  26  596   7  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_metrics[(combined_metrics['data balancing technique'] == 'Random Over Sampler') & (combined_metrics['dataset'] == 'DF8')].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd948ec1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc4b04f0",
   "metadata": {},
   "source": [
    "## Performance metrics for the Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1158fa25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>data balancing technique</th>\n",
       "      <th>fold</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_2</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>f1-score_1</th>\n",
       "      <th>f1-score_2</th>\n",
       "      <th>support_1</th>\n",
       "      <th>support_2</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0.990191</td>\n",
       "      <td>0.984589</td>\n",
       "      <td>0.997530</td>\n",
       "      <td>0.941080</td>\n",
       "      <td>0.993847</td>\n",
       "      <td>0.962343</td>\n",
       "      <td>3643.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>3634</td>\n",
       "      <td>36</td>\n",
       "      <td>575</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>0.992341</td>\n",
       "      <td>0.993311</td>\n",
       "      <td>0.998899</td>\n",
       "      <td>0.954984</td>\n",
       "      <td>0.995609</td>\n",
       "      <td>0.973770</td>\n",
       "      <td>3632.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>3628</td>\n",
       "      <td>28</td>\n",
       "      <td>594</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>0.993396</td>\n",
       "      <td>0.993548</td>\n",
       "      <td>0.998893</td>\n",
       "      <td>0.962500</td>\n",
       "      <td>0.996137</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>3614.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3610</td>\n",
       "      <td>24</td>\n",
       "      <td>616</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>0.991738</td>\n",
       "      <td>0.985554</td>\n",
       "      <td>0.997507</td>\n",
       "      <td>0.953416</td>\n",
       "      <td>0.994614</td>\n",
       "      <td>0.969219</td>\n",
       "      <td>3610.0</td>\n",
       "      <td>644.0</td>\n",
       "      <td>3601</td>\n",
       "      <td>30</td>\n",
       "      <td>614</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>0.993119</td>\n",
       "      <td>0.991948</td>\n",
       "      <td>0.998616</td>\n",
       "      <td>0.960998</td>\n",
       "      <td>0.995860</td>\n",
       "      <td>0.976228</td>\n",
       "      <td>3613.0</td>\n",
       "      <td>641.0</td>\n",
       "      <td>3608</td>\n",
       "      <td>25</td>\n",
       "      <td>616</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>0.993111</td>\n",
       "      <td>0.985577</td>\n",
       "      <td>0.997509</td>\n",
       "      <td>0.960938</td>\n",
       "      <td>0.995305</td>\n",
       "      <td>0.973101</td>\n",
       "      <td>3613.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3604</td>\n",
       "      <td>25</td>\n",
       "      <td>615</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>None</td>\n",
       "      <td>7</td>\n",
       "      <td>0.991985</td>\n",
       "      <td>0.993701</td>\n",
       "      <td>0.998887</td>\n",
       "      <td>0.956061</td>\n",
       "      <td>0.995424</td>\n",
       "      <td>0.974517</td>\n",
       "      <td>3593.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3589</td>\n",
       "      <td>29</td>\n",
       "      <td>631</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>None</td>\n",
       "      <td>8</td>\n",
       "      <td>0.991133</td>\n",
       "      <td>0.990683</td>\n",
       "      <td>0.998325</td>\n",
       "      <td>0.952239</td>\n",
       "      <td>0.994716</td>\n",
       "      <td>0.971081</td>\n",
       "      <td>3583.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>3577</td>\n",
       "      <td>32</td>\n",
       "      <td>638</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>None</td>\n",
       "      <td>9</td>\n",
       "      <td>0.989244</td>\n",
       "      <td>0.993620</td>\n",
       "      <td>0.998886</td>\n",
       "      <td>0.941088</td>\n",
       "      <td>0.994042</td>\n",
       "      <td>0.966641</td>\n",
       "      <td>3591.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>3587</td>\n",
       "      <td>39</td>\n",
       "      <td>623</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.994483</td>\n",
       "      <td>0.990446</td>\n",
       "      <td>0.998338</td>\n",
       "      <td>0.968847</td>\n",
       "      <td>0.996407</td>\n",
       "      <td>0.979528</td>\n",
       "      <td>3611.0</td>\n",
       "      <td>642.0</td>\n",
       "      <td>3605</td>\n",
       "      <td>20</td>\n",
       "      <td>622</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>1</td>\n",
       "      <td>0.994455</td>\n",
       "      <td>0.913447</td>\n",
       "      <td>0.984628</td>\n",
       "      <td>0.967267</td>\n",
       "      <td>0.989517</td>\n",
       "      <td>0.939587</td>\n",
       "      <td>3643.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>3587</td>\n",
       "      <td>20</td>\n",
       "      <td>591</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>2</td>\n",
       "      <td>0.995834</td>\n",
       "      <td>0.929556</td>\n",
       "      <td>0.987335</td>\n",
       "      <td>0.975884</td>\n",
       "      <td>0.991566</td>\n",
       "      <td>0.952157</td>\n",
       "      <td>3632.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>3586</td>\n",
       "      <td>15</td>\n",
       "      <td>607</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>3</td>\n",
       "      <td>0.995822</td>\n",
       "      <td>0.941265</td>\n",
       "      <td>0.989209</td>\n",
       "      <td>0.976562</td>\n",
       "      <td>0.992504</td>\n",
       "      <td>0.958589</td>\n",
       "      <td>3614.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3575</td>\n",
       "      <td>15</td>\n",
       "      <td>625</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>4</td>\n",
       "      <td>0.993863</td>\n",
       "      <td>0.929746</td>\n",
       "      <td>0.986981</td>\n",
       "      <td>0.965839</td>\n",
       "      <td>0.990410</td>\n",
       "      <td>0.947449</td>\n",
       "      <td>3610.0</td>\n",
       "      <td>644.0</td>\n",
       "      <td>3563</td>\n",
       "      <td>22</td>\n",
       "      <td>622</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>5</td>\n",
       "      <td>0.996350</td>\n",
       "      <td>0.907514</td>\n",
       "      <td>0.982286</td>\n",
       "      <td>0.979719</td>\n",
       "      <td>0.989268</td>\n",
       "      <td>0.942236</td>\n",
       "      <td>3613.0</td>\n",
       "      <td>641.0</td>\n",
       "      <td>3549</td>\n",
       "      <td>13</td>\n",
       "      <td>628</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>6</td>\n",
       "      <td>0.995784</td>\n",
       "      <td>0.899281</td>\n",
       "      <td>0.980626</td>\n",
       "      <td>0.976562</td>\n",
       "      <td>0.988147</td>\n",
       "      <td>0.936330</td>\n",
       "      <td>3613.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3543</td>\n",
       "      <td>15</td>\n",
       "      <td>625</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>7</td>\n",
       "      <td>0.995200</td>\n",
       "      <td>0.904360</td>\n",
       "      <td>0.981074</td>\n",
       "      <td>0.974242</td>\n",
       "      <td>0.988087</td>\n",
       "      <td>0.938001</td>\n",
       "      <td>3593.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3525</td>\n",
       "      <td>17</td>\n",
       "      <td>643</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>8</td>\n",
       "      <td>0.994091</td>\n",
       "      <td>0.928469</td>\n",
       "      <td>0.986045</td>\n",
       "      <td>0.968657</td>\n",
       "      <td>0.990052</td>\n",
       "      <td>0.948137</td>\n",
       "      <td>3583.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>3533</td>\n",
       "      <td>21</td>\n",
       "      <td>649</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>9</td>\n",
       "      <td>0.993548</td>\n",
       "      <td>0.928779</td>\n",
       "      <td>0.986355</td>\n",
       "      <td>0.965257</td>\n",
       "      <td>0.989939</td>\n",
       "      <td>0.946667</td>\n",
       "      <td>3591.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>3542</td>\n",
       "      <td>23</td>\n",
       "      <td>639</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>10</td>\n",
       "      <td>0.997483</td>\n",
       "      <td>0.933628</td>\n",
       "      <td>0.987538</td>\n",
       "      <td>0.985981</td>\n",
       "      <td>0.992485</td>\n",
       "      <td>0.959091</td>\n",
       "      <td>3611.0</td>\n",
       "      <td>642.0</td>\n",
       "      <td>3566</td>\n",
       "      <td>9</td>\n",
       "      <td>633</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>1</td>\n",
       "      <td>0.990461</td>\n",
       "      <td>0.984615</td>\n",
       "      <td>0.997530</td>\n",
       "      <td>0.942717</td>\n",
       "      <td>0.993982</td>\n",
       "      <td>0.963211</td>\n",
       "      <td>3643.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>3634</td>\n",
       "      <td>35</td>\n",
       "      <td>576</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>2</td>\n",
       "      <td>0.992879</td>\n",
       "      <td>0.988391</td>\n",
       "      <td>0.998073</td>\n",
       "      <td>0.958199</td>\n",
       "      <td>0.995469</td>\n",
       "      <td>0.973061</td>\n",
       "      <td>3632.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>3625</td>\n",
       "      <td>26</td>\n",
       "      <td>596</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>3</td>\n",
       "      <td>0.994213</td>\n",
       "      <td>0.990400</td>\n",
       "      <td>0.998340</td>\n",
       "      <td>0.967187</td>\n",
       "      <td>0.996272</td>\n",
       "      <td>0.978656</td>\n",
       "      <td>3614.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3608</td>\n",
       "      <td>21</td>\n",
       "      <td>619</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>4</td>\n",
       "      <td>0.991738</td>\n",
       "      <td>0.985554</td>\n",
       "      <td>0.997507</td>\n",
       "      <td>0.953416</td>\n",
       "      <td>0.994614</td>\n",
       "      <td>0.969219</td>\n",
       "      <td>3610.0</td>\n",
       "      <td>644.0</td>\n",
       "      <td>3601</td>\n",
       "      <td>30</td>\n",
       "      <td>614</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>5</td>\n",
       "      <td>0.993390</td>\n",
       "      <td>0.990369</td>\n",
       "      <td>0.998339</td>\n",
       "      <td>0.962559</td>\n",
       "      <td>0.995859</td>\n",
       "      <td>0.976266</td>\n",
       "      <td>3613.0</td>\n",
       "      <td>641.0</td>\n",
       "      <td>3607</td>\n",
       "      <td>24</td>\n",
       "      <td>617</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>6</td>\n",
       "      <td>0.993655</td>\n",
       "      <td>0.982484</td>\n",
       "      <td>0.996955</td>\n",
       "      <td>0.964063</td>\n",
       "      <td>0.995303</td>\n",
       "      <td>0.973186</td>\n",
       "      <td>3613.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3602</td>\n",
       "      <td>23</td>\n",
       "      <td>617</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>7</td>\n",
       "      <td>0.993082</td>\n",
       "      <td>0.993740</td>\n",
       "      <td>0.998887</td>\n",
       "      <td>0.962121</td>\n",
       "      <td>0.995976</td>\n",
       "      <td>0.977675</td>\n",
       "      <td>3593.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3589</td>\n",
       "      <td>25</td>\n",
       "      <td>635</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>8</td>\n",
       "      <td>0.991953</td>\n",
       "      <td>0.987673</td>\n",
       "      <td>0.997767</td>\n",
       "      <td>0.956716</td>\n",
       "      <td>0.994852</td>\n",
       "      <td>0.971948</td>\n",
       "      <td>3583.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>3575</td>\n",
       "      <td>29</td>\n",
       "      <td>641</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>9</td>\n",
       "      <td>0.991146</td>\n",
       "      <td>0.985915</td>\n",
       "      <td>0.997494</td>\n",
       "      <td>0.951662</td>\n",
       "      <td>0.994310</td>\n",
       "      <td>0.968486</td>\n",
       "      <td>3591.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>3582</td>\n",
       "      <td>32</td>\n",
       "      <td>630</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>DF8</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>10</td>\n",
       "      <td>0.995578</td>\n",
       "      <td>0.985827</td>\n",
       "      <td>0.997508</td>\n",
       "      <td>0.975078</td>\n",
       "      <td>0.996542</td>\n",
       "      <td>0.980423</td>\n",
       "      <td>3611.0</td>\n",
       "      <td>642.0</td>\n",
       "      <td>3602</td>\n",
       "      <td>16</td>\n",
       "      <td>626</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset                         model data balancing technique  fold  \\\n",
       "0      DF8  Fast Text - train_supervised                     None     1   \n",
       "1      DF8  Fast Text - train_supervised                     None     2   \n",
       "2      DF8  Fast Text - train_supervised                     None     3   \n",
       "3      DF8  Fast Text - train_supervised                     None     4   \n",
       "4      DF8  Fast Text - train_supervised                     None     5   \n",
       "5      DF8  Fast Text - train_supervised                     None     6   \n",
       "6      DF8  Fast Text - train_supervised                     None     7   \n",
       "7      DF8  Fast Text - train_supervised                     None     8   \n",
       "8      DF8  Fast Text - train_supervised                     None     9   \n",
       "9      DF8  Fast Text - train_supervised                     None    10   \n",
       "10     DF8  Fast Text - train_supervised     Random Under Sampler     1   \n",
       "11     DF8  Fast Text - train_supervised     Random Under Sampler     2   \n",
       "12     DF8  Fast Text - train_supervised     Random Under Sampler     3   \n",
       "13     DF8  Fast Text - train_supervised     Random Under Sampler     4   \n",
       "14     DF8  Fast Text - train_supervised     Random Under Sampler     5   \n",
       "15     DF8  Fast Text - train_supervised     Random Under Sampler     6   \n",
       "16     DF8  Fast Text - train_supervised     Random Under Sampler     7   \n",
       "17     DF8  Fast Text - train_supervised     Random Under Sampler     8   \n",
       "18     DF8  Fast Text - train_supervised     Random Under Sampler     9   \n",
       "19     DF8  Fast Text - train_supervised     Random Under Sampler    10   \n",
       "20     DF8  Fast Text - train_supervised      Random Over Sampler     1   \n",
       "21     DF8  Fast Text - train_supervised      Random Over Sampler     2   \n",
       "22     DF8  Fast Text - train_supervised      Random Over Sampler     3   \n",
       "23     DF8  Fast Text - train_supervised      Random Over Sampler     4   \n",
       "24     DF8  Fast Text - train_supervised      Random Over Sampler     5   \n",
       "25     DF8  Fast Text - train_supervised      Random Over Sampler     6   \n",
       "26     DF8  Fast Text - train_supervised      Random Over Sampler     7   \n",
       "27     DF8  Fast Text - train_supervised      Random Over Sampler     8   \n",
       "28     DF8  Fast Text - train_supervised      Random Over Sampler     9   \n",
       "29     DF8  Fast Text - train_supervised      Random Over Sampler    10   \n",
       "\n",
       "    precision_1  precision_2  recall_1  recall_2  f1-score_1  f1-score_2  \\\n",
       "0      0.990191     0.984589  0.997530  0.941080    0.993847    0.962343   \n",
       "1      0.992341     0.993311  0.998899  0.954984    0.995609    0.973770   \n",
       "2      0.993396     0.993548  0.998893  0.962500    0.996137    0.977778   \n",
       "3      0.991738     0.985554  0.997507  0.953416    0.994614    0.969219   \n",
       "4      0.993119     0.991948  0.998616  0.960998    0.995860    0.976228   \n",
       "5      0.993111     0.985577  0.997509  0.960938    0.995305    0.973101   \n",
       "6      0.991985     0.993701  0.998887  0.956061    0.995424    0.974517   \n",
       "7      0.991133     0.990683  0.998325  0.952239    0.994716    0.971081   \n",
       "8      0.989244     0.993620  0.998886  0.941088    0.994042    0.966641   \n",
       "9      0.994483     0.990446  0.998338  0.968847    0.996407    0.979528   \n",
       "10     0.994455     0.913447  0.984628  0.967267    0.989517    0.939587   \n",
       "11     0.995834     0.929556  0.987335  0.975884    0.991566    0.952157   \n",
       "12     0.995822     0.941265  0.989209  0.976562    0.992504    0.958589   \n",
       "13     0.993863     0.929746  0.986981  0.965839    0.990410    0.947449   \n",
       "14     0.996350     0.907514  0.982286  0.979719    0.989268    0.942236   \n",
       "15     0.995784     0.899281  0.980626  0.976562    0.988147    0.936330   \n",
       "16     0.995200     0.904360  0.981074  0.974242    0.988087    0.938001   \n",
       "17     0.994091     0.928469  0.986045  0.968657    0.990052    0.948137   \n",
       "18     0.993548     0.928779  0.986355  0.965257    0.989939    0.946667   \n",
       "19     0.997483     0.933628  0.987538  0.985981    0.992485    0.959091   \n",
       "20     0.990461     0.984615  0.997530  0.942717    0.993982    0.963211   \n",
       "21     0.992879     0.988391  0.998073  0.958199    0.995469    0.973061   \n",
       "22     0.994213     0.990400  0.998340  0.967187    0.996272    0.978656   \n",
       "23     0.991738     0.985554  0.997507  0.953416    0.994614    0.969219   \n",
       "24     0.993390     0.990369  0.998339  0.962559    0.995859    0.976266   \n",
       "25     0.993655     0.982484  0.996955  0.964063    0.995303    0.973186   \n",
       "26     0.993082     0.993740  0.998887  0.962121    0.995976    0.977675   \n",
       "27     0.991953     0.987673  0.997767  0.956716    0.994852    0.971948   \n",
       "28     0.991146     0.985915  0.997494  0.951662    0.994310    0.968486   \n",
       "29     0.995578     0.985827  0.997508  0.975078    0.996542    0.980423   \n",
       "\n",
       "    support_1  support_2    TP  FP   TN  FN  \n",
       "0      3643.0      611.0  3634  36  575   9  \n",
       "1      3632.0      622.0  3628  28  594   4  \n",
       "2      3614.0      640.0  3610  24  616   4  \n",
       "3      3610.0      644.0  3601  30  614   9  \n",
       "4      3613.0      641.0  3608  25  616   5  \n",
       "5      3613.0      640.0  3604  25  615   9  \n",
       "6      3593.0      660.0  3589  29  631   4  \n",
       "7      3583.0      670.0  3577  32  638   6  \n",
       "8      3591.0      662.0  3587  39  623   4  \n",
       "9      3611.0      642.0  3605  20  622   6  \n",
       "10     3643.0      611.0  3587  20  591  56  \n",
       "11     3632.0      622.0  3586  15  607  46  \n",
       "12     3614.0      640.0  3575  15  625  39  \n",
       "13     3610.0      644.0  3563  22  622  47  \n",
       "14     3613.0      641.0  3549  13  628  64  \n",
       "15     3613.0      640.0  3543  15  625  70  \n",
       "16     3593.0      660.0  3525  17  643  68  \n",
       "17     3583.0      670.0  3533  21  649  50  \n",
       "18     3591.0      662.0  3542  23  639  49  \n",
       "19     3611.0      642.0  3566   9  633  45  \n",
       "20     3643.0      611.0  3634  35  576   9  \n",
       "21     3632.0      622.0  3625  26  596   7  \n",
       "22     3614.0      640.0  3608  21  619   6  \n",
       "23     3610.0      644.0  3601  30  614   9  \n",
       "24     3613.0      641.0  3607  24  617   6  \n",
       "25     3613.0      640.0  3602  23  617  11  \n",
       "26     3593.0      660.0  3589  25  635   4  \n",
       "27     3583.0      670.0  3575  29  641   8  \n",
       "28     3591.0      662.0  3582  32  630   9  \n",
       "29     3611.0      642.0  3602  16  626   9  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8905e922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame\n",
    "combined_metrics.to_csv('Output Data/Fast Text - train_supervised2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2bf0bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
