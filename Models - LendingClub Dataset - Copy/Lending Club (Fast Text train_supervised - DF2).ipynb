{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d2c91a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f460afa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "import numpy as np\n",
    "from pprint import pprint as pp\n",
    "import csv\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "from itertools import product\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from imblearn.pipeline import Pipeline \n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import r2_score, classification_report, confusion_matrix, accuracy_score, roc_auc_score, roc_curve, precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import homogeneity_score, silhouette_score\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import MiniBatchKMeans, DBSCAN\n",
    "import fasttext\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17e9cee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, precision_score, recall_score, f1_score, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6238cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, precision_score, recall_score, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75e8fc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.combine import SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "378df2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0db62d0",
   "metadata": {},
   "source": [
    "### Retrieving the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10513ea6",
   "metadata": {},
   "source": [
    "#### DF 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc3d2069",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('df5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82ed7cb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>emp_title</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>issue_d</th>\n",
       "      <th>pymnt_plan</th>\n",
       "      <th>purpose</th>\n",
       "      <th>title</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>addr_state</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>earliest_cr_line</th>\n",
       "      <th>fico_range_low</th>\n",
       "      <th>fico_range_high</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>mths_since_last_delinq</th>\n",
       "      <th>mths_since_last_record</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>revol_bal</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>total_acc</th>\n",
       "      <th>out_prncp</th>\n",
       "      <th>out_prncp_inv</th>\n",
       "      <th>total_pymnt</th>\n",
       "      <th>total_pymnt_inv</th>\n",
       "      <th>total_rec_prncp</th>\n",
       "      <th>total_rec_int</th>\n",
       "      <th>total_rec_late_fee</th>\n",
       "      <th>recoveries</th>\n",
       "      <th>collection_recovery_fee</th>\n",
       "      <th>last_pymnt_d</th>\n",
       "      <th>last_pymnt_amnt</th>\n",
       "      <th>next_pymnt_d</th>\n",
       "      <th>last_credit_pull_d</th>\n",
       "      <th>last_fico_range_high</th>\n",
       "      <th>last_fico_range_low</th>\n",
       "      <th>collections_12_mths_ex_med</th>\n",
       "      <th>acc_now_delinq</th>\n",
       "      <th>chargeoff_within_12_mths</th>\n",
       "      <th>delinq_amnt</th>\n",
       "      <th>pub_rec_bankruptcies</th>\n",
       "      <th>tax_liens</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1077501.0</td>\n",
       "      <td>1296599.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>4975.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1065</td>\n",
       "      <td>162.87</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>25275</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3160</td>\n",
       "      <td>860</td>\n",
       "      <td>3</td>\n",
       "      <td>27.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>735.0</td>\n",
       "      <td>739.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13648.0</td>\n",
       "      <td>0.837</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5863.155187</td>\n",
       "      <td>5833.84</td>\n",
       "      <td>5000.00</td>\n",
       "      <td>863.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>171.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>744.0</td>\n",
       "      <td>740.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1077430.0</td>\n",
       "      <td>1314167.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1527</td>\n",
       "      <td>59.83</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>20173</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17558</td>\n",
       "      <td>309</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>740.0</td>\n",
       "      <td>744.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1687.0</td>\n",
       "      <td>0.094</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1008.710000</td>\n",
       "      <td>1008.71</td>\n",
       "      <td>456.46</td>\n",
       "      <td>435.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117.08</td>\n",
       "      <td>1.11</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>119.66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>499.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         id  member_id  loan_amnt  funded_amnt  funded_amnt_inv  \\\n",
       "0           0  1077501.0  1296599.0     5000.0       5000.0           4975.0   \n",
       "1           1  1077430.0  1314167.0     2500.0       2500.0           2500.0   \n",
       "\n",
       "   term  int_rate  installment  grade  sub_grade  emp_title  emp_length  \\\n",
       "0     0    0.1065       162.87      1          6      25275        10.0   \n",
       "1     1    0.1527        59.83      2         13      20173         1.0   \n",
       "\n",
       "   home_ownership  annual_inc  verification_status  issue_d  pymnt_plan  \\\n",
       "0               4     24000.0                    2   2011.0           0   \n",
       "1               4     30000.0                    1   2011.0           0   \n",
       "\n",
       "   purpose  title  zip_code  addr_state    dti  delinq_2yrs  earliest_cr_line  \\\n",
       "0        1   3160       860           3  27.65          0.0            1985.0   \n",
       "1        0  17558       309          10   1.00          0.0            1999.0   \n",
       "\n",
       "   fico_range_low  fico_range_high  inq_last_6mths  mths_since_last_delinq  \\\n",
       "0           735.0            739.0             1.0                   500.0   \n",
       "1           740.0            744.0             5.0                   500.0   \n",
       "\n",
       "   mths_since_last_record  open_acc  pub_rec  revol_bal  revol_util  \\\n",
       "0                   222.0       3.0      0.0    13648.0       0.837   \n",
       "1                   222.0       3.0      0.0     1687.0       0.094   \n",
       "\n",
       "   total_acc  out_prncp  out_prncp_inv  total_pymnt  total_pymnt_inv  \\\n",
       "0        9.0        0.0            0.0  5863.155187          5833.84   \n",
       "1        4.0        0.0            0.0  1008.710000          1008.71   \n",
       "\n",
       "   total_rec_prncp  total_rec_int  total_rec_late_fee  recoveries  \\\n",
       "0          5000.00         863.16                 0.0        0.00   \n",
       "1           456.46         435.17                 0.0      117.08   \n",
       "\n",
       "   collection_recovery_fee  last_pymnt_d  last_pymnt_amnt  next_pymnt_d  \\\n",
       "0                     0.00        2015.0           171.62           0.0   \n",
       "1                     1.11        2013.0           119.66           0.0   \n",
       "\n",
       "   last_credit_pull_d  last_fico_range_high  last_fico_range_low  \\\n",
       "0              2016.0                 744.0                740.0   \n",
       "1              2016.0                 499.0                  0.0   \n",
       "\n",
       "   collections_12_mths_ex_med  acc_now_delinq  chargeoff_within_12_mths  \\\n",
       "0                           0               0                         0   \n",
       "1                           0               0                         0   \n",
       "\n",
       "   delinq_amnt  pub_rec_bankruptcies  tax_liens  target  \n",
       "0          0.0                   0.0          0       1  \n",
       "1          0.0                   0.0          0       2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f9963f",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b0bea07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store evaluation metrics for each fold\n",
    "dataset_used = []\n",
    "model_used = []\n",
    "data_balancing_technique = []\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "conf_matrices = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e6d6d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combined_metrics = pd.DataFrame()\n",
    "\n",
    "combined_metrics = pd.DataFrame(columns=['dataset', 'model', 'data balancing technique', 'fold', 'precision_1','precision_2','recall_1','recall_2','f1-score_1','f1-score_2','support_1','support_2','TP','FP','TN','FN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052cda7c",
   "metadata": {},
   "source": [
    "# Fast Text \n",
    "### train_supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0914ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "dim = 300  # Dimension of word vectors\n",
    "min_count = 1  # Minimum frequency of words\n",
    "loss = 'ns'  # Hierarchical softmax loss #'hs', 'ns', 'softmax'\n",
    "epoch = 100  # Number of training epochs\n",
    "bucket = 2000000  # Number of buckets used for hashing n-grams\n",
    "word_ngrams = 1  # Maximum length of word n-grams\n",
    "lr = 0.5 #0.1, 0.01, 0.001 #learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedf6e11",
   "metadata": {},
   "source": [
    "## DF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89f99b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.92\n",
      "Mean Precision: 0.92\n",
      "Mean Recall: 0.92\n",
      "Mean F1-Score: 0.92\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df2' is your DataFrame with features and the target column\n",
    "# Replace 'features' with the actual list of feature columns\n",
    "features = df2.drop(columns=['target'])  # Drop the target column to get the feature columns\n",
    "target = '__label__' + df2['target'].astype(str)\n",
    "\n",
    "# Initialize KFold with 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    # Create a new column \"content\" by concatenating values from selected columns\n",
    "    X_train['content'] = y_train + ' ' + X_train.apply(lambda row: ' '.join(str(val) for val in row), axis=1)\n",
    "    X_test['content'] = X_test.apply(lambda row: ' '.join(str(val) for val in row), axis=1)\n",
    "    \n",
    "    X_train = X_train['content']\n",
    "    X_test = X_test['content']\n",
    "    \n",
    "    X_train_list = [value for value in X_train]\n",
    "    \n",
    "    # Save training data to a file\n",
    "    with open(\"train_german_fast_text.txt\", \"w\") as f:\n",
    "        for line in X_train_list:\n",
    "            f.write(line + \"\\n\")\n",
    "\n",
    "    # Training data file path\n",
    "    train_data_path = \"train_german_fast_text.txt\"\n",
    "    \n",
    "    # Train the supervised model\n",
    "    model = fasttext.train_supervised(input=train_data_path, dim=dim, minCount=min_count,bucket=bucket, loss=loss, epoch=epoch, wordNgrams=word_ngrams)#lr=lr, \n",
    "                                       #lr=lr,bucket=bucket,\n",
    "    \n",
    "    # Predict on the testing set\n",
    "    # Initialize an empty list to store the predicted labels\n",
    "    y_pred_list = []\n",
    "\n",
    "    # Iterate over each data point in X_test and predict the label\n",
    "    for text in X_test:\n",
    "        # Predict the label for the current text\n",
    "        predicted_label, _ = model.predict(text)\n",
    "        # Append the predicted label to the list\n",
    "        y_pred_list.append(predicted_label[0])\n",
    "\n",
    "    # Convert the list of predicted labels to a pandas Series\n",
    "    y_pred = pd.Series(y_pred_list)\n",
    "    \n",
    "    #y_pred = np.round(y_pred)\n",
    "    \n",
    "    #y_pred[y_pred <= 0] = 1\n",
    "    #y_pred[y_pred >= 2] = 2\n",
    "    \n",
    "    # Extract the numeric label using a lambda function\n",
    "    y_test = y_test.apply(lambda x: int(x.split(\"__label__\")[1]))  ## uncomment for next run\n",
    "    y_pred = y_pred.apply(lambda x: int(x.split(\"__label__\")[1]))\n",
    "    \n",
    "    # Model evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred.round())\n",
    "    precision = precision_score(y_test, y_pred.round(), average='weighted')\n",
    "    recall = recall_score(y_test, y_pred.round(), average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred.round(), average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred.round())\n",
    "    \n",
    "    \n",
    "    # Convert classification report to DataFrame\n",
    "    report_df = pd.DataFrame(classification_report(y_test, y_pred.round(), output_dict=True)).transpose()\n",
    "    # Convert confusion matrix to DataFrame\n",
    "    matrix_df = pd.DataFrame(confusion_matrix(y_test, y_pred.round()))\n",
    "    \n",
    "    # Extract metrics for class 1\n",
    "    metrics_1 = report_df.loc['1', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract metrics for class 2\n",
    "    metrics_2 = report_df.loc['2', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract TP, TN, FP, FN counts from the confusion matrix DataFrame\n",
    "    TP = matrix_df.loc[0, 0]\n",
    "    TN = matrix_df.loc[1, 1]\n",
    "    FP = matrix_df.loc[1, 0]\n",
    "    FN = matrix_df.loc[0, 1]\n",
    "    \n",
    "    new_metric_row = {\n",
    "    'dataset': 'DF2',\n",
    "    'model' : 'Fast Text - train_supervised',\n",
    "    'data balancing technique' : 'None',\n",
    "    'fold' : i,\n",
    "    'precision_1': metrics_1['precision'],\n",
    "    'precision_2': metrics_2['precision'],\n",
    "    'recall_1': metrics_1['recall'],\n",
    "    'recall_2': metrics_2['recall'],\n",
    "    'f1-score_1': metrics_1['f1-score'],\n",
    "    'f1-score_2': metrics_2['f1-score'],\n",
    "    'support_1': metrics_1['support'],\n",
    "    'support_2': metrics_2['support'],\n",
    "    'TP' : TP,\n",
    "    'FP' : FP,\n",
    "    'TN' : TN,\n",
    "    'FN' : FN\n",
    "    }\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    #combined_metrics = combined_metrics.append(new_metric_row, ignore_index=True)\n",
    "    combined_metrics.loc[len(combined_metrics)] = new_metric_row\n",
    "    \n",
    "    \n",
    "    # Append evaluation metrics to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "\n",
    "# Calculate mean evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores) #sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = np.mean(precision_scores) #sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = np.mean(recall_scores) #sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = np.mean(f1_scores) #sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print('Mean Accuracy: {:.2f}'.format(mean_accuracy))\n",
    "print('Mean Precision: {:.2f}'.format(mean_precision))\n",
    "print('Mean Recall: {:.2f}'.format(mean_recall))\n",
    "print('Mean F1-Score: {:.2f}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5cd58d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>data balancing technique</th>\n",
       "      <th>fold</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_2</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>f1-score_1</th>\n",
       "      <th>f1-score_2</th>\n",
       "      <th>support_1</th>\n",
       "      <th>support_2</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DF2</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0.940644</td>\n",
       "      <td>0.780684</td>\n",
       "      <td>0.970080</td>\n",
       "      <td>0.635025</td>\n",
       "      <td>0.955135</td>\n",
       "      <td>0.700361</td>\n",
       "      <td>3643.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>3534</td>\n",
       "      <td>223</td>\n",
       "      <td>388</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DF2</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>0.941240</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.965859</td>\n",
       "      <td>0.647910</td>\n",
       "      <td>0.953390</td>\n",
       "      <td>0.701480</td>\n",
       "      <td>3632.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>3508</td>\n",
       "      <td>219</td>\n",
       "      <td>403</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DF2</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>0.936682</td>\n",
       "      <td>0.788650</td>\n",
       "      <td>0.970116</td>\n",
       "      <td>0.629687</td>\n",
       "      <td>0.953106</td>\n",
       "      <td>0.700261</td>\n",
       "      <td>3614.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3506</td>\n",
       "      <td>237</td>\n",
       "      <td>403</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DF2</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>0.938341</td>\n",
       "      <td>0.768519</td>\n",
       "      <td>0.965374</td>\n",
       "      <td>0.644410</td>\n",
       "      <td>0.951666</td>\n",
       "      <td>0.701014</td>\n",
       "      <td>3610.0</td>\n",
       "      <td>644.0</td>\n",
       "      <td>3485</td>\n",
       "      <td>229</td>\n",
       "      <td>415</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DF2</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>0.943019</td>\n",
       "      <td>0.780399</td>\n",
       "      <td>0.966510</td>\n",
       "      <td>0.670827</td>\n",
       "      <td>0.954620</td>\n",
       "      <td>0.721477</td>\n",
       "      <td>3613.0</td>\n",
       "      <td>641.0</td>\n",
       "      <td>3492</td>\n",
       "      <td>211</td>\n",
       "      <td>430</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DF2</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>0.946943</td>\n",
       "      <td>0.820370</td>\n",
       "      <td>0.973153</td>\n",
       "      <td>0.692187</td>\n",
       "      <td>0.959869</td>\n",
       "      <td>0.750847</td>\n",
       "      <td>3613.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3516</td>\n",
       "      <td>197</td>\n",
       "      <td>443</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DF2</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>None</td>\n",
       "      <td>7</td>\n",
       "      <td>0.939925</td>\n",
       "      <td>0.807763</td>\n",
       "      <td>0.971055</td>\n",
       "      <td>0.662121</td>\n",
       "      <td>0.955236</td>\n",
       "      <td>0.727727</td>\n",
       "      <td>3593.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3489</td>\n",
       "      <td>223</td>\n",
       "      <td>437</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DF2</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>None</td>\n",
       "      <td>8</td>\n",
       "      <td>0.938255</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.975440</td>\n",
       "      <td>0.656716</td>\n",
       "      <td>0.956486</td>\n",
       "      <td>0.734558</td>\n",
       "      <td>3583.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>3495</td>\n",
       "      <td>230</td>\n",
       "      <td>440</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DF2</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>None</td>\n",
       "      <td>9</td>\n",
       "      <td>0.944037</td>\n",
       "      <td>0.797203</td>\n",
       "      <td>0.967697</td>\n",
       "      <td>0.688822</td>\n",
       "      <td>0.955721</td>\n",
       "      <td>0.739060</td>\n",
       "      <td>3591.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>3475</td>\n",
       "      <td>206</td>\n",
       "      <td>456</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DF2</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.931419</td>\n",
       "      <td>0.782077</td>\n",
       "      <td>0.970368</td>\n",
       "      <td>0.598131</td>\n",
       "      <td>0.950495</td>\n",
       "      <td>0.677846</td>\n",
       "      <td>3611.0</td>\n",
       "      <td>642.0</td>\n",
       "      <td>3504</td>\n",
       "      <td>258</td>\n",
       "      <td>384</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset                         model data balancing technique  fold  \\\n",
       "0     DF2  Fast Text - train_supervised                     None     1   \n",
       "1     DF2  Fast Text - train_supervised                     None     2   \n",
       "2     DF2  Fast Text - train_supervised                     None     3   \n",
       "3     DF2  Fast Text - train_supervised                     None     4   \n",
       "4     DF2  Fast Text - train_supervised                     None     5   \n",
       "5     DF2  Fast Text - train_supervised                     None     6   \n",
       "6     DF2  Fast Text - train_supervised                     None     7   \n",
       "7     DF2  Fast Text - train_supervised                     None     8   \n",
       "8     DF2  Fast Text - train_supervised                     None     9   \n",
       "9     DF2  Fast Text - train_supervised                     None    10   \n",
       "\n",
       "   precision_1  precision_2  recall_1  recall_2  f1-score_1  f1-score_2  \\\n",
       "0     0.940644     0.780684  0.970080  0.635025    0.955135    0.700361   \n",
       "1     0.941240     0.764706  0.965859  0.647910    0.953390    0.701480   \n",
       "2     0.936682     0.788650  0.970116  0.629687    0.953106    0.700261   \n",
       "3     0.938341     0.768519  0.965374  0.644410    0.951666    0.701014   \n",
       "4     0.943019     0.780399  0.966510  0.670827    0.954620    0.721477   \n",
       "5     0.946943     0.820370  0.973153  0.692187    0.959869    0.750847   \n",
       "6     0.939925     0.807763  0.971055  0.662121    0.955236    0.727727   \n",
       "7     0.938255     0.833333  0.975440  0.656716    0.956486    0.734558   \n",
       "8     0.944037     0.797203  0.967697  0.688822    0.955721    0.739060   \n",
       "9     0.931419     0.782077  0.970368  0.598131    0.950495    0.677846   \n",
       "\n",
       "   support_1  support_2    TP   FP   TN   FN  \n",
       "0     3643.0      611.0  3534  223  388  109  \n",
       "1     3632.0      622.0  3508  219  403  124  \n",
       "2     3614.0      640.0  3506  237  403  108  \n",
       "3     3610.0      644.0  3485  229  415  125  \n",
       "4     3613.0      641.0  3492  211  430  121  \n",
       "5     3613.0      640.0  3516  197  443   97  \n",
       "6     3593.0      660.0  3489  223  437  104  \n",
       "7     3583.0      670.0  3495  230  440   88  \n",
       "8     3591.0      662.0  3475  206  456  116  \n",
       "9     3611.0      642.0  3504  258  384  107  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_metrics[(combined_metrics['data balancing technique'] == 'None') & (combined_metrics['dataset'] == 'DF2')]#.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737bdf77",
   "metadata": {},
   "source": [
    "### FastText train_supervised with df2 data and imbalance data tackling (RandomUnderSampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0efc30fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.90\n",
      "Mean Precision: 0.91\n",
      "Mean Recall: 0.90\n",
      "Mean F1-Score: 0.90\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df2' is your DataFrame with features and the target column\n",
    "# Replace 'features' with the actual list of feature columns\n",
    "features = df2.drop(columns=['target'])  # Drop the target column to get the feature columns\n",
    "target = '__label__' + df2['target'].astype(str)\n",
    "\n",
    "# Initialize KFold with 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    # Oversampling the minority class using SMOTE\n",
    "    rus = RandomUnderSampler(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Create a new column \"content\" by concatenating values from selected columns\n",
    "    X_train_resampled['content'] = y_train_resampled + ' ' + X_train_resampled.apply(lambda row: ' '.join(str(val) for val in row), axis=1)\n",
    "    X_test['content'] = X_test.apply(lambda row: ' '.join(str(val) for val in row), axis=1)\n",
    "    \n",
    "    X_train = X_train_resampled['content']\n",
    "    X_test = X_test['content']\n",
    "    \n",
    "    X_train_list = [value for value in X_train]\n",
    "    \n",
    "    # Save training data to a file\n",
    "    with open(\"train_german_fast_text.txt\", \"w\") as f:\n",
    "        for line in X_train_list:\n",
    "            f.write(line + \"\\n\")\n",
    "\n",
    "    # Training data file path\n",
    "    train_data_path = \"train_german_fast_text.txt\"\n",
    "    \n",
    "    # Train the supervised model\n",
    "    model = fasttext.train_supervised(input=train_data_path, dim=dim, minCount=min_count,bucket=bucket, loss=loss, epoch=epoch, wordNgrams=word_ngrams)#lr=lr, \n",
    "                                       #lr=lr,bucket=bucket,\n",
    "    \n",
    "    # Predict on the testing set\n",
    "    # Initialize an empty list to store the predicted labels\n",
    "    y_pred_list = []\n",
    "\n",
    "    # Iterate over each data point in X_test and predict the label\n",
    "    for text in X_test:\n",
    "        # Predict the label for the current text\n",
    "        predicted_label, _ = model.predict(text)\n",
    "        # Append the predicted label to the list\n",
    "        y_pred_list.append(predicted_label[0])\n",
    "\n",
    "    # Convert the list of predicted labels to a pandas Series\n",
    "    y_pred = pd.Series(y_pred_list)\n",
    "    \n",
    "    # Extract the numeric label using a lambda function\n",
    "    y_test = y_test.apply(lambda x: int(x.split(\"__label__\")[1]))  ## uncomment for next run\n",
    "    y_pred = y_pred.apply(lambda x: int(x.split(\"__label__\")[1]))\n",
    "    \n",
    "    # Model evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred.round())\n",
    "    precision = precision_score(y_test, y_pred.round(), average='weighted')\n",
    "    recall = recall_score(y_test, y_pred.round(), average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred.round(), average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred.round())\n",
    "    \n",
    "    \n",
    "    # Convert classification report to DataFrame\n",
    "    report_df = pd.DataFrame(classification_report(y_test, y_pred.round(), output_dict=True)).transpose()\n",
    "    # Convert confusion matrix to DataFrame\n",
    "    matrix_df = pd.DataFrame(confusion_matrix(y_test, y_pred.round()))\n",
    "    \n",
    "    # Extract metrics for class 1\n",
    "    metrics_1 = report_df.loc['1', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract metrics for class 2\n",
    "    metrics_2 = report_df.loc['2', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract TP, TN, FP, FN counts from the confusion matrix DataFrame\n",
    "    TP = matrix_df.loc[0, 0]\n",
    "    TN = matrix_df.loc[1, 1]\n",
    "    FP = matrix_df.loc[1, 0]\n",
    "    FN = matrix_df.loc[0, 1]\n",
    "    \n",
    "    new_metric_row = {\n",
    "    'dataset': 'DF2',\n",
    "    'model' : 'Fast Text - train_supervised',\n",
    "    'data balancing technique' : 'Random Under Sampler',\n",
    "    'fold' : i,\n",
    "    'precision_1': metrics_1['precision'],\n",
    "    'precision_2': metrics_2['precision'],\n",
    "    'recall_1': metrics_1['recall'],\n",
    "    'recall_2': metrics_2['recall'],\n",
    "    'f1-score_1': metrics_1['f1-score'],\n",
    "    'f1-score_2': metrics_2['f1-score'],\n",
    "    'support_1': metrics_1['support'],\n",
    "    'support_2': metrics_2['support'],\n",
    "    'TP' : TP,\n",
    "    'FP' : FP,\n",
    "    'TN' : TN,\n",
    "    'FN' : FN\n",
    "    }\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    #combined_metrics = combined_metrics.append(new_metric_row, ignore_index=True)\n",
    "    combined_metrics.loc[len(combined_metrics)] = new_metric_row\n",
    "    \n",
    "    \n",
    "    # Append evaluation metrics to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "\n",
    "# Calculate mean evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores) #sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = np.mean(precision_scores) #sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = np.mean(recall_scores) #sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = np.mean(f1_scores) #sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print('Mean Accuracy: {:.2f}'.format(mean_accuracy))\n",
    "print('Mean Precision: {:.2f}'.format(mean_precision))\n",
    "print('Mean Recall: {:.2f}'.format(mean_recall))\n",
    "print('Mean F1-Score: {:.2f}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d72cc02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>data balancing technique</th>\n",
       "      <th>fold</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_2</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>f1-score_1</th>\n",
       "      <th>f1-score_2</th>\n",
       "      <th>support_1</th>\n",
       "      <th>support_2</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DF2</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>1</td>\n",
       "      <td>0.977832</td>\n",
       "      <td>0.559834</td>\n",
       "      <td>0.883887</td>\n",
       "      <td>0.880524</td>\n",
       "      <td>0.928489</td>\n",
       "      <td>0.684478</td>\n",
       "      <td>3643.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>3220</td>\n",
       "      <td>73</td>\n",
       "      <td>538</td>\n",
       "      <td>423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DF2</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>2</td>\n",
       "      <td>0.982573</td>\n",
       "      <td>0.516393</td>\n",
       "      <td>0.853800</td>\n",
       "      <td>0.911576</td>\n",
       "      <td>0.913671</td>\n",
       "      <td>0.659302</td>\n",
       "      <td>3632.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>3101</td>\n",
       "      <td>55</td>\n",
       "      <td>567</td>\n",
       "      <td>531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DF2</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>3</td>\n",
       "      <td>0.975248</td>\n",
       "      <td>0.547945</td>\n",
       "      <td>0.872164</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.920830</td>\n",
       "      <td>0.673887</td>\n",
       "      <td>3614.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3152</td>\n",
       "      <td>80</td>\n",
       "      <td>560</td>\n",
       "      <td>462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DF2</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>4</td>\n",
       "      <td>0.978192</td>\n",
       "      <td>0.527523</td>\n",
       "      <td>0.857341</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.913788</td>\n",
       "      <td>0.663206</td>\n",
       "      <td>3610.0</td>\n",
       "      <td>644.0</td>\n",
       "      <td>3095</td>\n",
       "      <td>69</td>\n",
       "      <td>575</td>\n",
       "      <td>515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DF2</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>5</td>\n",
       "      <td>0.977123</td>\n",
       "      <td>0.534337</td>\n",
       "      <td>0.862995</td>\n",
       "      <td>0.886115</td>\n",
       "      <td>0.916520</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>3613.0</td>\n",
       "      <td>641.0</td>\n",
       "      <td>3118</td>\n",
       "      <td>73</td>\n",
       "      <td>568</td>\n",
       "      <td>495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>DF2</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>6</td>\n",
       "      <td>0.978158</td>\n",
       "      <td>0.521938</td>\n",
       "      <td>0.855245</td>\n",
       "      <td>0.892188</td>\n",
       "      <td>0.912581</td>\n",
       "      <td>0.658593</td>\n",
       "      <td>3613.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3090</td>\n",
       "      <td>69</td>\n",
       "      <td>571</td>\n",
       "      <td>523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DF2</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>7</td>\n",
       "      <td>0.973864</td>\n",
       "      <td>0.554379</td>\n",
       "      <td>0.871138</td>\n",
       "      <td>0.872727</td>\n",
       "      <td>0.919642</td>\n",
       "      <td>0.678046</td>\n",
       "      <td>3593.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3130</td>\n",
       "      <td>84</td>\n",
       "      <td>576</td>\n",
       "      <td>463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DF2</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>8</td>\n",
       "      <td>0.976577</td>\n",
       "      <td>0.566127</td>\n",
       "      <td>0.872732</td>\n",
       "      <td>0.888060</td>\n",
       "      <td>0.921739</td>\n",
       "      <td>0.691458</td>\n",
       "      <td>3583.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>3127</td>\n",
       "      <td>75</td>\n",
       "      <td>595</td>\n",
       "      <td>456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>DF2</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>9</td>\n",
       "      <td>0.983943</td>\n",
       "      <td>0.537313</td>\n",
       "      <td>0.853244</td>\n",
       "      <td>0.924471</td>\n",
       "      <td>0.913945</td>\n",
       "      <td>0.679622</td>\n",
       "      <td>3591.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>3064</td>\n",
       "      <td>50</td>\n",
       "      <td>612</td>\n",
       "      <td>527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DF2</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>10</td>\n",
       "      <td>0.973814</td>\n",
       "      <td>0.553128</td>\n",
       "      <td>0.875381</td>\n",
       "      <td>0.867601</td>\n",
       "      <td>0.921978</td>\n",
       "      <td>0.675561</td>\n",
       "      <td>3611.0</td>\n",
       "      <td>642.0</td>\n",
       "      <td>3161</td>\n",
       "      <td>85</td>\n",
       "      <td>557</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset                         model data balancing technique  fold  \\\n",
       "10     DF2  Fast Text - train_supervised     Random Under Sampler     1   \n",
       "11     DF2  Fast Text - train_supervised     Random Under Sampler     2   \n",
       "12     DF2  Fast Text - train_supervised     Random Under Sampler     3   \n",
       "13     DF2  Fast Text - train_supervised     Random Under Sampler     4   \n",
       "14     DF2  Fast Text - train_supervised     Random Under Sampler     5   \n",
       "15     DF2  Fast Text - train_supervised     Random Under Sampler     6   \n",
       "16     DF2  Fast Text - train_supervised     Random Under Sampler     7   \n",
       "17     DF2  Fast Text - train_supervised     Random Under Sampler     8   \n",
       "18     DF2  Fast Text - train_supervised     Random Under Sampler     9   \n",
       "19     DF2  Fast Text - train_supervised     Random Under Sampler    10   \n",
       "\n",
       "    precision_1  precision_2  recall_1  recall_2  f1-score_1  f1-score_2  \\\n",
       "10     0.977832     0.559834  0.883887  0.880524    0.928489    0.684478   \n",
       "11     0.982573     0.516393  0.853800  0.911576    0.913671    0.659302   \n",
       "12     0.975248     0.547945  0.872164  0.875000    0.920830    0.673887   \n",
       "13     0.978192     0.527523  0.857341  0.892857    0.913788    0.663206   \n",
       "14     0.977123     0.534337  0.862995  0.886115    0.916520    0.666667   \n",
       "15     0.978158     0.521938  0.855245  0.892188    0.912581    0.658593   \n",
       "16     0.973864     0.554379  0.871138  0.872727    0.919642    0.678046   \n",
       "17     0.976577     0.566127  0.872732  0.888060    0.921739    0.691458   \n",
       "18     0.983943     0.537313  0.853244  0.924471    0.913945    0.679622   \n",
       "19     0.973814     0.553128  0.875381  0.867601    0.921978    0.675561   \n",
       "\n",
       "    support_1  support_2    TP  FP   TN   FN  \n",
       "10     3643.0      611.0  3220  73  538  423  \n",
       "11     3632.0      622.0  3101  55  567  531  \n",
       "12     3614.0      640.0  3152  80  560  462  \n",
       "13     3610.0      644.0  3095  69  575  515  \n",
       "14     3613.0      641.0  3118  73  568  495  \n",
       "15     3613.0      640.0  3090  69  571  523  \n",
       "16     3593.0      660.0  3130  84  576  463  \n",
       "17     3583.0      670.0  3127  75  595  456  \n",
       "18     3591.0      662.0  3064  50  612  527  \n",
       "19     3611.0      642.0  3161  85  557  450  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_metrics[(combined_metrics['data balancing technique'] == 'Random Under Sampler') & (combined_metrics['dataset'] == 'DF2')]#.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc10646",
   "metadata": {},
   "source": [
    "### FastText train_supervised with df2 data and imbalance data tackling (RandomOverSampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c500a1fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.90\n",
      "Mean Precision: 0.92\n",
      "Mean Recall: 0.90\n",
      "Mean F1-Score: 0.91\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df2' is your DataFrame with features and the target column\n",
    "# Replace 'features' with the actual list of feature columns\n",
    "features = df2.drop(columns=['target'])  # Drop the target column to get the feature columns\n",
    "target = '__label__' + df2['target'].astype(str)\n",
    "\n",
    "# Initialize KFold with 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    # Oversampling the minority class using SMOTE\n",
    "    ros = RandomOverSampler(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Create a new column \"content\" by concatenating values from selected columns\n",
    "    X_train_resampled['content'] = y_train_resampled + ' ' + X_train_resampled.apply(lambda row: ' '.join(str(val) for val in row), axis=1)\n",
    "    X_test['content'] = X_test.apply(lambda row: ' '.join(str(val) for val in row), axis=1)\n",
    "    \n",
    "    X_train = X_train_resampled['content']\n",
    "    X_test = X_test['content']\n",
    "    \n",
    "    X_train_list = [value for value in X_train]\n",
    "    \n",
    "    # Save training data to a file\n",
    "    with open(\"train_german_fast_text.txt\", \"w\") as f:\n",
    "        for line in X_train_list:\n",
    "            f.write(line + \"\\n\")\n",
    "\n",
    "    # Training data file path\n",
    "    train_data_path = \"train_german_fast_text.txt\"\n",
    "    \n",
    "    # Train the supervised model\n",
    "    model = fasttext.train_supervised(input=train_data_path, dim=dim, minCount=min_count,bucket=bucket, loss=loss, epoch=epoch, wordNgrams=word_ngrams)#lr=lr, \n",
    "                                       #lr=lr,bucket=bucket,\n",
    "    \n",
    "    # Predict on the testing set\n",
    "    # Initialize an empty list to store the predicted labels\n",
    "    y_pred_list = []\n",
    "\n",
    "    # Iterate over each data point in X_test and predict the label\n",
    "    for text in X_test:\n",
    "        # Predict the label for the current text\n",
    "        predicted_label, _ = model.predict(text)\n",
    "        # Append the predicted label to the list\n",
    "        y_pred_list.append(predicted_label[0])\n",
    "\n",
    "    # Convert the list of predicted labels to a pandas Series\n",
    "    y_pred = pd.Series(y_pred_list)\n",
    "    \n",
    "    # Extract the numeric label using a lambda function\n",
    "    y_test = y_test.apply(lambda x: int(x.split(\"__label__\")[1]))  ## uncomment for next run\n",
    "    y_pred = y_pred.apply(lambda x: int(x.split(\"__label__\")[1]))\n",
    "    \n",
    "    # Model evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred.round())\n",
    "    precision = precision_score(y_test, y_pred.round(), average='weighted')\n",
    "    recall = recall_score(y_test, y_pred.round(), average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred.round(), average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred.round())\n",
    "    \n",
    "    \n",
    "    # Convert classification report to DataFrame\n",
    "    report_df = pd.DataFrame(classification_report(y_test, y_pred.round(), output_dict=True)).transpose()\n",
    "    # Convert confusion matrix to DataFrame\n",
    "    matrix_df = pd.DataFrame(confusion_matrix(y_test, y_pred.round()))\n",
    "    \n",
    "    # Extract metrics for class 1\n",
    "    metrics_1 = report_df.loc['1', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract metrics for class 2\n",
    "    metrics_2 = report_df.loc['2', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract TP, TN, FP, FN counts from the confusion matrix DataFrame\n",
    "    TP = matrix_df.loc[0, 0]\n",
    "    TN = matrix_df.loc[1, 1]\n",
    "    FP = matrix_df.loc[1, 0]\n",
    "    FN = matrix_df.loc[0, 1]\n",
    "    \n",
    "    new_metric_row = {\n",
    "    'dataset': 'DF2',\n",
    "    'model' : 'Fast Text - train_supervised',\n",
    "    'data balancing technique' : 'Random Over Sampler',\n",
    "    'fold' : i,\n",
    "    'precision_1': metrics_1['precision'],\n",
    "    'precision_2': metrics_2['precision'],\n",
    "    'recall_1': metrics_1['recall'],\n",
    "    'recall_2': metrics_2['recall'],\n",
    "    'f1-score_1': metrics_1['f1-score'],\n",
    "    'f1-score_2': metrics_2['f1-score'],\n",
    "    'support_1': metrics_1['support'],\n",
    "    'support_2': metrics_2['support'],\n",
    "    'TP' : TP,\n",
    "    'FP' : FP,\n",
    "    'TN' : TN,\n",
    "    'FN' : FN\n",
    "    }\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    #combined_metrics = combined_metrics.append(new_metric_row, ignore_index=True)\n",
    "    combined_metrics.loc[len(combined_metrics)] = new_metric_row\n",
    "    \n",
    "    \n",
    "    # Append evaluation metrics to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "\n",
    "# Calculate mean evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores) #sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = np.mean(precision_scores) #sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = np.mean(recall_scores) #sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = np.mean(f1_scores) #sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print('Mean Accuracy: {:.2f}'.format(mean_accuracy))\n",
    "print('Mean Precision: {:.2f}'.format(mean_precision))\n",
    "print('Mean Recall: {:.2f}'.format(mean_recall))\n",
    "print('Mean F1-Score: {:.2f}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca7e58c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>data balancing technique</th>\n",
       "      <th>fold</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_2</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>f1-score_1</th>\n",
       "      <th>f1-score_2</th>\n",
       "      <th>support_1</th>\n",
       "      <th>support_2</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>DF2</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>1</td>\n",
       "      <td>0.941349</td>\n",
       "      <td>0.777336</td>\n",
       "      <td>0.969256</td>\n",
       "      <td>0.639935</td>\n",
       "      <td>0.955099</td>\n",
       "      <td>0.701975</td>\n",
       "      <td>3643.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>3531</td>\n",
       "      <td>220</td>\n",
       "      <td>391</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>DF2</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>2</td>\n",
       "      <td>0.941555</td>\n",
       "      <td>0.770992</td>\n",
       "      <td>0.966960</td>\n",
       "      <td>0.649518</td>\n",
       "      <td>0.954089</td>\n",
       "      <td>0.705061</td>\n",
       "      <td>3632.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>3512</td>\n",
       "      <td>218</td>\n",
       "      <td>404</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>DF2</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>3</td>\n",
       "      <td>0.939930</td>\n",
       "      <td>0.792381</td>\n",
       "      <td>0.969840</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.954651</td>\n",
       "      <td>0.714163</td>\n",
       "      <td>3614.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3505</td>\n",
       "      <td>224</td>\n",
       "      <td>416</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>DF2</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>4</td>\n",
       "      <td>0.943811</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.963158</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.953386</td>\n",
       "      <td>0.719934</td>\n",
       "      <td>3610.0</td>\n",
       "      <td>644.0</td>\n",
       "      <td>3477</td>\n",
       "      <td>207</td>\n",
       "      <td>437</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>DF2</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>5</td>\n",
       "      <td>0.943452</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.965126</td>\n",
       "      <td>0.673947</td>\n",
       "      <td>0.954166</td>\n",
       "      <td>0.720601</td>\n",
       "      <td>3613.0</td>\n",
       "      <td>641.0</td>\n",
       "      <td>3487</td>\n",
       "      <td>209</td>\n",
       "      <td>432</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>DF2</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>6</td>\n",
       "      <td>0.946602</td>\n",
       "      <td>0.811009</td>\n",
       "      <td>0.971492</td>\n",
       "      <td>0.690625</td>\n",
       "      <td>0.958885</td>\n",
       "      <td>0.745992</td>\n",
       "      <td>3613.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3510</td>\n",
       "      <td>198</td>\n",
       "      <td>442</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>DF2</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>7</td>\n",
       "      <td>0.945139</td>\n",
       "      <td>0.802102</td>\n",
       "      <td>0.968550</td>\n",
       "      <td>0.693939</td>\n",
       "      <td>0.956701</td>\n",
       "      <td>0.744110</td>\n",
       "      <td>3593.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3480</td>\n",
       "      <td>202</td>\n",
       "      <td>458</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>DF2</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>8</td>\n",
       "      <td>0.940399</td>\n",
       "      <td>0.823853</td>\n",
       "      <td>0.973207</td>\n",
       "      <td>0.670149</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.739095</td>\n",
       "      <td>3583.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>3487</td>\n",
       "      <td>221</td>\n",
       "      <td>449</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>DF2</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>9</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.789007</td>\n",
       "      <td>0.966862</td>\n",
       "      <td>0.672205</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.725938</td>\n",
       "      <td>3591.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>3472</td>\n",
       "      <td>217</td>\n",
       "      <td>445</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>DF2</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>10</td>\n",
       "      <td>0.932997</td>\n",
       "      <td>0.792683</td>\n",
       "      <td>0.971753</td>\n",
       "      <td>0.607477</td>\n",
       "      <td>0.951980</td>\n",
       "      <td>0.687831</td>\n",
       "      <td>3611.0</td>\n",
       "      <td>642.0</td>\n",
       "      <td>3509</td>\n",
       "      <td>252</td>\n",
       "      <td>390</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset                         model data balancing technique  fold  \\\n",
       "20     DF2  Fast Text - train_supervised      Random Over Sampler     1   \n",
       "21     DF2  Fast Text - train_supervised      Random Over Sampler     2   \n",
       "22     DF2  Fast Text - train_supervised      Random Over Sampler     3   \n",
       "23     DF2  Fast Text - train_supervised      Random Over Sampler     4   \n",
       "24     DF2  Fast Text - train_supervised      Random Over Sampler     5   \n",
       "25     DF2  Fast Text - train_supervised      Random Over Sampler     6   \n",
       "26     DF2  Fast Text - train_supervised      Random Over Sampler     7   \n",
       "27     DF2  Fast Text - train_supervised      Random Over Sampler     8   \n",
       "28     DF2  Fast Text - train_supervised      Random Over Sampler     9   \n",
       "29     DF2  Fast Text - train_supervised      Random Over Sampler    10   \n",
       "\n",
       "    precision_1  precision_2  recall_1  recall_2  f1-score_1  f1-score_2  \\\n",
       "20     0.941349     0.777336  0.969256  0.639935    0.955099    0.701975   \n",
       "21     0.941555     0.770992  0.966960  0.649518    0.954089    0.705061   \n",
       "22     0.939930     0.792381  0.969840  0.650000    0.954651    0.714163   \n",
       "23     0.943811     0.766667  0.963158  0.678571    0.953386    0.719934   \n",
       "24     0.943452     0.774194  0.965126  0.673947    0.954166    0.720601   \n",
       "25     0.946602     0.811009  0.971492  0.690625    0.958885    0.745992   \n",
       "26     0.945139     0.802102  0.968550  0.693939    0.956701    0.744110   \n",
       "27     0.940399     0.823853  0.973207  0.670149    0.956522    0.739095   \n",
       "28     0.941176     0.789007  0.966862  0.672205    0.953846    0.725938   \n",
       "29     0.932997     0.792683  0.971753  0.607477    0.951980    0.687831   \n",
       "\n",
       "    support_1  support_2    TP   FP   TN   FN  \n",
       "20     3643.0      611.0  3531  220  391  112  \n",
       "21     3632.0      622.0  3512  218  404  120  \n",
       "22     3614.0      640.0  3505  224  416  109  \n",
       "23     3610.0      644.0  3477  207  437  133  \n",
       "24     3613.0      641.0  3487  209  432  126  \n",
       "25     3613.0      640.0  3510  198  442  103  \n",
       "26     3593.0      660.0  3480  202  458  113  \n",
       "27     3583.0      670.0  3487  221  449   96  \n",
       "28     3591.0      662.0  3472  217  445  119  \n",
       "29     3611.0      642.0  3509  252  390  102  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_metrics[(combined_metrics['data balancing technique'] == 'Random Over Sampler') & (combined_metrics['dataset'] == 'DF2')]#.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4b04f0",
   "metadata": {},
   "source": [
    "## Performance metrics for the Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1158fa25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>data balancing technique</th>\n",
       "      <th>fold</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_2</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>f1-score_1</th>\n",
       "      <th>f1-score_2</th>\n",
       "      <th>support_1</th>\n",
       "      <th>support_2</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DF2</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0.940644</td>\n",
       "      <td>0.780684</td>\n",
       "      <td>0.970080</td>\n",
       "      <td>0.635025</td>\n",
       "      <td>0.955135</td>\n",
       "      <td>0.700361</td>\n",
       "      <td>3643.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>3534</td>\n",
       "      <td>223</td>\n",
       "      <td>388</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DF2</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>0.941240</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.965859</td>\n",
       "      <td>0.647910</td>\n",
       "      <td>0.953390</td>\n",
       "      <td>0.701480</td>\n",
       "      <td>3632.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>3508</td>\n",
       "      <td>219</td>\n",
       "      <td>403</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DF2</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>0.936682</td>\n",
       "      <td>0.788650</td>\n",
       "      <td>0.970116</td>\n",
       "      <td>0.629687</td>\n",
       "      <td>0.953106</td>\n",
       "      <td>0.700261</td>\n",
       "      <td>3614.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3506</td>\n",
       "      <td>237</td>\n",
       "      <td>403</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DF2</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>0.938341</td>\n",
       "      <td>0.768519</td>\n",
       "      <td>0.965374</td>\n",
       "      <td>0.644410</td>\n",
       "      <td>0.951666</td>\n",
       "      <td>0.701014</td>\n",
       "      <td>3610.0</td>\n",
       "      <td>644.0</td>\n",
       "      <td>3485</td>\n",
       "      <td>229</td>\n",
       "      <td>415</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DF2</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>0.943019</td>\n",
       "      <td>0.780399</td>\n",
       "      <td>0.966510</td>\n",
       "      <td>0.670827</td>\n",
       "      <td>0.954620</td>\n",
       "      <td>0.721477</td>\n",
       "      <td>3613.0</td>\n",
       "      <td>641.0</td>\n",
       "      <td>3492</td>\n",
       "      <td>211</td>\n",
       "      <td>430</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DF2</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>0.946943</td>\n",
       "      <td>0.820370</td>\n",
       "      <td>0.973153</td>\n",
       "      <td>0.692187</td>\n",
       "      <td>0.959869</td>\n",
       "      <td>0.750847</td>\n",
       "      <td>3613.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3516</td>\n",
       "      <td>197</td>\n",
       "      <td>443</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DF2</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>None</td>\n",
       "      <td>7</td>\n",
       "      <td>0.939925</td>\n",
       "      <td>0.807763</td>\n",
       "      <td>0.971055</td>\n",
       "      <td>0.662121</td>\n",
       "      <td>0.955236</td>\n",
       "      <td>0.727727</td>\n",
       "      <td>3593.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3489</td>\n",
       "      <td>223</td>\n",
       "      <td>437</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DF2</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>None</td>\n",
       "      <td>8</td>\n",
       "      <td>0.938255</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.975440</td>\n",
       "      <td>0.656716</td>\n",
       "      <td>0.956486</td>\n",
       "      <td>0.734558</td>\n",
       "      <td>3583.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>3495</td>\n",
       "      <td>230</td>\n",
       "      <td>440</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DF2</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>None</td>\n",
       "      <td>9</td>\n",
       "      <td>0.944037</td>\n",
       "      <td>0.797203</td>\n",
       "      <td>0.967697</td>\n",
       "      <td>0.688822</td>\n",
       "      <td>0.955721</td>\n",
       "      <td>0.739060</td>\n",
       "      <td>3591.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>3475</td>\n",
       "      <td>206</td>\n",
       "      <td>456</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DF2</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.931419</td>\n",
       "      <td>0.782077</td>\n",
       "      <td>0.970368</td>\n",
       "      <td>0.598131</td>\n",
       "      <td>0.950495</td>\n",
       "      <td>0.677846</td>\n",
       "      <td>3611.0</td>\n",
       "      <td>642.0</td>\n",
       "      <td>3504</td>\n",
       "      <td>258</td>\n",
       "      <td>384</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DF2</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>1</td>\n",
       "      <td>0.977832</td>\n",
       "      <td>0.559834</td>\n",
       "      <td>0.883887</td>\n",
       "      <td>0.880524</td>\n",
       "      <td>0.928489</td>\n",
       "      <td>0.684478</td>\n",
       "      <td>3643.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>3220</td>\n",
       "      <td>73</td>\n",
       "      <td>538</td>\n",
       "      <td>423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DF2</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>2</td>\n",
       "      <td>0.982573</td>\n",
       "      <td>0.516393</td>\n",
       "      <td>0.853800</td>\n",
       "      <td>0.911576</td>\n",
       "      <td>0.913671</td>\n",
       "      <td>0.659302</td>\n",
       "      <td>3632.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>3101</td>\n",
       "      <td>55</td>\n",
       "      <td>567</td>\n",
       "      <td>531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DF2</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>3</td>\n",
       "      <td>0.975248</td>\n",
       "      <td>0.547945</td>\n",
       "      <td>0.872164</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.920830</td>\n",
       "      <td>0.673887</td>\n",
       "      <td>3614.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3152</td>\n",
       "      <td>80</td>\n",
       "      <td>560</td>\n",
       "      <td>462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DF2</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>4</td>\n",
       "      <td>0.978192</td>\n",
       "      <td>0.527523</td>\n",
       "      <td>0.857341</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.913788</td>\n",
       "      <td>0.663206</td>\n",
       "      <td>3610.0</td>\n",
       "      <td>644.0</td>\n",
       "      <td>3095</td>\n",
       "      <td>69</td>\n",
       "      <td>575</td>\n",
       "      <td>515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DF2</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>5</td>\n",
       "      <td>0.977123</td>\n",
       "      <td>0.534337</td>\n",
       "      <td>0.862995</td>\n",
       "      <td>0.886115</td>\n",
       "      <td>0.916520</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>3613.0</td>\n",
       "      <td>641.0</td>\n",
       "      <td>3118</td>\n",
       "      <td>73</td>\n",
       "      <td>568</td>\n",
       "      <td>495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>DF2</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>6</td>\n",
       "      <td>0.978158</td>\n",
       "      <td>0.521938</td>\n",
       "      <td>0.855245</td>\n",
       "      <td>0.892188</td>\n",
       "      <td>0.912581</td>\n",
       "      <td>0.658593</td>\n",
       "      <td>3613.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3090</td>\n",
       "      <td>69</td>\n",
       "      <td>571</td>\n",
       "      <td>523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DF2</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>7</td>\n",
       "      <td>0.973864</td>\n",
       "      <td>0.554379</td>\n",
       "      <td>0.871138</td>\n",
       "      <td>0.872727</td>\n",
       "      <td>0.919642</td>\n",
       "      <td>0.678046</td>\n",
       "      <td>3593.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3130</td>\n",
       "      <td>84</td>\n",
       "      <td>576</td>\n",
       "      <td>463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DF2</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>8</td>\n",
       "      <td>0.976577</td>\n",
       "      <td>0.566127</td>\n",
       "      <td>0.872732</td>\n",
       "      <td>0.888060</td>\n",
       "      <td>0.921739</td>\n",
       "      <td>0.691458</td>\n",
       "      <td>3583.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>3127</td>\n",
       "      <td>75</td>\n",
       "      <td>595</td>\n",
       "      <td>456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>DF2</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>9</td>\n",
       "      <td>0.983943</td>\n",
       "      <td>0.537313</td>\n",
       "      <td>0.853244</td>\n",
       "      <td>0.924471</td>\n",
       "      <td>0.913945</td>\n",
       "      <td>0.679622</td>\n",
       "      <td>3591.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>3064</td>\n",
       "      <td>50</td>\n",
       "      <td>612</td>\n",
       "      <td>527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DF2</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>10</td>\n",
       "      <td>0.973814</td>\n",
       "      <td>0.553128</td>\n",
       "      <td>0.875381</td>\n",
       "      <td>0.867601</td>\n",
       "      <td>0.921978</td>\n",
       "      <td>0.675561</td>\n",
       "      <td>3611.0</td>\n",
       "      <td>642.0</td>\n",
       "      <td>3161</td>\n",
       "      <td>85</td>\n",
       "      <td>557</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>DF2</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>1</td>\n",
       "      <td>0.941349</td>\n",
       "      <td>0.777336</td>\n",
       "      <td>0.969256</td>\n",
       "      <td>0.639935</td>\n",
       "      <td>0.955099</td>\n",
       "      <td>0.701975</td>\n",
       "      <td>3643.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>3531</td>\n",
       "      <td>220</td>\n",
       "      <td>391</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>DF2</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>2</td>\n",
       "      <td>0.941555</td>\n",
       "      <td>0.770992</td>\n",
       "      <td>0.966960</td>\n",
       "      <td>0.649518</td>\n",
       "      <td>0.954089</td>\n",
       "      <td>0.705061</td>\n",
       "      <td>3632.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>3512</td>\n",
       "      <td>218</td>\n",
       "      <td>404</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>DF2</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>3</td>\n",
       "      <td>0.939930</td>\n",
       "      <td>0.792381</td>\n",
       "      <td>0.969840</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.954651</td>\n",
       "      <td>0.714163</td>\n",
       "      <td>3614.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3505</td>\n",
       "      <td>224</td>\n",
       "      <td>416</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>DF2</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>4</td>\n",
       "      <td>0.943811</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.963158</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.953386</td>\n",
       "      <td>0.719934</td>\n",
       "      <td>3610.0</td>\n",
       "      <td>644.0</td>\n",
       "      <td>3477</td>\n",
       "      <td>207</td>\n",
       "      <td>437</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>DF2</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>5</td>\n",
       "      <td>0.943452</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.965126</td>\n",
       "      <td>0.673947</td>\n",
       "      <td>0.954166</td>\n",
       "      <td>0.720601</td>\n",
       "      <td>3613.0</td>\n",
       "      <td>641.0</td>\n",
       "      <td>3487</td>\n",
       "      <td>209</td>\n",
       "      <td>432</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>DF2</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>6</td>\n",
       "      <td>0.946602</td>\n",
       "      <td>0.811009</td>\n",
       "      <td>0.971492</td>\n",
       "      <td>0.690625</td>\n",
       "      <td>0.958885</td>\n",
       "      <td>0.745992</td>\n",
       "      <td>3613.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3510</td>\n",
       "      <td>198</td>\n",
       "      <td>442</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>DF2</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>7</td>\n",
       "      <td>0.945139</td>\n",
       "      <td>0.802102</td>\n",
       "      <td>0.968550</td>\n",
       "      <td>0.693939</td>\n",
       "      <td>0.956701</td>\n",
       "      <td>0.744110</td>\n",
       "      <td>3593.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3480</td>\n",
       "      <td>202</td>\n",
       "      <td>458</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>DF2</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>8</td>\n",
       "      <td>0.940399</td>\n",
       "      <td>0.823853</td>\n",
       "      <td>0.973207</td>\n",
       "      <td>0.670149</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.739095</td>\n",
       "      <td>3583.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>3487</td>\n",
       "      <td>221</td>\n",
       "      <td>449</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>DF2</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>9</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.789007</td>\n",
       "      <td>0.966862</td>\n",
       "      <td>0.672205</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.725938</td>\n",
       "      <td>3591.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>3472</td>\n",
       "      <td>217</td>\n",
       "      <td>445</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>DF2</td>\n",
       "      <td>Fast Text - train_supervised</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>10</td>\n",
       "      <td>0.932997</td>\n",
       "      <td>0.792683</td>\n",
       "      <td>0.971753</td>\n",
       "      <td>0.607477</td>\n",
       "      <td>0.951980</td>\n",
       "      <td>0.687831</td>\n",
       "      <td>3611.0</td>\n",
       "      <td>642.0</td>\n",
       "      <td>3509</td>\n",
       "      <td>252</td>\n",
       "      <td>390</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset                         model data balancing technique  fold  \\\n",
       "0      DF2  Fast Text - train_supervised                     None     1   \n",
       "1      DF2  Fast Text - train_supervised                     None     2   \n",
       "2      DF2  Fast Text - train_supervised                     None     3   \n",
       "3      DF2  Fast Text - train_supervised                     None     4   \n",
       "4      DF2  Fast Text - train_supervised                     None     5   \n",
       "5      DF2  Fast Text - train_supervised                     None     6   \n",
       "6      DF2  Fast Text - train_supervised                     None     7   \n",
       "7      DF2  Fast Text - train_supervised                     None     8   \n",
       "8      DF2  Fast Text - train_supervised                     None     9   \n",
       "9      DF2  Fast Text - train_supervised                     None    10   \n",
       "10     DF2  Fast Text - train_supervised     Random Under Sampler     1   \n",
       "11     DF2  Fast Text - train_supervised     Random Under Sampler     2   \n",
       "12     DF2  Fast Text - train_supervised     Random Under Sampler     3   \n",
       "13     DF2  Fast Text - train_supervised     Random Under Sampler     4   \n",
       "14     DF2  Fast Text - train_supervised     Random Under Sampler     5   \n",
       "15     DF2  Fast Text - train_supervised     Random Under Sampler     6   \n",
       "16     DF2  Fast Text - train_supervised     Random Under Sampler     7   \n",
       "17     DF2  Fast Text - train_supervised     Random Under Sampler     8   \n",
       "18     DF2  Fast Text - train_supervised     Random Under Sampler     9   \n",
       "19     DF2  Fast Text - train_supervised     Random Under Sampler    10   \n",
       "20     DF2  Fast Text - train_supervised      Random Over Sampler     1   \n",
       "21     DF2  Fast Text - train_supervised      Random Over Sampler     2   \n",
       "22     DF2  Fast Text - train_supervised      Random Over Sampler     3   \n",
       "23     DF2  Fast Text - train_supervised      Random Over Sampler     4   \n",
       "24     DF2  Fast Text - train_supervised      Random Over Sampler     5   \n",
       "25     DF2  Fast Text - train_supervised      Random Over Sampler     6   \n",
       "26     DF2  Fast Text - train_supervised      Random Over Sampler     7   \n",
       "27     DF2  Fast Text - train_supervised      Random Over Sampler     8   \n",
       "28     DF2  Fast Text - train_supervised      Random Over Sampler     9   \n",
       "29     DF2  Fast Text - train_supervised      Random Over Sampler    10   \n",
       "\n",
       "    precision_1  precision_2  recall_1  recall_2  f1-score_1  f1-score_2  \\\n",
       "0      0.940644     0.780684  0.970080  0.635025    0.955135    0.700361   \n",
       "1      0.941240     0.764706  0.965859  0.647910    0.953390    0.701480   \n",
       "2      0.936682     0.788650  0.970116  0.629687    0.953106    0.700261   \n",
       "3      0.938341     0.768519  0.965374  0.644410    0.951666    0.701014   \n",
       "4      0.943019     0.780399  0.966510  0.670827    0.954620    0.721477   \n",
       "5      0.946943     0.820370  0.973153  0.692187    0.959869    0.750847   \n",
       "6      0.939925     0.807763  0.971055  0.662121    0.955236    0.727727   \n",
       "7      0.938255     0.833333  0.975440  0.656716    0.956486    0.734558   \n",
       "8      0.944037     0.797203  0.967697  0.688822    0.955721    0.739060   \n",
       "9      0.931419     0.782077  0.970368  0.598131    0.950495    0.677846   \n",
       "10     0.977832     0.559834  0.883887  0.880524    0.928489    0.684478   \n",
       "11     0.982573     0.516393  0.853800  0.911576    0.913671    0.659302   \n",
       "12     0.975248     0.547945  0.872164  0.875000    0.920830    0.673887   \n",
       "13     0.978192     0.527523  0.857341  0.892857    0.913788    0.663206   \n",
       "14     0.977123     0.534337  0.862995  0.886115    0.916520    0.666667   \n",
       "15     0.978158     0.521938  0.855245  0.892188    0.912581    0.658593   \n",
       "16     0.973864     0.554379  0.871138  0.872727    0.919642    0.678046   \n",
       "17     0.976577     0.566127  0.872732  0.888060    0.921739    0.691458   \n",
       "18     0.983943     0.537313  0.853244  0.924471    0.913945    0.679622   \n",
       "19     0.973814     0.553128  0.875381  0.867601    0.921978    0.675561   \n",
       "20     0.941349     0.777336  0.969256  0.639935    0.955099    0.701975   \n",
       "21     0.941555     0.770992  0.966960  0.649518    0.954089    0.705061   \n",
       "22     0.939930     0.792381  0.969840  0.650000    0.954651    0.714163   \n",
       "23     0.943811     0.766667  0.963158  0.678571    0.953386    0.719934   \n",
       "24     0.943452     0.774194  0.965126  0.673947    0.954166    0.720601   \n",
       "25     0.946602     0.811009  0.971492  0.690625    0.958885    0.745992   \n",
       "26     0.945139     0.802102  0.968550  0.693939    0.956701    0.744110   \n",
       "27     0.940399     0.823853  0.973207  0.670149    0.956522    0.739095   \n",
       "28     0.941176     0.789007  0.966862  0.672205    0.953846    0.725938   \n",
       "29     0.932997     0.792683  0.971753  0.607477    0.951980    0.687831   \n",
       "\n",
       "    support_1  support_2    TP   FP   TN   FN  \n",
       "0      3643.0      611.0  3534  223  388  109  \n",
       "1      3632.0      622.0  3508  219  403  124  \n",
       "2      3614.0      640.0  3506  237  403  108  \n",
       "3      3610.0      644.0  3485  229  415  125  \n",
       "4      3613.0      641.0  3492  211  430  121  \n",
       "5      3613.0      640.0  3516  197  443   97  \n",
       "6      3593.0      660.0  3489  223  437  104  \n",
       "7      3583.0      670.0  3495  230  440   88  \n",
       "8      3591.0      662.0  3475  206  456  116  \n",
       "9      3611.0      642.0  3504  258  384  107  \n",
       "10     3643.0      611.0  3220   73  538  423  \n",
       "11     3632.0      622.0  3101   55  567  531  \n",
       "12     3614.0      640.0  3152   80  560  462  \n",
       "13     3610.0      644.0  3095   69  575  515  \n",
       "14     3613.0      641.0  3118   73  568  495  \n",
       "15     3613.0      640.0  3090   69  571  523  \n",
       "16     3593.0      660.0  3130   84  576  463  \n",
       "17     3583.0      670.0  3127   75  595  456  \n",
       "18     3591.0      662.0  3064   50  612  527  \n",
       "19     3611.0      642.0  3161   85  557  450  \n",
       "20     3643.0      611.0  3531  220  391  112  \n",
       "21     3632.0      622.0  3512  218  404  120  \n",
       "22     3614.0      640.0  3505  224  416  109  \n",
       "23     3610.0      644.0  3477  207  437  133  \n",
       "24     3613.0      641.0  3487  209  432  126  \n",
       "25     3613.0      640.0  3510  198  442  103  \n",
       "26     3593.0      660.0  3480  202  458  113  \n",
       "27     3583.0      670.0  3487  221  449   96  \n",
       "28     3591.0      662.0  3472  217  445  119  \n",
       "29     3611.0      642.0  3509  252  390  102  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8905e922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame\n",
    "combined_metrics.to_csv('Output Data/Fast Text - train_supervised.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e221aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
