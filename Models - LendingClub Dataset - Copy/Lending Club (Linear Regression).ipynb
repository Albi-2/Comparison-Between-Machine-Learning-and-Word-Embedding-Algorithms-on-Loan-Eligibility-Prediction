{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d2c91a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f460afa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "import numpy as np\n",
    "from pprint import pprint as pp\n",
    "import csv\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "from itertools import product\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from imblearn.pipeline import Pipeline \n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import r2_score, classification_report, confusion_matrix, accuracy_score, roc_auc_score, roc_curve, precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import homogeneity_score, silhouette_score\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import MiniBatchKMeans, DBSCAN\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17e9cee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, precision_score, recall_score, f1_score, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6238cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, precision_score, recall_score, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75e8fc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.combine import SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "378df2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0db62d0",
   "metadata": {},
   "source": [
    "### Retrieving the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10513ea6",
   "metadata": {},
   "source": [
    "#### DF 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc3d2069",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = pd.read_csv('df5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82ed7cb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>emp_title</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>issue_d</th>\n",
       "      <th>pymnt_plan</th>\n",
       "      <th>purpose</th>\n",
       "      <th>title</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>addr_state</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>earliest_cr_line</th>\n",
       "      <th>fico_range_low</th>\n",
       "      <th>fico_range_high</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>mths_since_last_delinq</th>\n",
       "      <th>mths_since_last_record</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>revol_bal</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>total_acc</th>\n",
       "      <th>out_prncp</th>\n",
       "      <th>out_prncp_inv</th>\n",
       "      <th>total_pymnt</th>\n",
       "      <th>total_pymnt_inv</th>\n",
       "      <th>total_rec_prncp</th>\n",
       "      <th>total_rec_int</th>\n",
       "      <th>total_rec_late_fee</th>\n",
       "      <th>recoveries</th>\n",
       "      <th>collection_recovery_fee</th>\n",
       "      <th>last_pymnt_d</th>\n",
       "      <th>last_pymnt_amnt</th>\n",
       "      <th>next_pymnt_d</th>\n",
       "      <th>last_credit_pull_d</th>\n",
       "      <th>last_fico_range_high</th>\n",
       "      <th>last_fico_range_low</th>\n",
       "      <th>collections_12_mths_ex_med</th>\n",
       "      <th>acc_now_delinq</th>\n",
       "      <th>chargeoff_within_12_mths</th>\n",
       "      <th>delinq_amnt</th>\n",
       "      <th>pub_rec_bankruptcies</th>\n",
       "      <th>tax_liens</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1077501.0</td>\n",
       "      <td>1296599.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>4975.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1065</td>\n",
       "      <td>162.87</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>25275</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3160</td>\n",
       "      <td>860</td>\n",
       "      <td>3</td>\n",
       "      <td>27.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>735.0</td>\n",
       "      <td>739.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13648.0</td>\n",
       "      <td>0.837</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5863.155187</td>\n",
       "      <td>5833.84</td>\n",
       "      <td>5000.00</td>\n",
       "      <td>863.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>171.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>744.0</td>\n",
       "      <td>740.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1077430.0</td>\n",
       "      <td>1314167.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1527</td>\n",
       "      <td>59.83</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>20173</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17558</td>\n",
       "      <td>309</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>740.0</td>\n",
       "      <td>744.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1687.0</td>\n",
       "      <td>0.094</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1008.710000</td>\n",
       "      <td>1008.71</td>\n",
       "      <td>456.46</td>\n",
       "      <td>435.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117.08</td>\n",
       "      <td>1.11</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>119.66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>499.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         id  member_id  loan_amnt  funded_amnt  funded_amnt_inv  \\\n",
       "0           0  1077501.0  1296599.0     5000.0       5000.0           4975.0   \n",
       "1           1  1077430.0  1314167.0     2500.0       2500.0           2500.0   \n",
       "\n",
       "   term  int_rate  installment  grade  sub_grade  emp_title  emp_length  \\\n",
       "0     0    0.1065       162.87      1          6      25275        10.0   \n",
       "1     1    0.1527        59.83      2         13      20173         1.0   \n",
       "\n",
       "   home_ownership  annual_inc  verification_status  issue_d  pymnt_plan  \\\n",
       "0               4     24000.0                    2   2011.0           0   \n",
       "1               4     30000.0                    1   2011.0           0   \n",
       "\n",
       "   purpose  title  zip_code  addr_state    dti  delinq_2yrs  earliest_cr_line  \\\n",
       "0        1   3160       860           3  27.65          0.0            1985.0   \n",
       "1        0  17558       309          10   1.00          0.0            1999.0   \n",
       "\n",
       "   fico_range_low  fico_range_high  inq_last_6mths  mths_since_last_delinq  \\\n",
       "0           735.0            739.0             1.0                   500.0   \n",
       "1           740.0            744.0             5.0                   500.0   \n",
       "\n",
       "   mths_since_last_record  open_acc  pub_rec  revol_bal  revol_util  \\\n",
       "0                   222.0       3.0      0.0    13648.0       0.837   \n",
       "1                   222.0       3.0      0.0     1687.0       0.094   \n",
       "\n",
       "   total_acc  out_prncp  out_prncp_inv  total_pymnt  total_pymnt_inv  \\\n",
       "0        9.0        0.0            0.0  5863.155187          5833.84   \n",
       "1        4.0        0.0            0.0  1008.710000          1008.71   \n",
       "\n",
       "   total_rec_prncp  total_rec_int  total_rec_late_fee  recoveries  \\\n",
       "0          5000.00         863.16                 0.0        0.00   \n",
       "1           456.46         435.17                 0.0      117.08   \n",
       "\n",
       "   collection_recovery_fee  last_pymnt_d  last_pymnt_amnt  next_pymnt_d  \\\n",
       "0                     0.00        2015.0           171.62           0.0   \n",
       "1                     1.11        2013.0           119.66           0.0   \n",
       "\n",
       "   last_credit_pull_d  last_fico_range_high  last_fico_range_low  \\\n",
       "0              2016.0                 744.0                740.0   \n",
       "1              2016.0                 499.0                  0.0   \n",
       "\n",
       "   collections_12_mths_ex_med  acc_now_delinq  chargeoff_within_12_mths  \\\n",
       "0                           0               0                         0   \n",
       "1                           0               0                         0   \n",
       "\n",
       "   delinq_amnt  pub_rec_bankruptcies  tax_liens  target  \n",
       "0          0.0                   0.0          0       1  \n",
       "1          0.0                   0.0          0       2  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed385af",
   "metadata": {},
   "source": [
    "#### DF 5c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4218b67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df5c = pd.read_csv('df5c.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "026f4728",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df5c.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f9963f",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b0bea07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store evaluation metrics for each fold\n",
    "dataset_used = []\n",
    "model_used = []\n",
    "data_balancing_technique = []\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "conf_matrices = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4e6d6d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combined_metrics = pd.DataFrame()\n",
    "\n",
    "combined_metrics = pd.DataFrame(columns=['dataset', 'model', 'data balancing technique', 'fold', 'precision_1','precision_2','recall_1','recall_2','f1-score_1','f1-score_2','support_1','support_2','TP','FP','TN','FN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052cda7c",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedf6e11",
   "metadata": {},
   "source": [
    "## DF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "89f99b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.94\n",
      "Mean Precision: 0.95\n",
      "Mean Recall: 0.94\n",
      "Mean F1-Score: 0.94\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df5' is your DataFrame with features and the target column\n",
    "# Replace 'features' with the actual list of feature columns\n",
    "features = df5.drop(columns=['target'])  # Drop the target column to get the feature columns\n",
    "target = df5['target']  # Target column to predict\n",
    "\n",
    "# Initialize Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Initialize KFold with 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the testing set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    y_pred = np.round(y_pred)\n",
    "\n",
    "    y_pred[y_pred <= 0] = 1\n",
    "    y_pred[y_pred >= 2] = 2\n",
    "    \n",
    "    # Model evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred.round())\n",
    "    precision = precision_score(y_test, y_pred.round(), average='weighted')\n",
    "    recall = recall_score(y_test, y_pred.round(), average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred.round(), average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred.round())\n",
    "    \n",
    "    \n",
    "    # Convert classification report to DataFrame\n",
    "    report_df = pd.DataFrame(classification_report(y_test, y_pred.round(), output_dict=True)).transpose()\n",
    "    # Convert confusion matrix to DataFrame\n",
    "    matrix_df = pd.DataFrame(confusion_matrix(y_test, y_pred.round()))\n",
    "    \n",
    "    # Extract metrics for class 1\n",
    "    metrics_1 = report_df.loc['1', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract metrics for class 2\n",
    "    metrics_2 = report_df.loc['2', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract TP, TN, FP, FN counts from the confusion matrix DataFrame\n",
    "    TP = matrix_df.loc[0, 0]\n",
    "    TN = matrix_df.loc[1, 1]\n",
    "    FP = matrix_df.loc[1, 0]\n",
    "    FN = matrix_df.loc[0, 1]\n",
    "    \n",
    "    new_metric_row = {\n",
    "    'dataset': 'DF5',\n",
    "    'model' : 'Linear Regression',\n",
    "    'data balancing technique' : 'None',\n",
    "    'fold' : i,\n",
    "    'precision_1': metrics_1['precision'],\n",
    "    'precision_2': metrics_2['precision'],\n",
    "    'recall_1': metrics_1['recall'],\n",
    "    'recall_2': metrics_2['recall'],\n",
    "    'f1-score_1': metrics_1['f1-score'],\n",
    "    'f1-score_2': metrics_2['f1-score'],\n",
    "    'support_1': metrics_1['support'],\n",
    "    'support_2': metrics_2['support'],\n",
    "    'TP' : TP,\n",
    "    'FP' : FP,\n",
    "    'TN' : TN,\n",
    "    'FN' : FN\n",
    "    }\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    #combined_metrics = combined_metrics.append(new_metric_row, ignore_index=True)\n",
    "    combined_metrics.loc[len(combined_metrics)] = new_metric_row\n",
    "    \n",
    "    \n",
    "    # Append evaluation metrics to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "\n",
    "# Calculate mean evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores) #sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = np.mean(precision_scores) #sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = np.mean(recall_scores) #sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = np.mean(f1_scores) #sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print('Mean Accuracy: {:.2f}'.format(mean_accuracy))\n",
    "print('Mean Precision: {:.2f}'.format(mean_precision))\n",
    "print('Mean Recall: {:.2f}'.format(mean_recall))\n",
    "print('Mean F1-Score: {:.2f}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e5cd58d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>data balancing technique</th>\n",
       "      <th>fold</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_2</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>f1-score_1</th>\n",
       "      <th>f1-score_2</th>\n",
       "      <th>support_1</th>\n",
       "      <th>support_2</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0.940766</td>\n",
       "      <td>0.984536</td>\n",
       "      <td>0.998353</td>\n",
       "      <td>0.625205</td>\n",
       "      <td>0.968704</td>\n",
       "      <td>0.764765</td>\n",
       "      <td>3643.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>3637</td>\n",
       "      <td>229</td>\n",
       "      <td>382</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>0.936774</td>\n",
       "      <td>0.994723</td>\n",
       "      <td>0.999449</td>\n",
       "      <td>0.606109</td>\n",
       "      <td>0.967097</td>\n",
       "      <td>0.753247</td>\n",
       "      <td>3632.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>3630</td>\n",
       "      <td>245</td>\n",
       "      <td>377</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset              model data balancing technique  fold  precision_1  \\\n",
       "0     DF5  Linear Regression                     None     1     0.940766   \n",
       "1     DF5  Linear Regression                     None     2     0.936774   \n",
       "\n",
       "   precision_2  recall_1  recall_2  f1-score_1  f1-score_2  support_1  \\\n",
       "0     0.984536  0.998353  0.625205    0.968704    0.764765     3643.0   \n",
       "1     0.994723  0.999449  0.606109    0.967097    0.753247     3632.0   \n",
       "\n",
       "   support_2    TP   FP   TN  FN  \n",
       "0      611.0  3637  229  382   6  \n",
       "1      622.0  3630  245  377   2  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_metrics[(combined_metrics['data balancing technique'] == 'None') & (combined_metrics['dataset'] == 'DF5')].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd45aea",
   "metadata": {},
   "source": [
    "### Linear Regression with df5 data and imbalance data tackling (SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4eaaba2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.94\n",
      "Mean Precision: 0.95\n",
      "Mean Recall: 0.94\n",
      "Mean F1-Score: 0.94\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df5' is your DataFrame with features and the target column\n",
    "# Replace 'features' with the actual list of feature columns\n",
    "features = df5.drop(columns=['target'])  # Drop the target column to get the feature columns\n",
    "target = df5['target']  # Target column to predict\n",
    "\n",
    "# Initialize Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Initialize KFold with 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    # Apply SMOTE to the training data\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Predict on the testing set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    y_pred = np.round(y_pred)\n",
    "\n",
    "    y_pred[y_pred <= 0] = 1\n",
    "    y_pred[y_pred >= 2] = 2\n",
    "    \n",
    "    # Model evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred.round())\n",
    "    precision = precision_score(y_test, y_pred.round(), average='weighted')\n",
    "    recall = recall_score(y_test, y_pred.round(), average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred.round(), average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred.round())\n",
    "    \n",
    "    # Convert classification report to DataFrame\n",
    "    report_df = pd.DataFrame(classification_report(y_test, y_pred.round(), output_dict=True)).transpose()\n",
    "    # Convert confusion matrix to DataFrame\n",
    "    matrix_df = pd.DataFrame(confusion_matrix(y_test, y_pred.round()))\n",
    "    \n",
    "    # Extract metrics for class 1\n",
    "    metrics_1 = report_df.loc['1', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract metrics for class 2\n",
    "    metrics_2 = report_df.loc['2', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract TP, TN, FP, FN counts from the confusion matrix DataFrame\n",
    "    TP = matrix_df.loc[0, 0]\n",
    "    TN = matrix_df.loc[1, 1]\n",
    "    FP = matrix_df.loc[1, 0]\n",
    "    FN = matrix_df.loc[0, 1]\n",
    "    \n",
    "    new_metric_row = {\n",
    "    'dataset': 'DF5',\n",
    "    'model' : 'Linear Regression',\n",
    "    'data balancing technique' : 'SMOTE',\n",
    "    'fold' : i,\n",
    "    'precision_1': metrics_1['precision'],\n",
    "    'precision_2': metrics_2['precision'],\n",
    "    'recall_1': metrics_1['recall'],\n",
    "    'recall_2': metrics_2['recall'],\n",
    "    'f1-score_1': metrics_1['f1-score'],\n",
    "    'f1-score_2': metrics_2['f1-score'],\n",
    "    'support_1': metrics_1['support'],\n",
    "    'support_2': metrics_2['support'],\n",
    "    'TP' : TP,\n",
    "    'FP' : FP,\n",
    "    'TN' : TN,\n",
    "    'FN' : FN\n",
    "    }\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    #combined_metrics = combined_metrics.append(new_metric_row, ignore_index=True)\n",
    "    combined_metrics.loc[len(combined_metrics)] = new_metric_row\n",
    "    \n",
    "    \n",
    "    # Append evaluation metrics to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "\n",
    "# Calculate mean evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores) #sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = np.mean(precision_scores) #sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = np.mean(recall_scores) #sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = np.mean(f1_scores) #sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print('Mean Accuracy: {:.2f}'.format(mean_accuracy))\n",
    "print('Mean Precision: {:.2f}'.format(mean_precision))\n",
    "print('Mean Recall: {:.2f}'.format(mean_recall))\n",
    "print('Mean F1-Score: {:.2f}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "031ffc3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>data balancing technique</th>\n",
       "      <th>fold</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_2</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>f1-score_1</th>\n",
       "      <th>f1-score_2</th>\n",
       "      <th>support_1</th>\n",
       "      <th>support_2</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>1</td>\n",
       "      <td>0.983700</td>\n",
       "      <td>0.731836</td>\n",
       "      <td>0.944277</td>\n",
       "      <td>0.906710</td>\n",
       "      <td>0.963585</td>\n",
       "      <td>0.809942</td>\n",
       "      <td>3643.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>3440</td>\n",
       "      <td>57</td>\n",
       "      <td>554</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>2</td>\n",
       "      <td>0.983471</td>\n",
       "      <td>0.757047</td>\n",
       "      <td>0.950165</td>\n",
       "      <td>0.906752</td>\n",
       "      <td>0.966531</td>\n",
       "      <td>0.825165</td>\n",
       "      <td>3632.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>3451</td>\n",
       "      <td>58</td>\n",
       "      <td>564</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset              model data balancing technique  fold  precision_1  \\\n",
       "10     DF5  Linear Regression                    SMOTE     1     0.983700   \n",
       "11     DF5  Linear Regression                    SMOTE     2     0.983471   \n",
       "\n",
       "    precision_2  recall_1  recall_2  f1-score_1  f1-score_2  support_1  \\\n",
       "10     0.731836  0.944277  0.906710    0.963585    0.809942     3643.0   \n",
       "11     0.757047  0.950165  0.906752    0.966531    0.825165     3632.0   \n",
       "\n",
       "    support_2    TP  FP   TN   FN  \n",
       "10      611.0  3440  57  554  203  \n",
       "11      622.0  3451  58  564  181  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_metrics[(combined_metrics['data balancing technique'] == 'SMOTE') & (combined_metrics['dataset'] == 'DF5')].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737bdf77",
   "metadata": {},
   "source": [
    "### Linear Regression with df5 data and imbalance data tackling (RandomUnderSampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0efc30fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.94\n",
      "Mean Precision: 0.95\n",
      "Mean Recall: 0.94\n",
      "Mean F1-Score: 0.94\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df5' is your DataFrame with features and the target column\n",
    "# Replace 'features' with the actual list of feature columns\n",
    "features = df5.drop(columns=['target'])  # Drop the target column to get the feature columns\n",
    "target = df5['target']  # Target column to predict\n",
    "\n",
    "# Initialize Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Initialize KFold with 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    # Undersampling the majority class\n",
    "    rus = RandomUnderSampler(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Predict on the testing set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    y_pred = np.round(y_pred)\n",
    "\n",
    "    y_pred[y_pred <= 0] = 1\n",
    "    y_pred[y_pred >= 2] = 2\n",
    "    \n",
    "    # Model evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred.round())\n",
    "    precision = precision_score(y_test, y_pred.round(), average='weighted')\n",
    "    recall = recall_score(y_test, y_pred.round(), average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred.round(), average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred.round())\n",
    "    \n",
    "    # Convert classification report to DataFrame\n",
    "    report_df = pd.DataFrame(classification_report(y_test, y_pred.round(), output_dict=True)).transpose()\n",
    "    # Convert confusion matrix to DataFrame\n",
    "    matrix_df = pd.DataFrame(confusion_matrix(y_test, y_pred.round()))\n",
    "    \n",
    "    # Extract metrics for class 1\n",
    "    metrics_1 = report_df.loc['1', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract metrics for class 2\n",
    "    metrics_2 = report_df.loc['2', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract TP, TN, FP, FN counts from the confusion matrix DataFrame\n",
    "    TP = matrix_df.loc[0, 0]\n",
    "    TN = matrix_df.loc[1, 1]\n",
    "    FP = matrix_df.loc[1, 0]\n",
    "    FN = matrix_df.loc[0, 1]\n",
    "    \n",
    "    new_metric_row = {\n",
    "    'dataset': 'DF5',\n",
    "    'model' : 'Linear Regression',\n",
    "    'data balancing technique' : 'Random Under Sampler',\n",
    "    'fold' : i,\n",
    "    'precision_1': metrics_1['precision'],\n",
    "    'precision_2': metrics_2['precision'],\n",
    "    'recall_1': metrics_1['recall'],\n",
    "    'recall_2': metrics_2['recall'],\n",
    "    'f1-score_1': metrics_1['f1-score'],\n",
    "    'f1-score_2': metrics_2['f1-score'],\n",
    "    'support_1': metrics_1['support'],\n",
    "    'support_2': metrics_2['support'],\n",
    "    'TP' : TP,\n",
    "    'FP' : FP,\n",
    "    'TN' : TN,\n",
    "    'FN' : FN\n",
    "    }\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    #combined_metrics = combined_metrics.append(new_metric_row, ignore_index=True)\n",
    "    combined_metrics.loc[len(combined_metrics)] = new_metric_row\n",
    "    \n",
    "    \n",
    "    # Append evaluation metrics to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "\n",
    "# Calculate mean evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores) #sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = np.mean(precision_scores) #sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = np.mean(recall_scores) #sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = np.mean(f1_scores) #sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print('Mean Accuracy: {:.2f}'.format(mean_accuracy))\n",
    "print('Mean Precision: {:.2f}'.format(mean_precision))\n",
    "print('Mean Recall: {:.2f}'.format(mean_recall))\n",
    "print('Mean F1-Score: {:.2f}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2d72cc02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>data balancing technique</th>\n",
       "      <th>fold</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_2</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>f1-score_1</th>\n",
       "      <th>f1-score_2</th>\n",
       "      <th>support_1</th>\n",
       "      <th>support_2</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>1</td>\n",
       "      <td>0.988979</td>\n",
       "      <td>0.710918</td>\n",
       "      <td>0.936042</td>\n",
       "      <td>0.937807</td>\n",
       "      <td>0.961783</td>\n",
       "      <td>0.808751</td>\n",
       "      <td>3643.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>3410</td>\n",
       "      <td>38</td>\n",
       "      <td>573</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>2</td>\n",
       "      <td>0.988950</td>\n",
       "      <td>0.716564</td>\n",
       "      <td>0.936399</td>\n",
       "      <td>0.938907</td>\n",
       "      <td>0.961957</td>\n",
       "      <td>0.812804</td>\n",
       "      <td>3632.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>3401</td>\n",
       "      <td>38</td>\n",
       "      <td>584</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset              model data balancing technique  fold  precision_1  \\\n",
       "20     DF5  Linear Regression     Random Under Sampler     1     0.988979   \n",
       "21     DF5  Linear Regression     Random Under Sampler     2     0.988950   \n",
       "\n",
       "    precision_2  recall_1  recall_2  f1-score_1  f1-score_2  support_1  \\\n",
       "20     0.710918  0.936042  0.937807    0.961783    0.808751     3643.0   \n",
       "21     0.716564  0.936399  0.938907    0.961957    0.812804     3632.0   \n",
       "\n",
       "    support_2    TP  FP   TN   FN  \n",
       "20      611.0  3410  38  573  233  \n",
       "21      622.0  3401  38  584  231  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_metrics[(combined_metrics['data balancing technique'] == 'Random Under Sampler') & (combined_metrics['dataset'] == 'DF5')].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc10646",
   "metadata": {},
   "source": [
    "### Linear Regression with df5 data and imbalance data tackling (RandomOverSampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c500a1fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.94\n",
      "Mean Precision: 0.95\n",
      "Mean Recall: 0.94\n",
      "Mean F1-Score: 0.94\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df5' is your DataFrame with features and the target column\n",
    "# Replace 'features' with the actual list of feature columns\n",
    "features = df5.drop(columns=['target'])  # Drop the target column to get the feature columns\n",
    "target = df5['target']  # Target column to predict\n",
    "\n",
    "# Initialize Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Initialize KFold with 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    # Oversampling the majority class\n",
    "    ros = RandomOverSampler(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Predict on the testing set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    y_pred = np.round(y_pred)\n",
    "\n",
    "    y_pred[y_pred <= 0] = 1\n",
    "    y_pred[y_pred >= 2] = 2\n",
    "    \n",
    "    # Model evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred.round())\n",
    "    precision = precision_score(y_test, y_pred.round(), average='weighted')\n",
    "    recall = recall_score(y_test, y_pred.round(), average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred.round(), average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred.round())\n",
    "    \n",
    "    # Convert classification report to DataFrame\n",
    "    report_df = pd.DataFrame(classification_report(y_test, y_pred.round(), output_dict=True)).transpose()\n",
    "    # Convert confusion matrix to DataFrame\n",
    "    matrix_df = pd.DataFrame(confusion_matrix(y_test, y_pred.round()))\n",
    "    \n",
    "    # Extract metrics for class 1\n",
    "    metrics_1 = report_df.loc['1', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract metrics for class 2\n",
    "    metrics_2 = report_df.loc['2', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract TP, TN, FP, FN counts from the confusion matrix DataFrame\n",
    "    TP = matrix_df.loc[0, 0]\n",
    "    TN = matrix_df.loc[1, 1]\n",
    "    FP = matrix_df.loc[1, 0]\n",
    "    FN = matrix_df.loc[0, 1]\n",
    "    \n",
    "    new_metric_row = {\n",
    "    'dataset': 'DF5',\n",
    "    'model' : 'Linear Regression',\n",
    "    'data balancing technique' : 'Random Over Sampler',\n",
    "    'fold' : i,\n",
    "    'precision_1': metrics_1['precision'],\n",
    "    'precision_2': metrics_2['precision'],\n",
    "    'recall_1': metrics_1['recall'],\n",
    "    'recall_2': metrics_2['recall'],\n",
    "    'f1-score_1': metrics_1['f1-score'],\n",
    "    'f1-score_2': metrics_2['f1-score'],\n",
    "    'support_1': metrics_1['support'],\n",
    "    'support_2': metrics_2['support'],\n",
    "    'TP' : TP,\n",
    "    'FP' : FP,\n",
    "    'TN' : TN,\n",
    "    'FN' : FN\n",
    "    }\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    #combined_metrics = combined_metrics.append(new_metric_row, ignore_index=True)\n",
    "    combined_metrics.loc[len(combined_metrics)] = new_metric_row\n",
    "    \n",
    "    \n",
    "    # Append evaluation metrics to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "\n",
    "# Calculate mean evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores) #sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = np.mean(precision_scores) #sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = np.mean(recall_scores) #sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = np.mean(f1_scores) #sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print('Mean Accuracy: {:.2f}'.format(mean_accuracy))\n",
    "print('Mean Precision: {:.2f}'.format(mean_precision))\n",
    "print('Mean Recall: {:.2f}'.format(mean_recall))\n",
    "print('Mean F1-Score: {:.2f}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ca7e58c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>data balancing technique</th>\n",
       "      <th>fold</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_2</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>f1-score_1</th>\n",
       "      <th>f1-score_2</th>\n",
       "      <th>support_1</th>\n",
       "      <th>support_2</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>1</td>\n",
       "      <td>0.988947</td>\n",
       "      <td>0.702206</td>\n",
       "      <td>0.933297</td>\n",
       "      <td>0.937807</td>\n",
       "      <td>0.960316</td>\n",
       "      <td>0.803083</td>\n",
       "      <td>3643.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>3400</td>\n",
       "      <td>38</td>\n",
       "      <td>573</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>2</td>\n",
       "      <td>0.987823</td>\n",
       "      <td>0.720497</td>\n",
       "      <td>0.938051</td>\n",
       "      <td>0.932476</td>\n",
       "      <td>0.962293</td>\n",
       "      <td>0.812894</td>\n",
       "      <td>3632.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>3407</td>\n",
       "      <td>42</td>\n",
       "      <td>580</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset              model data balancing technique  fold  precision_1  \\\n",
       "30     DF5  Linear Regression      Random Over Sampler     1     0.988947   \n",
       "31     DF5  Linear Regression      Random Over Sampler     2     0.987823   \n",
       "\n",
       "    precision_2  recall_1  recall_2  f1-score_1  f1-score_2  support_1  \\\n",
       "30     0.702206  0.933297  0.937807    0.960316    0.803083     3643.0   \n",
       "31     0.720497  0.938051  0.932476    0.962293    0.812894     3632.0   \n",
       "\n",
       "    support_2    TP  FP   TN   FN  \n",
       "30      611.0  3400  38  573  243  \n",
       "31      622.0  3407  42  580  225  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_metrics[(combined_metrics['data balancing technique'] == 'Random Over Sampler') & (combined_metrics['dataset'] == 'DF5')].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3502aa0f",
   "metadata": {},
   "source": [
    "### Linear Regression with df5 data and imbalance data tackling (SMOTEENN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "14344c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.93\n",
      "Mean Precision: 0.95\n",
      "Mean Recall: 0.93\n",
      "Mean F1-Score: 0.94\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df5' is your DataFrame with features and the target column\n",
    "# Replace 'features' with the actual list of feature columns\n",
    "features = df5.drop(columns=['target'])  # Drop the target column to get the feature columns\n",
    "target = df5['target']  # Target column to predict\n",
    "\n",
    "# Initialize Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Initialize KFold with 10 folds\n",
    "kf = KFold(n_splits=9, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    # Apply SMOTEENN for combined over and undersampling\n",
    "    smote_enn = SMOTEENN(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote_enn.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Predict on the testing set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    y_pred = np.round(y_pred)\n",
    "\n",
    "    y_pred[y_pred <= 0] = 1\n",
    "    y_pred[y_pred >= 2] = 2\n",
    "    \n",
    "    # Model evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred.round())\n",
    "    precision = precision_score(y_test, y_pred.round(), average='weighted')\n",
    "    recall = recall_score(y_test, y_pred.round(), average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred.round(), average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred.round())\n",
    "    \n",
    "    # Convert classification report to DataFrame\n",
    "    report_df = pd.DataFrame(classification_report(y_test, y_pred.round(), output_dict=True)).transpose()\n",
    "    # Convert confusion matrix to DataFrame\n",
    "    matrix_df = pd.DataFrame(confusion_matrix(y_test, y_pred.round()))\n",
    "    \n",
    "    # Extract metrics for class 1\n",
    "    metrics_1 = report_df.loc['1', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract metrics for class 2\n",
    "    metrics_2 = report_df.loc['2', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract TP, TN, FP, FN counts from the confusion matrix DataFrame\n",
    "    TP = matrix_df.loc[0, 0]\n",
    "    TN = matrix_df.loc[1, 1]\n",
    "    FP = matrix_df.loc[1, 0]\n",
    "    FN = matrix_df.loc[0, 1]\n",
    "    \n",
    "    new_metric_row = {\n",
    "    'dataset': 'DF5',\n",
    "    'model' : 'Linear Regression',\n",
    "    'data balancing technique' : 'SMOTEENN',\n",
    "    'fold' : i,\n",
    "    'precision_1': metrics_1['precision'],\n",
    "    'precision_2': metrics_2['precision'],\n",
    "    'recall_1': metrics_1['recall'],\n",
    "    'recall_2': metrics_2['recall'],\n",
    "    'f1-score_1': metrics_1['f1-score'],\n",
    "    'f1-score_2': metrics_2['f1-score'],\n",
    "    'support_1': metrics_1['support'],\n",
    "    'support_2': metrics_2['support'],\n",
    "    'TP' : TP,\n",
    "    'FP' : FP,\n",
    "    'TN' : TN,\n",
    "    'FN' : FN\n",
    "    }\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    #combined_metrics = combined_metrics.append(new_metric_row, ignore_index=True)\n",
    "    combined_metrics.loc[len(combined_metrics)] = new_metric_row\n",
    "    \n",
    "    \n",
    "    # Append evaluation metrics to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "\n",
    "# Calculate mean evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores) #sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = np.mean(precision_scores) #sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = np.mean(recall_scores) #sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = np.mean(f1_scores) #sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print('Mean Accuracy: {:.2f}'.format(mean_accuracy))\n",
    "print('Mean Precision: {:.2f}'.format(mean_precision))\n",
    "print('Mean Recall: {:.2f}'.format(mean_recall))\n",
    "print('Mean F1-Score: {:.2f}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "661a7658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>data balancing technique</th>\n",
       "      <th>fold</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_2</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>f1-score_1</th>\n",
       "      <th>f1-score_2</th>\n",
       "      <th>support_1</th>\n",
       "      <th>support_2</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>SMOTEENN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.990924</td>\n",
       "      <td>0.657492</td>\n",
       "      <td>0.916996</td>\n",
       "      <td>0.949926</td>\n",
       "      <td>0.952528</td>\n",
       "      <td>0.777108</td>\n",
       "      <td>4048.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>3712</td>\n",
       "      <td>34</td>\n",
       "      <td>645</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>SMOTEENN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.988606</td>\n",
       "      <td>0.643269</td>\n",
       "      <td>0.907597</td>\n",
       "      <td>0.940928</td>\n",
       "      <td>0.946371</td>\n",
       "      <td>0.764135</td>\n",
       "      <td>4015.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>3644</td>\n",
       "      <td>42</td>\n",
       "      <td>669</td>\n",
       "      <td>371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset              model data balancing technique  fold  precision_1  \\\n",
       "40     DF5  Linear Regression                 SMOTEENN     1     0.990924   \n",
       "41     DF5  Linear Regression                 SMOTEENN     2     0.988606   \n",
       "\n",
       "    precision_2  recall_1  recall_2  f1-score_1  f1-score_2  support_1  \\\n",
       "40     0.657492  0.916996  0.949926    0.952528    0.777108     4048.0   \n",
       "41     0.643269  0.907597  0.940928    0.946371    0.764135     4015.0   \n",
       "\n",
       "    support_2    TP  FP   TN   FN  \n",
       "40      679.0  3712  34  645  336  \n",
       "41      711.0  3644  42  669  371  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_metrics[(combined_metrics['data balancing technique'] == 'SMOTEENN') & (combined_metrics['dataset'] == 'DF5')].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d61e0f",
   "metadata": {},
   "source": [
    "### Linear Regression with df5 data and imbalance data tackling (SMOTETOMEK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "474f7eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.93\n",
      "Mean Precision: 0.95\n",
      "Mean Recall: 0.93\n",
      "Mean F1-Score: 0.94\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df5' is your DataFrame with features and the target column\n",
    "# Replace 'features' with the actual list of feature columns\n",
    "features = df5.drop(columns=['target'])  # Drop the target column to get the feature columns\n",
    "target = df5['target']  # Target column to predict\n",
    "\n",
    "# Initialize Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Initialize KFold with 10 folds\n",
    "kf = KFold(n_splits=9, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    # Apply SMOTETomek for combined over and undersampling\n",
    "    SMOTE_Tomek = SMOTETomek(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = SMOTE_Tomek.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Predict on the testing set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    y_pred = np.round(y_pred)\n",
    "\n",
    "    y_pred[y_pred <= 0] = 1\n",
    "    y_pred[y_pred >= 2] = 2\n",
    "    \n",
    "    # Model evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred.round())\n",
    "    precision = precision_score(y_test, y_pred.round(), average='weighted')\n",
    "    recall = recall_score(y_test, y_pred.round(), average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred.round(), average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred.round())\n",
    "    \n",
    "    # Convert classification report to DataFrame\n",
    "    report_df = pd.DataFrame(classification_report(y_test, y_pred.round(), output_dict=True)).transpose()\n",
    "    # Convert confusion matrix to DataFrame\n",
    "    matrix_df = pd.DataFrame(confusion_matrix(y_test, y_pred.round()))\n",
    "    \n",
    "    # Extract metrics for class 1\n",
    "    metrics_1 = report_df.loc['1', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract metrics for class 2\n",
    "    metrics_2 = report_df.loc['2', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract TP, TN, FP, FN counts from the confusion matrix DataFrame\n",
    "    TP = matrix_df.loc[0, 0]\n",
    "    TN = matrix_df.loc[1, 1]\n",
    "    FP = matrix_df.loc[1, 0]\n",
    "    FN = matrix_df.loc[0, 1]\n",
    "    \n",
    "    new_metric_row = {\n",
    "    'dataset': 'DF5',\n",
    "    'model' : 'Linear Regression',\n",
    "    'data balancing technique' : 'SMOTETomek',\n",
    "    'fold' : i,\n",
    "    'precision_1': metrics_1['precision'],\n",
    "    'precision_2': metrics_2['precision'],\n",
    "    'recall_1': metrics_1['recall'],\n",
    "    'recall_2': metrics_2['recall'],\n",
    "    'f1-score_1': metrics_1['f1-score'],\n",
    "    'f1-score_2': metrics_2['f1-score'],\n",
    "    'support_1': metrics_1['support'],\n",
    "    'support_2': metrics_2['support'],\n",
    "    'TP' : TP,\n",
    "    'FP' : FP,\n",
    "    'TN' : TN,\n",
    "    'FN' : FN\n",
    "    }\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    #combined_metrics = combined_metrics.append(new_metric_row, ignore_index=True)\n",
    "    combined_metrics.loc[len(combined_metrics)] = new_metric_row\n",
    "    \n",
    "    \n",
    "    # Append evaluation metrics to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "\n",
    "# Calculate mean evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores) #sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = np.mean(precision_scores) #sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = np.mean(recall_scores) #sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = np.mean(f1_scores) #sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print('Mean Accuracy: {:.2f}'.format(mean_accuracy))\n",
    "print('Mean Precision: {:.2f}'.format(mean_precision))\n",
    "print('Mean Recall: {:.2f}'.format(mean_recall))\n",
    "print('Mean F1-Score: {:.2f}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f6da809c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>data balancing technique</th>\n",
       "      <th>fold</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_2</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>f1-score_1</th>\n",
       "      <th>f1-score_2</th>\n",
       "      <th>support_1</th>\n",
       "      <th>support_2</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>SMOTETomek</td>\n",
       "      <td>1</td>\n",
       "      <td>0.984086</td>\n",
       "      <td>0.742479</td>\n",
       "      <td>0.947134</td>\n",
       "      <td>0.908689</td>\n",
       "      <td>0.965257</td>\n",
       "      <td>0.817219</td>\n",
       "      <td>4048.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>3834</td>\n",
       "      <td>62</td>\n",
       "      <td>617</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>SMOTETomek</td>\n",
       "      <td>2</td>\n",
       "      <td>0.982411</td>\n",
       "      <td>0.747674</td>\n",
       "      <td>0.945953</td>\n",
       "      <td>0.904360</td>\n",
       "      <td>0.963837</td>\n",
       "      <td>0.818587</td>\n",
       "      <td>4015.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>3798</td>\n",
       "      <td>68</td>\n",
       "      <td>643</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>SMOTETomek</td>\n",
       "      <td>3</td>\n",
       "      <td>0.981195</td>\n",
       "      <td>0.752370</td>\n",
       "      <td>0.947984</td>\n",
       "      <td>0.896893</td>\n",
       "      <td>0.964304</td>\n",
       "      <td>0.818299</td>\n",
       "      <td>4018.0</td>\n",
       "      <td>708.0</td>\n",
       "      <td>3809</td>\n",
       "      <td>73</td>\n",
       "      <td>635</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>SMOTETomek</td>\n",
       "      <td>4</td>\n",
       "      <td>0.980165</td>\n",
       "      <td>0.746445</td>\n",
       "      <td>0.946753</td>\n",
       "      <td>0.891089</td>\n",
       "      <td>0.963169</td>\n",
       "      <td>0.812379</td>\n",
       "      <td>4019.0</td>\n",
       "      <td>707.0</td>\n",
       "      <td>3805</td>\n",
       "      <td>77</td>\n",
       "      <td>630</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>SMOTETomek</td>\n",
       "      <td>5</td>\n",
       "      <td>0.982620</td>\n",
       "      <td>0.724455</td>\n",
       "      <td>0.940417</td>\n",
       "      <td>0.904011</td>\n",
       "      <td>0.961055</td>\n",
       "      <td>0.804334</td>\n",
       "      <td>4028.0</td>\n",
       "      <td>698.0</td>\n",
       "      <td>3788</td>\n",
       "      <td>67</td>\n",
       "      <td>631</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>SMOTETomek</td>\n",
       "      <td>6</td>\n",
       "      <td>0.984915</td>\n",
       "      <td>0.749149</td>\n",
       "      <td>0.944860</td>\n",
       "      <td>0.919220</td>\n",
       "      <td>0.964472</td>\n",
       "      <td>0.825516</td>\n",
       "      <td>4008.0</td>\n",
       "      <td>718.0</td>\n",
       "      <td>3787</td>\n",
       "      <td>58</td>\n",
       "      <td>660</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>SMOTETomek</td>\n",
       "      <td>7</td>\n",
       "      <td>0.977237</td>\n",
       "      <td>0.746681</td>\n",
       "      <td>0.942230</td>\n",
       "      <td>0.885827</td>\n",
       "      <td>0.959414</td>\n",
       "      <td>0.810324</td>\n",
       "      <td>3964.0</td>\n",
       "      <td>762.0</td>\n",
       "      <td>3735</td>\n",
       "      <td>87</td>\n",
       "      <td>675</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>SMOTETomek</td>\n",
       "      <td>8</td>\n",
       "      <td>0.980555</td>\n",
       "      <td>0.750288</td>\n",
       "      <td>0.945736</td>\n",
       "      <td>0.896836</td>\n",
       "      <td>0.962831</td>\n",
       "      <td>0.817043</td>\n",
       "      <td>3999.0</td>\n",
       "      <td>727.0</td>\n",
       "      <td>3782</td>\n",
       "      <td>75</td>\n",
       "      <td>652</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>SMOTETomek</td>\n",
       "      <td>9</td>\n",
       "      <td>0.983112</td>\n",
       "      <td>0.749145</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.909972</td>\n",
       "      <td>0.963708</td>\n",
       "      <td>0.821764</td>\n",
       "      <td>4004.0</td>\n",
       "      <td>722.0</td>\n",
       "      <td>3784</td>\n",
       "      <td>65</td>\n",
       "      <td>657</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset              model data balancing technique  fold  precision_1  \\\n",
       "49     DF5  Linear Regression               SMOTETomek     1     0.984086   \n",
       "50     DF5  Linear Regression               SMOTETomek     2     0.982411   \n",
       "51     DF5  Linear Regression               SMOTETomek     3     0.981195   \n",
       "52     DF5  Linear Regression               SMOTETomek     4     0.980165   \n",
       "53     DF5  Linear Regression               SMOTETomek     5     0.982620   \n",
       "54     DF5  Linear Regression               SMOTETomek     6     0.984915   \n",
       "55     DF5  Linear Regression               SMOTETomek     7     0.977237   \n",
       "56     DF5  Linear Regression               SMOTETomek     8     0.980555   \n",
       "57     DF5  Linear Regression               SMOTETomek     9     0.983112   \n",
       "\n",
       "    precision_2  recall_1  recall_2  f1-score_1  f1-score_2  support_1  \\\n",
       "49     0.742479  0.947134  0.908689    0.965257    0.817219     4048.0   \n",
       "50     0.747674  0.945953  0.904360    0.963837    0.818587     4015.0   \n",
       "51     0.752370  0.947984  0.896893    0.964304    0.818299     4018.0   \n",
       "52     0.746445  0.946753  0.891089    0.963169    0.812379     4019.0   \n",
       "53     0.724455  0.940417  0.904011    0.961055    0.804334     4028.0   \n",
       "54     0.749149  0.944860  0.919220    0.964472    0.825516     4008.0   \n",
       "55     0.746681  0.942230  0.885827    0.959414    0.810324     3964.0   \n",
       "56     0.750288  0.945736  0.896836    0.962831    0.817043     3999.0   \n",
       "57     0.749145  0.945055  0.909972    0.963708    0.821764     4004.0   \n",
       "\n",
       "    support_2    TP  FP   TN   FN  \n",
       "49      679.0  3834  62  617  214  \n",
       "50      711.0  3798  68  643  217  \n",
       "51      708.0  3809  73  635  209  \n",
       "52      707.0  3805  77  630  214  \n",
       "53      698.0  3788  67  631  240  \n",
       "54      718.0  3787  58  660  221  \n",
       "55      762.0  3735  87  675  229  \n",
       "56      727.0  3782  75  652  217  \n",
       "57      722.0  3784  65  657  220  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_metrics[(combined_metrics['data balancing technique'] == 'SMOTETomek') & (combined_metrics['dataset'] == 'DF5')]#.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7106750",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85f183d",
   "metadata": {},
   "source": [
    "## DF5c - Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b53bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'df5' is your DataFrame with features and the target column\n",
    "# Replace 'features' with the actual list of feature columns\n",
    "features = df5c.drop(columns=['target'])  # Drop the target column to get the feature columns\n",
    "target = df5c['target']  # Target column to predict\n",
    "\n",
    "# Initialize Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Initialize KFold with 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the testing set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Model evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred.round())\n",
    "    precision = precision_score(y_test, y_pred.round().round(), average='weighted')\n",
    "    recall = recall_score(y_test, y_pred.round(), average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred.round(), average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred.round())\n",
    "    \n",
    "    # Convert classification report to DataFrame\n",
    "    report_df = pd.DataFrame(classification_report(y_test, y_pred.round(), output_dict=True)).transpose()\n",
    "    # Convert confusion matrix to DataFrame\n",
    "    matrix_df = pd.DataFrame(confusion_matrix(y_test, y_pred.round()))\n",
    "    \n",
    "    # Extract metrics for class 1\n",
    "    metrics_1 = report_df.loc['1', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract metrics for class 2\n",
    "    metrics_2 = report_df.loc['2', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract TP, TN, FP, FN counts from the confusion matrix DataFrame\n",
    "    TP = matrix_df.loc[0, 0]\n",
    "    TN = matrix_df.loc[1, 1]\n",
    "    FP = matrix_df.loc[1, 0]\n",
    "    FN = matrix_df.loc[0, 1]\n",
    "    \n",
    "    new_metric_row = {\n",
    "    'dataset': 'DF5c',\n",
    "    'model' : 'Linear Regression',\n",
    "    'data balancing technique' : 'None',\n",
    "    'fold' : i,\n",
    "    'precision_1': metrics_1['precision'],\n",
    "    'precision_2': metrics_2['precision'],\n",
    "    'recall_1': metrics_1['recall'],\n",
    "    'recall_2': metrics_2['recall'],\n",
    "    'f1-score_1': metrics_1['f1-score'],\n",
    "    'f1-score_2': metrics_2['f1-score'],\n",
    "    'support_1': metrics_1['support'],\n",
    "    'support_2': metrics_2['support'],\n",
    "    'TP' : TP,\n",
    "    'FP' : FP,\n",
    "    'TN' : TN,\n",
    "    'FN' : FN\n",
    "    }\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    #combined_metrics = combined_metrics.append(new_metric_row, ignore_index=True)\n",
    "    combined_metrics.loc[len(combined_metrics)] = new_metric_row\n",
    "    \n",
    "    \n",
    "    # Append evaluation metrics to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "\n",
    "# Calculate mean evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores) #sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = np.mean(precision_scores) #sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = np.mean(recall_scores) #sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = np.mean(f1_scores) #sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print('Mean Accuracy: {:.2f}'.format(mean_accuracy))\n",
    "print('Mean Precision: {:.2f}'.format(mean_precision))\n",
    "print('Mean Recall: {:.2f}'.format(mean_recall))\n",
    "print('Mean F1-Score: {:.2f}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbc10dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_metrics[(combined_metrics['data balancing technique'] == 'None') & (combined_metrics['dataset'] == 'DF5c')].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a96351",
   "metadata": {},
   "source": [
    "### Linear Regression with df5c data and imbalance data tackling (SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa40392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'df5' is your DataFrame with features and the target column\n",
    "# Replace 'features' with the actual list of feature columns\n",
    "features = df5c.drop(columns=['target'])  # Drop the target column to get the feature columns\n",
    "target = df5c['target']  # Target column to predict\n",
    "\n",
    "# Initialize Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Initialize KFold with 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    # Apply SMOTE to the training data\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Predict on the testing set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Model evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred.round())\n",
    "    precision = precision_score(y_test, y_pred.round(), average='weighted')\n",
    "    recall = recall_score(y_test, y_pred.round(), average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred.round(), average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred.round())\n",
    "    \n",
    "    # Convert classification report to DataFrame\n",
    "    report_df = pd.DataFrame(classification_report(y_test, y_pred.round(), output_dict=True)).transpose()\n",
    "    # Convert confusion matrix to DataFrame\n",
    "    matrix_df = pd.DataFrame(confusion_matrix(y_test, y_pred.round()))\n",
    "    \n",
    "    # Extract metrics for class 1\n",
    "    metrics_1 = report_df.loc['1', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract metrics for class 2\n",
    "    metrics_2 = report_df.loc['2', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract TP, TN, FP, FN counts from the confusion matrix DataFrame\n",
    "    TP = matrix_df.loc[0, 0]\n",
    "    TN = matrix_df.loc[1, 1]\n",
    "    FP = matrix_df.loc[1, 0]\n",
    "    FN = matrix_df.loc[0, 1]\n",
    "    \n",
    "    new_metric_row = {\n",
    "    'dataset': 'DF5c',\n",
    "    'model' : 'Linear Regression',\n",
    "    'data balancing technique' : 'SMOTE',\n",
    "    'fold' : i,\n",
    "    'precision_1': metrics_1['precision'],\n",
    "    'precision_2': metrics_2['precision'],\n",
    "    'recall_1': metrics_1['recall'],\n",
    "    'recall_2': metrics_2['recall'],\n",
    "    'f1-score_1': metrics_1['f1-score'],\n",
    "    'f1-score_2': metrics_2['f1-score'],\n",
    "    'support_1': metrics_1['support'],\n",
    "    'support_2': metrics_2['support'],\n",
    "    'TP' : TP,\n",
    "    'FP' : FP,\n",
    "    'TN' : TN,\n",
    "    'FN' : FN\n",
    "    }\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    #combined_metrics = combined_metrics.append(new_metric_row, ignore_index=True)\n",
    "    combined_metrics.loc[len(combined_metrics)] = new_metric_row\n",
    "    \n",
    "    \n",
    "    # Append evaluation metrics to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "\n",
    "# Calculate mean evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores) #sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = np.mean(precision_scores) #sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = np.mean(recall_scores) #sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = np.mean(f1_scores) #sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print('Mean Accuracy: {:.2f}'.format(mean_accuracy))\n",
    "print('Mean Precision: {:.2f}'.format(mean_precision))\n",
    "print('Mean Recall: {:.2f}'.format(mean_recall))\n",
    "print('Mean F1-Score: {:.2f}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d1a9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_metrics[(combined_metrics['data balancing technique'] == 'SMOTE') & (combined_metrics['dataset'] == 'DF5c')].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fab885",
   "metadata": {},
   "source": [
    "### Linear Regression with df5c data and imbalance data tackling (Random Under Sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9f5e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'df5' is your DataFrame with features and the target column\n",
    "# Replace 'features' with the actual list of feature columns\n",
    "features = df5c.drop(columns=['target'])  # Drop the target column to get the feature columns\n",
    "target = df5c['target']  # Target column to predict\n",
    "\n",
    "# Initialize Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Initialize KFold with 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    # Apply RUS to the training data\n",
    "    rus = RandomUnderSampler(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Predict on the testing set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Model evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred.round())\n",
    "    precision = precision_score(y_test, y_pred.round(), average='weighted')\n",
    "    recall = recall_score(y_test, y_pred.round(), average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred.round(), average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred.round())\n",
    "    \n",
    "    # Convert classification report to DataFrame\n",
    "    report_df = pd.DataFrame(classification_report(y_test, y_pred.round(), output_dict=True)).transpose()\n",
    "    # Convert confusion matrix to DataFrame\n",
    "    matrix_df = pd.DataFrame(confusion_matrix(y_test, y_pred.round()))\n",
    "    \n",
    "    # Extract metrics for class 1\n",
    "    metrics_1 = report_df.loc['1', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract metrics for class 2\n",
    "    metrics_2 = report_df.loc['2', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract TP, TN, FP, FN counts from the confusion matrix DataFrame\n",
    "    TP = matrix_df.loc[0, 0]\n",
    "    TN = matrix_df.loc[1, 1]\n",
    "    FP = matrix_df.loc[1, 0]\n",
    "    FN = matrix_df.loc[0, 1]\n",
    "    \n",
    "    new_metric_row = {\n",
    "    'dataset': 'DF5c',\n",
    "    'model' : 'Linear Regression',\n",
    "    'data balancing technique' : 'Random Under Sampler',\n",
    "    'fold' : i,\n",
    "    'precision_1': metrics_1['precision'],\n",
    "    'precision_2': metrics_2['precision'],\n",
    "    'recall_1': metrics_1['recall'],\n",
    "    'recall_2': metrics_2['recall'],\n",
    "    'f1-score_1': metrics_1['f1-score'],\n",
    "    'f1-score_2': metrics_2['f1-score'],\n",
    "    'support_1': metrics_1['support'],\n",
    "    'support_2': metrics_2['support'],\n",
    "    'TP' : TP,\n",
    "    'FP' : FP,\n",
    "    'TN' : TN,\n",
    "    'FN' : FN\n",
    "    }\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    #combined_metrics = combined_metrics.append(new_metric_row, ignore_index=True)\n",
    "    combined_metrics.loc[len(combined_metrics)] = new_metric_row\n",
    "    \n",
    "    \n",
    "    # Append evaluation metrics to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "\n",
    "# Calculate mean evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores) #sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = np.mean(precision_scores) #sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = np.mean(recall_scores) #sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = np.mean(f1_scores) #sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print('Mean Accuracy: {:.2f}'.format(mean_accuracy))\n",
    "print('Mean Precision: {:.2f}'.format(mean_precision))\n",
    "print('Mean Recall: {:.2f}'.format(mean_recall))\n",
    "print('Mean F1-Score: {:.2f}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1bb284",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_metrics[(combined_metrics['data balancing technique'] == 'Random Under Sampler') & (combined_metrics['dataset'] == 'DF5c')].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596f2d9a",
   "metadata": {},
   "source": [
    "### Linear Regression with df5c data and imbalance data tackling (Random Over Sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deeacc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'df5' is your DataFrame with features and the target column\n",
    "# Replace 'features' with the actual list of feature columns\n",
    "features = df5c.drop(columns=['target'])  # Drop the target column to get the feature columns\n",
    "target = df5c['target']  # Target column to predict\n",
    "\n",
    "# Initialize Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Initialize KFold with 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    # Apply ROS to the training data\n",
    "    ros = RandomOverSampler(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Predict on the testing set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Model evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred.round())\n",
    "    precision = precision_score(y_test, y_pred.round(), average='weighted')\n",
    "    recall = recall_score(y_test, y_pred.round(), average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred.round(), average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred.round())\n",
    "    \n",
    "    # Convert classification report to DataFrame\n",
    "    report_df = pd.DataFrame(classification_report(y_test, y_pred.round(), output_dict=True)).transpose()\n",
    "    # Convert confusion matrix to DataFrame\n",
    "    matrix_df = pd.DataFrame(confusion_matrix(y_test, y_pred.round()))\n",
    "    \n",
    "    # Extract metrics for class 1\n",
    "    metrics_1 = report_df.loc['1', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract metrics for class 2\n",
    "    metrics_2 = report_df.loc['2', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract TP, TN, FP, FN counts from the confusion matrix DataFrame\n",
    "    TP = matrix_df.loc[0, 0]\n",
    "    TN = matrix_df.loc[1, 1]\n",
    "    FP = matrix_df.loc[1, 0]\n",
    "    FN = matrix_df.loc[0, 1]\n",
    "    \n",
    "    new_metric_row = {\n",
    "    'dataset': 'DF5c',\n",
    "    'model' : 'Linear Regression',\n",
    "    'data balancing technique' : 'Random Over Sampler',\n",
    "    'fold' : i,\n",
    "    'precision_1': metrics_1['precision'],\n",
    "    'precision_2': metrics_2['precision'],\n",
    "    'recall_1': metrics_1['recall'],\n",
    "    'recall_2': metrics_2['recall'],\n",
    "    'f1-score_1': metrics_1['f1-score'],\n",
    "    'f1-score_2': metrics_2['f1-score'],\n",
    "    'support_1': metrics_1['support'],\n",
    "    'support_2': metrics_2['support'],\n",
    "    'TP' : TP,\n",
    "    'FP' : FP,\n",
    "    'TN' : TN,\n",
    "    'FN' : FN\n",
    "    }\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    #combined_metrics = combined_metrics.append(new_metric_row, ignore_index=True)\n",
    "    combined_metrics.loc[len(combined_metrics)] = new_metric_row\n",
    "    \n",
    "    \n",
    "    # Append evaluation metrics to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "\n",
    "# Calculate mean evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores) #sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = np.mean(precision_scores) #sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = np.mean(recall_scores) #sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = np.mean(f1_scores) #sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print('Mean Accuracy: {:.2f}'.format(mean_accuracy))\n",
    "print('Mean Precision: {:.2f}'.format(mean_precision))\n",
    "print('Mean Recall: {:.2f}'.format(mean_recall))\n",
    "print('Mean F1-Score: {:.2f}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c845f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_metrics[(combined_metrics['data balancing technique'] == 'Random Over Sampler') & (combined_metrics['dataset'] == 'DF5c')].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d688e2",
   "metadata": {},
   "source": [
    "### Linear Regression with df5c data and imbalance data tackling (SMOTEENN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945b4908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'df5' is your DataFrame with features and the target column\n",
    "# Replace 'features' with the actual list of feature columns\n",
    "features = df5c.drop(columns=['target'])  # Drop the target column to get the feature columns\n",
    "target = df5c['target']  # Target column to predict\n",
    "\n",
    "# Initialize Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Initialize KFold with 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    # Apply ROS to the training data\n",
    "    smote_enn = SMOTEENN(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote_enn.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Predict on the testing set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Model evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred.round())\n",
    "    precision = precision_score(y_test, y_pred.round(), average='weighted')\n",
    "    recall = recall_score(y_test, y_pred.round(), average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred.round(), average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred.round())\n",
    "    \n",
    "    # Convert classification report to DataFrame\n",
    "    report_df = pd.DataFrame(classification_report(y_test, y_pred.round(), output_dict=True)).transpose()\n",
    "    # Convert confusion matrix to DataFrame\n",
    "    matrix_df = pd.DataFrame(confusion_matrix(y_test, y_pred.round()))\n",
    "    \n",
    "    # Extract metrics for class 1\n",
    "    metrics_1 = report_df.loc['1', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract metrics for class 2\n",
    "    metrics_2 = report_df.loc['2', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract TP, TN, FP, FN counts from the confusion matrix DataFrame\n",
    "    TP = matrix_df.loc[0, 0]\n",
    "    TN = matrix_df.loc[1, 1]\n",
    "    FP = matrix_df.loc[1, 0]\n",
    "    FN = matrix_df.loc[0, 1]\n",
    "    \n",
    "    new_metric_row = {\n",
    "    'dataset': 'DF5c',\n",
    "    'model' : 'Linear Regression',\n",
    "    'data balancing technique' : 'SMOTEENN',\n",
    "    'fold' : i,\n",
    "    'precision_1': metrics_1['precision'],\n",
    "    'precision_2': metrics_2['precision'],\n",
    "    'recall_1': metrics_1['recall'],\n",
    "    'recall_2': metrics_2['recall'],\n",
    "    'f1-score_1': metrics_1['f1-score'],\n",
    "    'f1-score_2': metrics_2['f1-score'],\n",
    "    'support_1': metrics_1['support'],\n",
    "    'support_2': metrics_2['support'],\n",
    "    'TP' : TP,\n",
    "    'FP' : FP,\n",
    "    'TN' : TN,\n",
    "    'FN' : FN\n",
    "    }\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    #combined_metrics = combined_metrics.append(new_metric_row, ignore_index=True)\n",
    "    combined_metrics.loc[len(combined_metrics)] = new_metric_row\n",
    "    \n",
    "    \n",
    "    # Append evaluation metrics to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "\n",
    "# Calculate mean evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores) #sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = np.mean(precision_scores) #sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = np.mean(recall_scores) #sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = np.mean(f1_scores) #sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print('Mean Accuracy: {:.2f}'.format(mean_accuracy))\n",
    "print('Mean Precision: {:.2f}'.format(mean_precision))\n",
    "print('Mean Recall: {:.2f}'.format(mean_recall))\n",
    "print('Mean F1-Score: {:.2f}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81297c53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_metrics[(combined_metrics['data balancing technique'] == 'SMOTEENN') & (combined_metrics['dataset'] == 'DF5c')].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d72534",
   "metadata": {},
   "source": [
    "### Linear Regression with df5c data and imbalance data tackling (SMOTETomek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf502b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'df5' is your DataFrame with features and the target column\n",
    "# Replace 'features' with the actual list of feature columns\n",
    "features = df5c.drop(columns=['target'])  # Drop the target column to get the feature columns\n",
    "target = df5c['target']  # Target column to predict\n",
    "\n",
    "# Initialize Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Initialize KFold with 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    # Apply SMOTEENN to the training data\n",
    "    SMOTETOMEK = SMOTETomek(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = SMOTETOMEK.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Predict on the testing set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    y_pred = np.round(y_pred)\n",
    "    y_pred[y_pred <= 0] = 1\n",
    "    y_pred[y_pred >= 2] = 2\n",
    "    \n",
    "    # Model evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Convert classification report to DataFrame\n",
    "    report_df = pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).transpose()\n",
    "    # Convert confusion matrix to DataFrame\n",
    "    matrix_df = pd.DataFrame(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    # Extract metrics for class 1\n",
    "    metrics_1 = report_df.loc['1', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract metrics for class 2\n",
    "    metrics_2 = report_df.loc['2', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract TP, TN, FP, FN counts from the confusion matrix DataFrame\n",
    "    TP = matrix_df.loc[0, 0]\n",
    "    TN = matrix_df.loc[1, 1]\n",
    "    FP = matrix_df.loc[1, 0]\n",
    "    FN = matrix_df.loc[0, 1]\n",
    "    \n",
    "    new_metric_row = {\n",
    "    'dataset': 'DF5c',\n",
    "    'model' : 'Linear Regression',\n",
    "    'data balancing technique' : 'SMOTETomek',\n",
    "    'fold' : i,\n",
    "    'precision_1': metrics_1['precision'],\n",
    "    'precision_2': metrics_2['precision'],\n",
    "    'recall_1': metrics_1['recall'],\n",
    "    'recall_2': metrics_2['recall'],\n",
    "    'f1-score_1': metrics_1['f1-score'],\n",
    "    'f1-score_2': metrics_2['f1-score'],\n",
    "    'support_1': metrics_1['support'],\n",
    "    'support_2': metrics_2['support'],\n",
    "    'TP' : TP,\n",
    "    'FP' : FP,\n",
    "    'TN' : TN,\n",
    "    'FN' : FN\n",
    "    }\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    #combined_metrics = combined_metrics.append(new_metric_row, ignore_index=True)\n",
    "    combined_metrics.loc[len(combined_metrics)] = new_metric_row\n",
    "    \n",
    "    \n",
    "    # Append evaluation metrics to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "\n",
    "# Calculate mean evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores) #sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = np.mean(precision_scores) #sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = np.mean(recall_scores) #sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = np.mean(f1_scores) #sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print('Mean Accuracy: {:.2f}'.format(mean_accuracy))\n",
    "print('Mean Precision: {:.2f}'.format(mean_precision))\n",
    "print('Mean Recall: {:.2f}'.format(mean_recall))\n",
    "print('Mean F1-Score: {:.2f}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6d42eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_metrics[(combined_metrics['data balancing technique'] == 'SMOTETomek') & (combined_metrics['dataset'] == 'DF5c')].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd948ec1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc4b04f0",
   "metadata": {},
   "source": [
    "## Performance metrics for the Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1158fa25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>data balancing technique</th>\n",
       "      <th>fold</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_2</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>f1-score_1</th>\n",
       "      <th>f1-score_2</th>\n",
       "      <th>support_1</th>\n",
       "      <th>support_2</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0.940766</td>\n",
       "      <td>0.984536</td>\n",
       "      <td>0.998353</td>\n",
       "      <td>0.625205</td>\n",
       "      <td>0.968704</td>\n",
       "      <td>0.764765</td>\n",
       "      <td>3643.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>3637</td>\n",
       "      <td>229</td>\n",
       "      <td>382</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>0.936774</td>\n",
       "      <td>0.994723</td>\n",
       "      <td>0.999449</td>\n",
       "      <td>0.606109</td>\n",
       "      <td>0.967097</td>\n",
       "      <td>0.753247</td>\n",
       "      <td>3632.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>3630</td>\n",
       "      <td>245</td>\n",
       "      <td>377</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>0.930412</td>\n",
       "      <td>0.989305</td>\n",
       "      <td>0.998893</td>\n",
       "      <td>0.578125</td>\n",
       "      <td>0.963437</td>\n",
       "      <td>0.729783</td>\n",
       "      <td>3614.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3610</td>\n",
       "      <td>270</td>\n",
       "      <td>370</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>0.935651</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.998892</td>\n",
       "      <td>0.614907</td>\n",
       "      <td>0.966238</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>3610.0</td>\n",
       "      <td>644.0</td>\n",
       "      <td>3606</td>\n",
       "      <td>248</td>\n",
       "      <td>396</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.981941</td>\n",
       "      <td>0.997786</td>\n",
       "      <td>0.678627</td>\n",
       "      <td>0.971175</td>\n",
       "      <td>0.802583</td>\n",
       "      <td>3613.0</td>\n",
       "      <td>641.0</td>\n",
       "      <td>3605</td>\n",
       "      <td>206</td>\n",
       "      <td>435</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>0.938929</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.632812</td>\n",
       "      <td>0.968503</td>\n",
       "      <td>0.775120</td>\n",
       "      <td>3613.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3613</td>\n",
       "      <td>235</td>\n",
       "      <td>405</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>7</td>\n",
       "      <td>0.936570</td>\n",
       "      <td>0.988152</td>\n",
       "      <td>0.998608</td>\n",
       "      <td>0.631818</td>\n",
       "      <td>0.966595</td>\n",
       "      <td>0.770795</td>\n",
       "      <td>3593.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3588</td>\n",
       "      <td>243</td>\n",
       "      <td>417</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>8</td>\n",
       "      <td>0.936092</td>\n",
       "      <td>0.979310</td>\n",
       "      <td>0.997488</td>\n",
       "      <td>0.635821</td>\n",
       "      <td>0.965815</td>\n",
       "      <td>0.771041</td>\n",
       "      <td>3583.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>3574</td>\n",
       "      <td>244</td>\n",
       "      <td>426</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>9</td>\n",
       "      <td>0.934080</td>\n",
       "      <td>0.985542</td>\n",
       "      <td>0.998329</td>\n",
       "      <td>0.617825</td>\n",
       "      <td>0.965137</td>\n",
       "      <td>0.759517</td>\n",
       "      <td>3591.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>3585</td>\n",
       "      <td>253</td>\n",
       "      <td>409</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.940073</td>\n",
       "      <td>0.992771</td>\n",
       "      <td>0.999169</td>\n",
       "      <td>0.641745</td>\n",
       "      <td>0.968721</td>\n",
       "      <td>0.779565</td>\n",
       "      <td>3611.0</td>\n",
       "      <td>642.0</td>\n",
       "      <td>3608</td>\n",
       "      <td>230</td>\n",
       "      <td>412</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>1</td>\n",
       "      <td>0.983700</td>\n",
       "      <td>0.731836</td>\n",
       "      <td>0.944277</td>\n",
       "      <td>0.906710</td>\n",
       "      <td>0.963585</td>\n",
       "      <td>0.809942</td>\n",
       "      <td>3643.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>3440</td>\n",
       "      <td>57</td>\n",
       "      <td>554</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>2</td>\n",
       "      <td>0.983471</td>\n",
       "      <td>0.757047</td>\n",
       "      <td>0.950165</td>\n",
       "      <td>0.906752</td>\n",
       "      <td>0.966531</td>\n",
       "      <td>0.825165</td>\n",
       "      <td>3632.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>3451</td>\n",
       "      <td>58</td>\n",
       "      <td>564</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>3</td>\n",
       "      <td>0.980493</td>\n",
       "      <td>0.744792</td>\n",
       "      <td>0.945766</td>\n",
       "      <td>0.893750</td>\n",
       "      <td>0.962817</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>3614.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3418</td>\n",
       "      <td>68</td>\n",
       "      <td>572</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>4</td>\n",
       "      <td>0.981338</td>\n",
       "      <td>0.750973</td>\n",
       "      <td>0.946814</td>\n",
       "      <td>0.899068</td>\n",
       "      <td>0.963767</td>\n",
       "      <td>0.818375</td>\n",
       "      <td>3610.0</td>\n",
       "      <td>644.0</td>\n",
       "      <td>3418</td>\n",
       "      <td>65</td>\n",
       "      <td>579</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>5</td>\n",
       "      <td>0.984664</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.941877</td>\n",
       "      <td>0.917317</td>\n",
       "      <td>0.962795</td>\n",
       "      <td>0.817234</td>\n",
       "      <td>3613.0</td>\n",
       "      <td>641.0</td>\n",
       "      <td>3403</td>\n",
       "      <td>53</td>\n",
       "      <td>588</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>6</td>\n",
       "      <td>0.979879</td>\n",
       "      <td>0.736434</td>\n",
       "      <td>0.943537</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.961365</td>\n",
       "      <td>0.806223</td>\n",
       "      <td>3613.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3409</td>\n",
       "      <td>70</td>\n",
       "      <td>570</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>7</td>\n",
       "      <td>0.980892</td>\n",
       "      <td>0.743429</td>\n",
       "      <td>0.942945</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.961544</td>\n",
       "      <td>0.814256</td>\n",
       "      <td>3593.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3388</td>\n",
       "      <td>66</td>\n",
       "      <td>594</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>8</td>\n",
       "      <td>0.980284</td>\n",
       "      <td>0.748756</td>\n",
       "      <td>0.943623</td>\n",
       "      <td>0.898507</td>\n",
       "      <td>0.961604</td>\n",
       "      <td>0.816825</td>\n",
       "      <td>3583.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>3381</td>\n",
       "      <td>68</td>\n",
       "      <td>602</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>9</td>\n",
       "      <td>0.980398</td>\n",
       "      <td>0.757653</td>\n",
       "      <td>0.947090</td>\n",
       "      <td>0.897281</td>\n",
       "      <td>0.963456</td>\n",
       "      <td>0.821577</td>\n",
       "      <td>3591.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>3401</td>\n",
       "      <td>68</td>\n",
       "      <td>594</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>10</td>\n",
       "      <td>0.982684</td>\n",
       "      <td>0.738579</td>\n",
       "      <td>0.942952</td>\n",
       "      <td>0.906542</td>\n",
       "      <td>0.962408</td>\n",
       "      <td>0.813986</td>\n",
       "      <td>3611.0</td>\n",
       "      <td>642.0</td>\n",
       "      <td>3405</td>\n",
       "      <td>60</td>\n",
       "      <td>582</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>1</td>\n",
       "      <td>0.988979</td>\n",
       "      <td>0.710918</td>\n",
       "      <td>0.936042</td>\n",
       "      <td>0.937807</td>\n",
       "      <td>0.961783</td>\n",
       "      <td>0.808751</td>\n",
       "      <td>3643.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>3410</td>\n",
       "      <td>38</td>\n",
       "      <td>573</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>2</td>\n",
       "      <td>0.988950</td>\n",
       "      <td>0.716564</td>\n",
       "      <td>0.936399</td>\n",
       "      <td>0.938907</td>\n",
       "      <td>0.961957</td>\n",
       "      <td>0.812804</td>\n",
       "      <td>3632.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>3401</td>\n",
       "      <td>38</td>\n",
       "      <td>584</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>3</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.733831</td>\n",
       "      <td>0.940786</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>0.962627</td>\n",
       "      <td>0.817175</td>\n",
       "      <td>3614.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3400</td>\n",
       "      <td>50</td>\n",
       "      <td>590</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>4</td>\n",
       "      <td>0.990067</td>\n",
       "      <td>0.734055</td>\n",
       "      <td>0.938781</td>\n",
       "      <td>0.947205</td>\n",
       "      <td>0.963742</td>\n",
       "      <td>0.827119</td>\n",
       "      <td>3610.0</td>\n",
       "      <td>644.0</td>\n",
       "      <td>3389</td>\n",
       "      <td>34</td>\n",
       "      <td>610</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>5</td>\n",
       "      <td>0.989384</td>\n",
       "      <td>0.701043</td>\n",
       "      <td>0.928591</td>\n",
       "      <td>0.943838</td>\n",
       "      <td>0.958024</td>\n",
       "      <td>0.804521</td>\n",
       "      <td>3613.0</td>\n",
       "      <td>641.0</td>\n",
       "      <td>3355</td>\n",
       "      <td>36</td>\n",
       "      <td>605</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>6</td>\n",
       "      <td>0.991246</td>\n",
       "      <td>0.738499</td>\n",
       "      <td>0.940216</td>\n",
       "      <td>0.953125</td>\n",
       "      <td>0.965057</td>\n",
       "      <td>0.832196</td>\n",
       "      <td>3613.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3397</td>\n",
       "      <td>30</td>\n",
       "      <td>610</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>7</td>\n",
       "      <td>0.990320</td>\n",
       "      <td>0.742891</td>\n",
       "      <td>0.939605</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.964296</td>\n",
       "      <td>0.833777</td>\n",
       "      <td>3593.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3376</td>\n",
       "      <td>33</td>\n",
       "      <td>627</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>8</td>\n",
       "      <td>0.988239</td>\n",
       "      <td>0.739437</td>\n",
       "      <td>0.938041</td>\n",
       "      <td>0.940299</td>\n",
       "      <td>0.962486</td>\n",
       "      <td>0.827858</td>\n",
       "      <td>3583.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>3361</td>\n",
       "      <td>40</td>\n",
       "      <td>630</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>9</td>\n",
       "      <td>0.984947</td>\n",
       "      <td>0.706358</td>\n",
       "      <td>0.929268</td>\n",
       "      <td>0.922961</td>\n",
       "      <td>0.956297</td>\n",
       "      <td>0.800262</td>\n",
       "      <td>3591.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>3337</td>\n",
       "      <td>51</td>\n",
       "      <td>611</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>10</td>\n",
       "      <td>0.987622</td>\n",
       "      <td>0.697674</td>\n",
       "      <td>0.927998</td>\n",
       "      <td>0.934579</td>\n",
       "      <td>0.956882</td>\n",
       "      <td>0.798935</td>\n",
       "      <td>3611.0</td>\n",
       "      <td>642.0</td>\n",
       "      <td>3351</td>\n",
       "      <td>42</td>\n",
       "      <td>600</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>1</td>\n",
       "      <td>0.988947</td>\n",
       "      <td>0.702206</td>\n",
       "      <td>0.933297</td>\n",
       "      <td>0.937807</td>\n",
       "      <td>0.960316</td>\n",
       "      <td>0.803083</td>\n",
       "      <td>3643.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>3400</td>\n",
       "      <td>38</td>\n",
       "      <td>573</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>2</td>\n",
       "      <td>0.987823</td>\n",
       "      <td>0.720497</td>\n",
       "      <td>0.938051</td>\n",
       "      <td>0.932476</td>\n",
       "      <td>0.962293</td>\n",
       "      <td>0.812894</td>\n",
       "      <td>3632.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>3407</td>\n",
       "      <td>42</td>\n",
       "      <td>580</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>3</td>\n",
       "      <td>0.986281</td>\n",
       "      <td>0.716184</td>\n",
       "      <td>0.934975</td>\n",
       "      <td>0.926562</td>\n",
       "      <td>0.959943</td>\n",
       "      <td>0.807902</td>\n",
       "      <td>3614.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3379</td>\n",
       "      <td>47</td>\n",
       "      <td>593</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>4</td>\n",
       "      <td>0.987709</td>\n",
       "      <td>0.719235</td>\n",
       "      <td>0.934903</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.960581</td>\n",
       "      <td>0.812964</td>\n",
       "      <td>3610.0</td>\n",
       "      <td>644.0</td>\n",
       "      <td>3375</td>\n",
       "      <td>42</td>\n",
       "      <td>602</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>5</td>\n",
       "      <td>0.990311</td>\n",
       "      <td>0.716981</td>\n",
       "      <td>0.933573</td>\n",
       "      <td>0.948518</td>\n",
       "      <td>0.961106</td>\n",
       "      <td>0.816655</td>\n",
       "      <td>3613.0</td>\n",
       "      <td>641.0</td>\n",
       "      <td>3373</td>\n",
       "      <td>33</td>\n",
       "      <td>608</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>6</td>\n",
       "      <td>0.988590</td>\n",
       "      <td>0.719760</td>\n",
       "      <td>0.935234</td>\n",
       "      <td>0.939063</td>\n",
       "      <td>0.961172</td>\n",
       "      <td>0.814915</td>\n",
       "      <td>3613.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3379</td>\n",
       "      <td>39</td>\n",
       "      <td>601</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>7</td>\n",
       "      <td>0.990280</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.935708</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.962221</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>3593.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3362</td>\n",
       "      <td>33</td>\n",
       "      <td>627</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>8</td>\n",
       "      <td>0.987338</td>\n",
       "      <td>0.731622</td>\n",
       "      <td>0.935808</td>\n",
       "      <td>0.935821</td>\n",
       "      <td>0.960883</td>\n",
       "      <td>0.821218</td>\n",
       "      <td>3583.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>3353</td>\n",
       "      <td>43</td>\n",
       "      <td>627</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>9</td>\n",
       "      <td>0.985277</td>\n",
       "      <td>0.714119</td>\n",
       "      <td>0.931774</td>\n",
       "      <td>0.924471</td>\n",
       "      <td>0.957779</td>\n",
       "      <td>0.805793</td>\n",
       "      <td>3591.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>3346</td>\n",
       "      <td>50</td>\n",
       "      <td>612</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>10</td>\n",
       "      <td>0.987973</td>\n",
       "      <td>0.712085</td>\n",
       "      <td>0.932706</td>\n",
       "      <td>0.936137</td>\n",
       "      <td>0.959544</td>\n",
       "      <td>0.808883</td>\n",
       "      <td>3611.0</td>\n",
       "      <td>642.0</td>\n",
       "      <td>3368</td>\n",
       "      <td>41</td>\n",
       "      <td>601</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>SMOTEENN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.990924</td>\n",
       "      <td>0.657492</td>\n",
       "      <td>0.916996</td>\n",
       "      <td>0.949926</td>\n",
       "      <td>0.952528</td>\n",
       "      <td>0.777108</td>\n",
       "      <td>4048.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>3712</td>\n",
       "      <td>34</td>\n",
       "      <td>645</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>SMOTEENN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.988606</td>\n",
       "      <td>0.643269</td>\n",
       "      <td>0.907597</td>\n",
       "      <td>0.940928</td>\n",
       "      <td>0.946371</td>\n",
       "      <td>0.764135</td>\n",
       "      <td>4015.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>3644</td>\n",
       "      <td>42</td>\n",
       "      <td>669</td>\n",
       "      <td>371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>SMOTEENN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.987952</td>\n",
       "      <td>0.669021</td>\n",
       "      <td>0.918367</td>\n",
       "      <td>0.936441</td>\n",
       "      <td>0.951890</td>\n",
       "      <td>0.780459</td>\n",
       "      <td>4018.0</td>\n",
       "      <td>708.0</td>\n",
       "      <td>3690</td>\n",
       "      <td>45</td>\n",
       "      <td>663</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>SMOTEENN</td>\n",
       "      <td>4</td>\n",
       "      <td>0.988649</td>\n",
       "      <td>0.648148</td>\n",
       "      <td>0.910177</td>\n",
       "      <td>0.940594</td>\n",
       "      <td>0.947791</td>\n",
       "      <td>0.767455</td>\n",
       "      <td>4019.0</td>\n",
       "      <td>707.0</td>\n",
       "      <td>3658</td>\n",
       "      <td>42</td>\n",
       "      <td>665</td>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>SMOTEENN</td>\n",
       "      <td>5</td>\n",
       "      <td>0.989189</td>\n",
       "      <td>0.641326</td>\n",
       "      <td>0.908640</td>\n",
       "      <td>0.942693</td>\n",
       "      <td>0.947205</td>\n",
       "      <td>0.763341</td>\n",
       "      <td>4028.0</td>\n",
       "      <td>698.0</td>\n",
       "      <td>3660</td>\n",
       "      <td>40</td>\n",
       "      <td>658</td>\n",
       "      <td>368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>SMOTEENN</td>\n",
       "      <td>6</td>\n",
       "      <td>0.991819</td>\n",
       "      <td>0.649669</td>\n",
       "      <td>0.907435</td>\n",
       "      <td>0.958217</td>\n",
       "      <td>0.947752</td>\n",
       "      <td>0.774339</td>\n",
       "      <td>4008.0</td>\n",
       "      <td>718.0</td>\n",
       "      <td>3637</td>\n",
       "      <td>30</td>\n",
       "      <td>688</td>\n",
       "      <td>371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>SMOTEENN</td>\n",
       "      <td>7</td>\n",
       "      <td>0.985578</td>\n",
       "      <td>0.674596</td>\n",
       "      <td>0.913724</td>\n",
       "      <td>0.930446</td>\n",
       "      <td>0.948292</td>\n",
       "      <td>0.782129</td>\n",
       "      <td>3964.0</td>\n",
       "      <td>762.0</td>\n",
       "      <td>3622</td>\n",
       "      <td>53</td>\n",
       "      <td>709</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>SMOTEENN</td>\n",
       "      <td>8</td>\n",
       "      <td>0.986216</td>\n",
       "      <td>0.658869</td>\n",
       "      <td>0.912478</td>\n",
       "      <td>0.929849</td>\n",
       "      <td>0.947915</td>\n",
       "      <td>0.771249</td>\n",
       "      <td>3999.0</td>\n",
       "      <td>727.0</td>\n",
       "      <td>3649</td>\n",
       "      <td>51</td>\n",
       "      <td>676</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>SMOTEENN</td>\n",
       "      <td>9</td>\n",
       "      <td>0.989674</td>\n",
       "      <td>0.653920</td>\n",
       "      <td>0.909590</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947944</td>\n",
       "      <td>0.773756</td>\n",
       "      <td>4004.0</td>\n",
       "      <td>722.0</td>\n",
       "      <td>3642</td>\n",
       "      <td>38</td>\n",
       "      <td>684</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>SMOTETomek</td>\n",
       "      <td>1</td>\n",
       "      <td>0.984086</td>\n",
       "      <td>0.742479</td>\n",
       "      <td>0.947134</td>\n",
       "      <td>0.908689</td>\n",
       "      <td>0.965257</td>\n",
       "      <td>0.817219</td>\n",
       "      <td>4048.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>3834</td>\n",
       "      <td>62</td>\n",
       "      <td>617</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>SMOTETomek</td>\n",
       "      <td>2</td>\n",
       "      <td>0.982411</td>\n",
       "      <td>0.747674</td>\n",
       "      <td>0.945953</td>\n",
       "      <td>0.904360</td>\n",
       "      <td>0.963837</td>\n",
       "      <td>0.818587</td>\n",
       "      <td>4015.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>3798</td>\n",
       "      <td>68</td>\n",
       "      <td>643</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>SMOTETomek</td>\n",
       "      <td>3</td>\n",
       "      <td>0.981195</td>\n",
       "      <td>0.752370</td>\n",
       "      <td>0.947984</td>\n",
       "      <td>0.896893</td>\n",
       "      <td>0.964304</td>\n",
       "      <td>0.818299</td>\n",
       "      <td>4018.0</td>\n",
       "      <td>708.0</td>\n",
       "      <td>3809</td>\n",
       "      <td>73</td>\n",
       "      <td>635</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>SMOTETomek</td>\n",
       "      <td>4</td>\n",
       "      <td>0.980165</td>\n",
       "      <td>0.746445</td>\n",
       "      <td>0.946753</td>\n",
       "      <td>0.891089</td>\n",
       "      <td>0.963169</td>\n",
       "      <td>0.812379</td>\n",
       "      <td>4019.0</td>\n",
       "      <td>707.0</td>\n",
       "      <td>3805</td>\n",
       "      <td>77</td>\n",
       "      <td>630</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>SMOTETomek</td>\n",
       "      <td>5</td>\n",
       "      <td>0.982620</td>\n",
       "      <td>0.724455</td>\n",
       "      <td>0.940417</td>\n",
       "      <td>0.904011</td>\n",
       "      <td>0.961055</td>\n",
       "      <td>0.804334</td>\n",
       "      <td>4028.0</td>\n",
       "      <td>698.0</td>\n",
       "      <td>3788</td>\n",
       "      <td>67</td>\n",
       "      <td>631</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>SMOTETomek</td>\n",
       "      <td>6</td>\n",
       "      <td>0.984915</td>\n",
       "      <td>0.749149</td>\n",
       "      <td>0.944860</td>\n",
       "      <td>0.919220</td>\n",
       "      <td>0.964472</td>\n",
       "      <td>0.825516</td>\n",
       "      <td>4008.0</td>\n",
       "      <td>718.0</td>\n",
       "      <td>3787</td>\n",
       "      <td>58</td>\n",
       "      <td>660</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>SMOTETomek</td>\n",
       "      <td>7</td>\n",
       "      <td>0.977237</td>\n",
       "      <td>0.746681</td>\n",
       "      <td>0.942230</td>\n",
       "      <td>0.885827</td>\n",
       "      <td>0.959414</td>\n",
       "      <td>0.810324</td>\n",
       "      <td>3964.0</td>\n",
       "      <td>762.0</td>\n",
       "      <td>3735</td>\n",
       "      <td>87</td>\n",
       "      <td>675</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>SMOTETomek</td>\n",
       "      <td>8</td>\n",
       "      <td>0.980555</td>\n",
       "      <td>0.750288</td>\n",
       "      <td>0.945736</td>\n",
       "      <td>0.896836</td>\n",
       "      <td>0.962831</td>\n",
       "      <td>0.817043</td>\n",
       "      <td>3999.0</td>\n",
       "      <td>727.0</td>\n",
       "      <td>3782</td>\n",
       "      <td>75</td>\n",
       "      <td>652</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>DF5</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>SMOTETomek</td>\n",
       "      <td>9</td>\n",
       "      <td>0.983112</td>\n",
       "      <td>0.749145</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.909972</td>\n",
       "      <td>0.963708</td>\n",
       "      <td>0.821764</td>\n",
       "      <td>4004.0</td>\n",
       "      <td>722.0</td>\n",
       "      <td>3784</td>\n",
       "      <td>65</td>\n",
       "      <td>657</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset              model data balancing technique  fold  precision_1  \\\n",
       "0      DF5  Linear Regression                     None     1     0.940766   \n",
       "1      DF5  Linear Regression                     None     2     0.936774   \n",
       "2      DF5  Linear Regression                     None     3     0.930412   \n",
       "3      DF5  Linear Regression                     None     4     0.935651   \n",
       "4      DF5  Linear Regression                     None     5     0.945946   \n",
       "5      DF5  Linear Regression                     None     6     0.938929   \n",
       "6      DF5  Linear Regression                     None     7     0.936570   \n",
       "7      DF5  Linear Regression                     None     8     0.936092   \n",
       "8      DF5  Linear Regression                     None     9     0.934080   \n",
       "9      DF5  Linear Regression                     None    10     0.940073   \n",
       "10     DF5  Linear Regression                    SMOTE     1     0.983700   \n",
       "11     DF5  Linear Regression                    SMOTE     2     0.983471   \n",
       "12     DF5  Linear Regression                    SMOTE     3     0.980493   \n",
       "13     DF5  Linear Regression                    SMOTE     4     0.981338   \n",
       "14     DF5  Linear Regression                    SMOTE     5     0.984664   \n",
       "15     DF5  Linear Regression                    SMOTE     6     0.979879   \n",
       "16     DF5  Linear Regression                    SMOTE     7     0.980892   \n",
       "17     DF5  Linear Regression                    SMOTE     8     0.980284   \n",
       "18     DF5  Linear Regression                    SMOTE     9     0.980398   \n",
       "19     DF5  Linear Regression                    SMOTE    10     0.982684   \n",
       "20     DF5  Linear Regression     Random Under Sampler     1     0.988979   \n",
       "21     DF5  Linear Regression     Random Under Sampler     2     0.988950   \n",
       "22     DF5  Linear Regression     Random Under Sampler     3     0.985507   \n",
       "23     DF5  Linear Regression     Random Under Sampler     4     0.990067   \n",
       "24     DF5  Linear Regression     Random Under Sampler     5     0.989384   \n",
       "25     DF5  Linear Regression     Random Under Sampler     6     0.991246   \n",
       "26     DF5  Linear Regression     Random Under Sampler     7     0.990320   \n",
       "27     DF5  Linear Regression     Random Under Sampler     8     0.988239   \n",
       "28     DF5  Linear Regression     Random Under Sampler     9     0.984947   \n",
       "29     DF5  Linear Regression     Random Under Sampler    10     0.987622   \n",
       "30     DF5  Linear Regression      Random Over Sampler     1     0.988947   \n",
       "31     DF5  Linear Regression      Random Over Sampler     2     0.987823   \n",
       "32     DF5  Linear Regression      Random Over Sampler     3     0.986281   \n",
       "33     DF5  Linear Regression      Random Over Sampler     4     0.987709   \n",
       "34     DF5  Linear Regression      Random Over Sampler     5     0.990311   \n",
       "35     DF5  Linear Regression      Random Over Sampler     6     0.988590   \n",
       "36     DF5  Linear Regression      Random Over Sampler     7     0.990280   \n",
       "37     DF5  Linear Regression      Random Over Sampler     8     0.987338   \n",
       "38     DF5  Linear Regression      Random Over Sampler     9     0.985277   \n",
       "39     DF5  Linear Regression      Random Over Sampler    10     0.987973   \n",
       "40     DF5  Linear Regression                 SMOTEENN     1     0.990924   \n",
       "41     DF5  Linear Regression                 SMOTEENN     2     0.988606   \n",
       "42     DF5  Linear Regression                 SMOTEENN     3     0.987952   \n",
       "43     DF5  Linear Regression                 SMOTEENN     4     0.988649   \n",
       "44     DF5  Linear Regression                 SMOTEENN     5     0.989189   \n",
       "45     DF5  Linear Regression                 SMOTEENN     6     0.991819   \n",
       "46     DF5  Linear Regression                 SMOTEENN     7     0.985578   \n",
       "47     DF5  Linear Regression                 SMOTEENN     8     0.986216   \n",
       "48     DF5  Linear Regression                 SMOTEENN     9     0.989674   \n",
       "49     DF5  Linear Regression               SMOTETomek     1     0.984086   \n",
       "50     DF5  Linear Regression               SMOTETomek     2     0.982411   \n",
       "51     DF5  Linear Regression               SMOTETomek     3     0.981195   \n",
       "52     DF5  Linear Regression               SMOTETomek     4     0.980165   \n",
       "53     DF5  Linear Regression               SMOTETomek     5     0.982620   \n",
       "54     DF5  Linear Regression               SMOTETomek     6     0.984915   \n",
       "55     DF5  Linear Regression               SMOTETomek     7     0.977237   \n",
       "56     DF5  Linear Regression               SMOTETomek     8     0.980555   \n",
       "57     DF5  Linear Regression               SMOTETomek     9     0.983112   \n",
       "\n",
       "    precision_2  recall_1  recall_2  f1-score_1  f1-score_2  support_1  \\\n",
       "0      0.984536  0.998353  0.625205    0.968704    0.764765     3643.0   \n",
       "1      0.994723  0.999449  0.606109    0.967097    0.753247     3632.0   \n",
       "2      0.989305  0.998893  0.578125    0.963437    0.729783     3614.0   \n",
       "3      0.990000  0.998892  0.614907    0.966238    0.758621     3610.0   \n",
       "4      0.981941  0.997786  0.678627    0.971175    0.802583     3613.0   \n",
       "5      1.000000  1.000000  0.632812    0.968503    0.775120     3613.0   \n",
       "6      0.988152  0.998608  0.631818    0.966595    0.770795     3593.0   \n",
       "7      0.979310  0.997488  0.635821    0.965815    0.771041     3583.0   \n",
       "8      0.985542  0.998329  0.617825    0.965137    0.759517     3591.0   \n",
       "9      0.992771  0.999169  0.641745    0.968721    0.779565     3611.0   \n",
       "10     0.731836  0.944277  0.906710    0.963585    0.809942     3643.0   \n",
       "11     0.757047  0.950165  0.906752    0.966531    0.825165     3632.0   \n",
       "12     0.744792  0.945766  0.893750    0.962817    0.812500     3614.0   \n",
       "13     0.750973  0.946814  0.899068    0.963767    0.818375     3610.0   \n",
       "14     0.736842  0.941877  0.917317    0.962795    0.817234     3613.0   \n",
       "15     0.736434  0.943537  0.890625    0.961365    0.806223     3613.0   \n",
       "16     0.743429  0.942945  0.900000    0.961544    0.814256     3593.0   \n",
       "17     0.748756  0.943623  0.898507    0.961604    0.816825     3583.0   \n",
       "18     0.757653  0.947090  0.897281    0.963456    0.821577     3591.0   \n",
       "19     0.738579  0.942952  0.906542    0.962408    0.813986     3611.0   \n",
       "20     0.710918  0.936042  0.937807    0.961783    0.808751     3643.0   \n",
       "21     0.716564  0.936399  0.938907    0.961957    0.812804     3632.0   \n",
       "22     0.733831  0.940786  0.921875    0.962627    0.817175     3614.0   \n",
       "23     0.734055  0.938781  0.947205    0.963742    0.827119     3610.0   \n",
       "24     0.701043  0.928591  0.943838    0.958024    0.804521     3613.0   \n",
       "25     0.738499  0.940216  0.953125    0.965057    0.832196     3613.0   \n",
       "26     0.742891  0.939605  0.950000    0.964296    0.833777     3593.0   \n",
       "27     0.739437  0.938041  0.940299    0.962486    0.827858     3583.0   \n",
       "28     0.706358  0.929268  0.922961    0.956297    0.800262     3591.0   \n",
       "29     0.697674  0.927998  0.934579    0.956882    0.798935     3611.0   \n",
       "30     0.702206  0.933297  0.937807    0.960316    0.803083     3643.0   \n",
       "31     0.720497  0.938051  0.932476    0.962293    0.812894     3632.0   \n",
       "32     0.716184  0.934975  0.926562    0.959943    0.807902     3614.0   \n",
       "33     0.719235  0.934903  0.934783    0.960581    0.812964     3610.0   \n",
       "34     0.716981  0.933573  0.948518    0.961106    0.816655     3613.0   \n",
       "35     0.719760  0.935234  0.939063    0.961172    0.814915     3613.0   \n",
       "36     0.730769  0.935708  0.950000    0.962221    0.826087     3593.0   \n",
       "37     0.731622  0.935808  0.935821    0.960883    0.821218     3583.0   \n",
       "38     0.714119  0.931774  0.924471    0.957779    0.805793     3591.0   \n",
       "39     0.712085  0.932706  0.936137    0.959544    0.808883     3611.0   \n",
       "40     0.657492  0.916996  0.949926    0.952528    0.777108     4048.0   \n",
       "41     0.643269  0.907597  0.940928    0.946371    0.764135     4015.0   \n",
       "42     0.669021  0.918367  0.936441    0.951890    0.780459     4018.0   \n",
       "43     0.648148  0.910177  0.940594    0.947791    0.767455     4019.0   \n",
       "44     0.641326  0.908640  0.942693    0.947205    0.763341     4028.0   \n",
       "45     0.649669  0.907435  0.958217    0.947752    0.774339     4008.0   \n",
       "46     0.674596  0.913724  0.930446    0.948292    0.782129     3964.0   \n",
       "47     0.658869  0.912478  0.929849    0.947915    0.771249     3999.0   \n",
       "48     0.653920  0.909590  0.947368    0.947944    0.773756     4004.0   \n",
       "49     0.742479  0.947134  0.908689    0.965257    0.817219     4048.0   \n",
       "50     0.747674  0.945953  0.904360    0.963837    0.818587     4015.0   \n",
       "51     0.752370  0.947984  0.896893    0.964304    0.818299     4018.0   \n",
       "52     0.746445  0.946753  0.891089    0.963169    0.812379     4019.0   \n",
       "53     0.724455  0.940417  0.904011    0.961055    0.804334     4028.0   \n",
       "54     0.749149  0.944860  0.919220    0.964472    0.825516     4008.0   \n",
       "55     0.746681  0.942230  0.885827    0.959414    0.810324     3964.0   \n",
       "56     0.750288  0.945736  0.896836    0.962831    0.817043     3999.0   \n",
       "57     0.749145  0.945055  0.909972    0.963708    0.821764     4004.0   \n",
       "\n",
       "    support_2    TP   FP   TN   FN  \n",
       "0       611.0  3637  229  382    6  \n",
       "1       622.0  3630  245  377    2  \n",
       "2       640.0  3610  270  370    4  \n",
       "3       644.0  3606  248  396    4  \n",
       "4       641.0  3605  206  435    8  \n",
       "5       640.0  3613  235  405    0  \n",
       "6       660.0  3588  243  417    5  \n",
       "7       670.0  3574  244  426    9  \n",
       "8       662.0  3585  253  409    6  \n",
       "9       642.0  3608  230  412    3  \n",
       "10      611.0  3440   57  554  203  \n",
       "11      622.0  3451   58  564  181  \n",
       "12      640.0  3418   68  572  196  \n",
       "13      644.0  3418   65  579  192  \n",
       "14      641.0  3403   53  588  210  \n",
       "15      640.0  3409   70  570  204  \n",
       "16      660.0  3388   66  594  205  \n",
       "17      670.0  3381   68  602  202  \n",
       "18      662.0  3401   68  594  190  \n",
       "19      642.0  3405   60  582  206  \n",
       "20      611.0  3410   38  573  233  \n",
       "21      622.0  3401   38  584  231  \n",
       "22      640.0  3400   50  590  214  \n",
       "23      644.0  3389   34  610  221  \n",
       "24      641.0  3355   36  605  258  \n",
       "25      640.0  3397   30  610  216  \n",
       "26      660.0  3376   33  627  217  \n",
       "27      670.0  3361   40  630  222  \n",
       "28      662.0  3337   51  611  254  \n",
       "29      642.0  3351   42  600  260  \n",
       "30      611.0  3400   38  573  243  \n",
       "31      622.0  3407   42  580  225  \n",
       "32      640.0  3379   47  593  235  \n",
       "33      644.0  3375   42  602  235  \n",
       "34      641.0  3373   33  608  240  \n",
       "35      640.0  3379   39  601  234  \n",
       "36      660.0  3362   33  627  231  \n",
       "37      670.0  3353   43  627  230  \n",
       "38      662.0  3346   50  612  245  \n",
       "39      642.0  3368   41  601  243  \n",
       "40      679.0  3712   34  645  336  \n",
       "41      711.0  3644   42  669  371  \n",
       "42      708.0  3690   45  663  328  \n",
       "43      707.0  3658   42  665  361  \n",
       "44      698.0  3660   40  658  368  \n",
       "45      718.0  3637   30  688  371  \n",
       "46      762.0  3622   53  709  342  \n",
       "47      727.0  3649   51  676  350  \n",
       "48      722.0  3642   38  684  362  \n",
       "49      679.0  3834   62  617  214  \n",
       "50      711.0  3798   68  643  217  \n",
       "51      708.0  3809   73  635  209  \n",
       "52      707.0  3805   77  630  214  \n",
       "53      698.0  3788   67  631  240  \n",
       "54      718.0  3787   58  660  221  \n",
       "55      762.0  3735   87  675  229  \n",
       "56      727.0  3782   75  652  217  \n",
       "57      722.0  3784   65  657  220  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8905e922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame\n",
    "combined_metrics.to_csv('Output Data/LinearRegression.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18364cc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
