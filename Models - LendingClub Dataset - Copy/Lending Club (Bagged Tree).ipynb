{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d2c91a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f460afa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "import numpy as np\n",
    "from pprint import pprint as pp\n",
    "import csv\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "from itertools import product\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from imblearn.pipeline import Pipeline \n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import r2_score, classification_report, confusion_matrix, accuracy_score, roc_auc_score, roc_curve, precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import homogeneity_score, silhouette_score\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import MiniBatchKMeans, DBSCAN\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17e9cee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, precision_score, recall_score, f1_score, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6238cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, precision_score, recall_score, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75e8fc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.combine import SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5eb141e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "378df2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0db62d0",
   "metadata": {},
   "source": [
    "### Retrieving the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10513ea6",
   "metadata": {},
   "source": [
    "#### DF 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc3d2069",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = pd.read_csv('df5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82ed7cb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>emp_title</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>issue_d</th>\n",
       "      <th>pymnt_plan</th>\n",
       "      <th>purpose</th>\n",
       "      <th>title</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>addr_state</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>earliest_cr_line</th>\n",
       "      <th>fico_range_low</th>\n",
       "      <th>fico_range_high</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>mths_since_last_delinq</th>\n",
       "      <th>mths_since_last_record</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>revol_bal</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>total_acc</th>\n",
       "      <th>out_prncp</th>\n",
       "      <th>out_prncp_inv</th>\n",
       "      <th>total_pymnt</th>\n",
       "      <th>total_pymnt_inv</th>\n",
       "      <th>total_rec_prncp</th>\n",
       "      <th>total_rec_int</th>\n",
       "      <th>total_rec_late_fee</th>\n",
       "      <th>recoveries</th>\n",
       "      <th>collection_recovery_fee</th>\n",
       "      <th>last_pymnt_d</th>\n",
       "      <th>last_pymnt_amnt</th>\n",
       "      <th>next_pymnt_d</th>\n",
       "      <th>last_credit_pull_d</th>\n",
       "      <th>last_fico_range_high</th>\n",
       "      <th>last_fico_range_low</th>\n",
       "      <th>collections_12_mths_ex_med</th>\n",
       "      <th>acc_now_delinq</th>\n",
       "      <th>chargeoff_within_12_mths</th>\n",
       "      <th>delinq_amnt</th>\n",
       "      <th>pub_rec_bankruptcies</th>\n",
       "      <th>tax_liens</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1077501.0</td>\n",
       "      <td>1296599.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>4975.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1065</td>\n",
       "      <td>162.87</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>25275</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3160</td>\n",
       "      <td>860</td>\n",
       "      <td>3</td>\n",
       "      <td>27.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>735.0</td>\n",
       "      <td>739.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13648.0</td>\n",
       "      <td>0.837</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5863.155187</td>\n",
       "      <td>5833.84</td>\n",
       "      <td>5000.00</td>\n",
       "      <td>863.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>171.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>744.0</td>\n",
       "      <td>740.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1077430.0</td>\n",
       "      <td>1314167.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1527</td>\n",
       "      <td>59.83</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>20173</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17558</td>\n",
       "      <td>309</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>740.0</td>\n",
       "      <td>744.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1687.0</td>\n",
       "      <td>0.094</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1008.710000</td>\n",
       "      <td>1008.71</td>\n",
       "      <td>456.46</td>\n",
       "      <td>435.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117.08</td>\n",
       "      <td>1.11</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>119.66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>499.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         id  member_id  loan_amnt  funded_amnt  funded_amnt_inv  \\\n",
       "0           0  1077501.0  1296599.0     5000.0       5000.0           4975.0   \n",
       "1           1  1077430.0  1314167.0     2500.0       2500.0           2500.0   \n",
       "\n",
       "   term  int_rate  installment  grade  sub_grade  emp_title  emp_length  \\\n",
       "0     0    0.1065       162.87      1          6      25275        10.0   \n",
       "1     1    0.1527        59.83      2         13      20173         1.0   \n",
       "\n",
       "   home_ownership  annual_inc  verification_status  issue_d  pymnt_plan  \\\n",
       "0               4     24000.0                    2   2011.0           0   \n",
       "1               4     30000.0                    1   2011.0           0   \n",
       "\n",
       "   purpose  title  zip_code  addr_state    dti  delinq_2yrs  earliest_cr_line  \\\n",
       "0        1   3160       860           3  27.65          0.0            1985.0   \n",
       "1        0  17558       309          10   1.00          0.0            1999.0   \n",
       "\n",
       "   fico_range_low  fico_range_high  inq_last_6mths  mths_since_last_delinq  \\\n",
       "0           735.0            739.0             1.0                   500.0   \n",
       "1           740.0            744.0             5.0                   500.0   \n",
       "\n",
       "   mths_since_last_record  open_acc  pub_rec  revol_bal  revol_util  \\\n",
       "0                   222.0       3.0      0.0    13648.0       0.837   \n",
       "1                   222.0       3.0      0.0     1687.0       0.094   \n",
       "\n",
       "   total_acc  out_prncp  out_prncp_inv  total_pymnt  total_pymnt_inv  \\\n",
       "0        9.0        0.0            0.0  5863.155187          5833.84   \n",
       "1        4.0        0.0            0.0  1008.710000          1008.71   \n",
       "\n",
       "   total_rec_prncp  total_rec_int  total_rec_late_fee  recoveries  \\\n",
       "0          5000.00         863.16                 0.0        0.00   \n",
       "1           456.46         435.17                 0.0      117.08   \n",
       "\n",
       "   collection_recovery_fee  last_pymnt_d  last_pymnt_amnt  next_pymnt_d  \\\n",
       "0                     0.00        2015.0           171.62           0.0   \n",
       "1                     1.11        2013.0           119.66           0.0   \n",
       "\n",
       "   last_credit_pull_d  last_fico_range_high  last_fico_range_low  \\\n",
       "0              2016.0                 744.0                740.0   \n",
       "1              2016.0                 499.0                  0.0   \n",
       "\n",
       "   collections_12_mths_ex_med  acc_now_delinq  chargeoff_within_12_mths  \\\n",
       "0                           0               0                         0   \n",
       "1                           0               0                         0   \n",
       "\n",
       "   delinq_amnt  pub_rec_bankruptcies  tax_liens  target  \n",
       "0          0.0                   0.0          0       1  \n",
       "1          0.0                   0.0          0       2  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed385af",
   "metadata": {},
   "source": [
    "#### DF 5c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4218b67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df5c = pd.read_csv('df5c.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "026f4728",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df5c.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f9963f",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b0bea07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store evaluation metrics for each fold\n",
    "dataset_used = []\n",
    "model_used = []\n",
    "data_balancing_technique = []\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "conf_matrices = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e6d6d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combined_metrics = pd.DataFrame()\n",
    "\n",
    "combined_metrics = pd.DataFrame(columns=['dataset', 'model', 'data balancing technique', 'fold', 'precision_1','precision_2','recall_1','recall_2','f1-score_1','f1-score_2','support_1','support_2','TP','FP','TN','FN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052cda7c",
   "metadata": {},
   "source": [
    "# BaggedTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedf6e11",
   "metadata": {},
   "source": [
    "## DF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89f99b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.99\n",
      "Mean Precision: 0.99\n",
      "Mean Recall: 0.99\n",
      "Mean F1-Score: 0.99\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df5' is your DataFrame with features and the target column\n",
    "# Replace 'features' with the actual list of feature columns\n",
    "features = df5.drop(columns=['target'])  # Drop the target column to get the feature columns\n",
    "target = df5['target']  # Target column to predict\n",
    "\n",
    "# Initialize a Decision Tree classifier\n",
    "base_estimator = DecisionTreeClassifier()\n",
    "model = BaggingClassifier(base_estimator, n_estimators=10, random_state=42)\n",
    "\n",
    "# Initialize KFold with 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the testing set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    y_pred = np.round(y_pred)\n",
    "\n",
    "    y_pred[y_pred <= 0] = 1\n",
    "    y_pred[y_pred >= 2] = 2\n",
    "    \n",
    "    # Model evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    \n",
    "    # Convert classification report to DataFrame\n",
    "    report_df = pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).transpose()\n",
    "    # Convert confusion matrix to DataFrame\n",
    "    matrix_df = pd.DataFrame(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    # Extract metrics for class 1\n",
    "    metrics_1 = report_df.loc['1', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract metrics for class 2\n",
    "    metrics_2 = report_df.loc['2', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract TP, TN, FP, FN counts from the confusion matrix DataFrame\n",
    "    TP = matrix_df.loc[0, 0]\n",
    "    TN = matrix_df.loc[1, 1]\n",
    "    FP = matrix_df.loc[1, 0]\n",
    "    FN = matrix_df.loc[0, 1]\n",
    "    \n",
    "    new_metric_row = {\n",
    "    'dataset': 'DF5',\n",
    "    'model' : 'BaggedTreeClassifier',\n",
    "    'data balancing technique' : 'None',\n",
    "    'fold' : i,\n",
    "    'precision_1': metrics_1['precision'],\n",
    "    'precision_2': metrics_2['precision'],\n",
    "    'recall_1': metrics_1['recall'],\n",
    "    'recall_2': metrics_2['recall'],\n",
    "    'f1-score_1': metrics_1['f1-score'],\n",
    "    'f1-score_2': metrics_2['f1-score'],\n",
    "    'support_1': metrics_1['support'],\n",
    "    'support_2': metrics_2['support'],\n",
    "    'TP' : TP,\n",
    "    'FP' : FP,\n",
    "    'TN' : TN,\n",
    "    'FN' : FN\n",
    "    }\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    #combined_metrics = combined_metrics.append(new_metric_row, ignore_index=True)\n",
    "    combined_metrics.loc[len(combined_metrics)] = new_metric_row\n",
    "    \n",
    "    \n",
    "    # Append evaluation metrics to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "\n",
    "# Calculate mean evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores) #sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = np.mean(precision_scores) #sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = np.mean(recall_scores) #sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = np.mean(f1_scores) #sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print('Mean Accuracy: {:.2f}'.format(mean_accuracy))\n",
    "print('Mean Precision: {:.2f}'.format(mean_precision))\n",
    "print('Mean Recall: {:.2f}'.format(mean_recall))\n",
    "print('Mean F1-Score: {:.2f}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5cd58d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>data balancing technique</th>\n",
       "      <th>fold</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_2</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>f1-score_1</th>\n",
       "      <th>f1-score_2</th>\n",
       "      <th>support_1</th>\n",
       "      <th>support_2</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0.992366</td>\n",
       "      <td>0.994881</td>\n",
       "      <td>0.999177</td>\n",
       "      <td>0.954173</td>\n",
       "      <td>0.99576</td>\n",
       "      <td>0.974102</td>\n",
       "      <td>3643.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>3640</td>\n",
       "      <td>28</td>\n",
       "      <td>583</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>0.994250</td>\n",
       "      <td>0.998339</td>\n",
       "      <td>0.999725</td>\n",
       "      <td>0.966238</td>\n",
       "      <td>0.99698</td>\n",
       "      <td>0.982026</td>\n",
       "      <td>3632.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>3631</td>\n",
       "      <td>21</td>\n",
       "      <td>601</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset                 model data balancing technique  fold  precision_1  \\\n",
       "0     DF5  BaggedTreeClassifier                     None     1     0.992366   \n",
       "1     DF5  BaggedTreeClassifier                     None     2     0.994250   \n",
       "\n",
       "   precision_2  recall_1  recall_2  f1-score_1  f1-score_2  support_1  \\\n",
       "0     0.994881  0.999177  0.954173     0.99576    0.974102     3643.0   \n",
       "1     0.998339  0.999725  0.966238     0.99698    0.982026     3632.0   \n",
       "\n",
       "   support_2    TP  FP   TN  FN  \n",
       "0      611.0  3640  28  583   3  \n",
       "1      622.0  3631  21  601   1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_metrics[(combined_metrics['data balancing technique'] == 'None') & (combined_metrics['dataset'] == 'DF5')].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd45aea",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier with df5 data and imbalance data tackling (SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4eaaba2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.99\n",
      "Mean Precision: 0.99\n",
      "Mean Recall: 0.99\n",
      "Mean F1-Score: 0.99\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df5' is your DataFrame with features and the target column\n",
    "# Replace 'features' with the actual list of feature columns\n",
    "features = df5.drop(columns=['target'])  # Drop the target column to get the feature columns\n",
    "target = df5['target']  # Target column to predict\n",
    "\n",
    "# Initialize a Decision Tree classifier\n",
    "base_estimator = DecisionTreeClassifier()\n",
    "model = BaggingClassifier(base_estimator, n_estimators=10, random_state=42)\n",
    "\n",
    "# Initialize KFold with 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    # Apply SMOTE to the training data\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Predict on the testing set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    y_pred = np.round(y_pred)\n",
    "\n",
    "    y_pred[y_pred <= 0] = 1\n",
    "    y_pred[y_pred >= 2] = 2\n",
    "    \n",
    "    # Model evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Convert classification report to DataFrame\n",
    "    report_df = pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).transpose()\n",
    "    # Convert confusion matrix to DataFrame\n",
    "    matrix_df = pd.DataFrame(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    # Extract metrics for class 1\n",
    "    metrics_1 = report_df.loc['1', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract metrics for class 2\n",
    "    metrics_2 = report_df.loc['2', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract TP, TN, FP, FN counts from the confusion matrix DataFrame\n",
    "    TP = matrix_df.loc[0, 0]\n",
    "    TN = matrix_df.loc[1, 1]\n",
    "    FP = matrix_df.loc[1, 0]\n",
    "    FN = matrix_df.loc[0, 1]\n",
    "    \n",
    "    new_metric_row = {\n",
    "    'dataset': 'DF5',\n",
    "    'model' : 'BaggedTreeClassifier',\n",
    "    'data balancing technique' : 'SMOTE',\n",
    "    'fold' : i,\n",
    "    'precision_1': metrics_1['precision'],\n",
    "    'precision_2': metrics_2['precision'],\n",
    "    'recall_1': metrics_1['recall'],\n",
    "    'recall_2': metrics_2['recall'],\n",
    "    'f1-score_1': metrics_1['f1-score'],\n",
    "    'f1-score_2': metrics_2['f1-score'],\n",
    "    'support_1': metrics_1['support'],\n",
    "    'support_2': metrics_2['support'],\n",
    "    'TP' : TP,\n",
    "    'FP' : FP,\n",
    "    'TN' : TN,\n",
    "    'FN' : FN\n",
    "    }\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    #combined_metrics = combined_metrics.append(new_metric_row, ignore_index=True)\n",
    "    combined_metrics.loc[len(combined_metrics)] = new_metric_row\n",
    "    \n",
    "    \n",
    "    # Append evaluation metrics to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "\n",
    "# Calculate mean evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores) #sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = np.mean(precision_scores) #sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = np.mean(recall_scores) #sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = np.mean(f1_scores) #sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print('Mean Accuracy: {:.2f}'.format(mean_accuracy))\n",
    "print('Mean Precision: {:.2f}'.format(mean_precision))\n",
    "print('Mean Recall: {:.2f}'.format(mean_recall))\n",
    "print('Mean F1-Score: {:.2f}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "031ffc3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>data balancing technique</th>\n",
       "      <th>fold</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_2</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>f1-score_1</th>\n",
       "      <th>f1-score_2</th>\n",
       "      <th>support_1</th>\n",
       "      <th>support_2</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>1</td>\n",
       "      <td>0.992639</td>\n",
       "      <td>0.996587</td>\n",
       "      <td>0.999451</td>\n",
       "      <td>0.955810</td>\n",
       "      <td>0.996033</td>\n",
       "      <td>0.975773</td>\n",
       "      <td>3643.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>3641</td>\n",
       "      <td>27</td>\n",
       "      <td>584</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>2</td>\n",
       "      <td>0.996156</td>\n",
       "      <td>0.993464</td>\n",
       "      <td>0.998899</td>\n",
       "      <td>0.977492</td>\n",
       "      <td>0.997525</td>\n",
       "      <td>0.985413</td>\n",
       "      <td>3632.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>3628</td>\n",
       "      <td>14</td>\n",
       "      <td>608</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset                 model data balancing technique  fold  precision_1  \\\n",
       "10     DF5  BaggedTreeClassifier                    SMOTE     1     0.992639   \n",
       "11     DF5  BaggedTreeClassifier                    SMOTE     2     0.996156   \n",
       "\n",
       "    precision_2  recall_1  recall_2  f1-score_1  f1-score_2  support_1  \\\n",
       "10     0.996587  0.999451  0.955810    0.996033    0.975773     3643.0   \n",
       "11     0.993464  0.998899  0.977492    0.997525    0.985413     3632.0   \n",
       "\n",
       "    support_2    TP  FP   TN  FN  \n",
       "10      611.0  3641  27  584   2  \n",
       "11      622.0  3628  14  608   4  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_metrics[(combined_metrics['data balancing technique'] == 'SMOTE') & (combined_metrics['dataset'] == 'DF5')].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737bdf77",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier with df5 data and imbalance data tackling (RandomUnderSampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0efc30fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.99\n",
      "Mean Precision: 0.99\n",
      "Mean Recall: 0.99\n",
      "Mean F1-Score: 0.99\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df5' is your DataFrame with features and the target column\n",
    "# Replace 'features' with the actual list of feature columns\n",
    "features = df5.drop(columns=['target'])  # Drop the target column to get the feature columns\n",
    "target = df5['target']  # Target column to predict\n",
    "\n",
    "# Initialize a Decision Tree classifier\n",
    "base_estimator = DecisionTreeClassifier()\n",
    "model = BaggingClassifier(base_estimator, n_estimators=10, random_state=42)\n",
    "\n",
    "# Initialize KFold with 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    # Undersampling the majority class\n",
    "    rus = RandomUnderSampler(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Predict on the testing set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    y_pred = np.round(y_pred)\n",
    "\n",
    "    y_pred[y_pred <= 0] = 1\n",
    "    y_pred[y_pred >= 2] = 2\n",
    "    \n",
    "    # Model evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Convert classification report to DataFrame\n",
    "    report_df = pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).transpose()\n",
    "    # Convert confusion matrix to DataFrame\n",
    "    matrix_df = pd.DataFrame(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    # Extract metrics for class 1\n",
    "    metrics_1 = report_df.loc['1', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract metrics for class 2\n",
    "    metrics_2 = report_df.loc['2', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract TP, TN, FP, FN counts from the confusion matrix DataFrame\n",
    "    TP = matrix_df.loc[0, 0]\n",
    "    TN = matrix_df.loc[1, 1]\n",
    "    FP = matrix_df.loc[1, 0]\n",
    "    FN = matrix_df.loc[0, 1]\n",
    "    \n",
    "    new_metric_row = {\n",
    "    'dataset': 'DF5',\n",
    "    'model' : 'BaggedTreeClassifier',\n",
    "    'data balancing technique' : 'Random Under Sampler',\n",
    "    'fold' : i,\n",
    "    'precision_1': metrics_1['precision'],\n",
    "    'precision_2': metrics_2['precision'],\n",
    "    'recall_1': metrics_1['recall'],\n",
    "    'recall_2': metrics_2['recall'],\n",
    "    'f1-score_1': metrics_1['f1-score'],\n",
    "    'f1-score_2': metrics_2['f1-score'],\n",
    "    'support_1': metrics_1['support'],\n",
    "    'support_2': metrics_2['support'],\n",
    "    'TP' : TP,\n",
    "    'FP' : FP,\n",
    "    'TN' : TN,\n",
    "    'FN' : FN\n",
    "    }\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    #combined_metrics = combined_metrics.append(new_metric_row, ignore_index=True)\n",
    "    combined_metrics.loc[len(combined_metrics)] = new_metric_row\n",
    "    \n",
    "    \n",
    "    # Append evaluation metrics to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "\n",
    "# Calculate mean evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores) #sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = np.mean(precision_scores) #sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = np.mean(recall_scores) #sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = np.mean(f1_scores) #sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print('Mean Accuracy: {:.2f}'.format(mean_accuracy))\n",
    "print('Mean Precision: {:.2f}'.format(mean_precision))\n",
    "print('Mean Recall: {:.2f}'.format(mean_recall))\n",
    "print('Mean F1-Score: {:.2f}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d72cc02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>data balancing technique</th>\n",
       "      <th>fold</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_2</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>f1-score_1</th>\n",
       "      <th>f1-score_2</th>\n",
       "      <th>support_1</th>\n",
       "      <th>support_2</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>1</td>\n",
       "      <td>0.994251</td>\n",
       "      <td>0.981697</td>\n",
       "      <td>0.996981</td>\n",
       "      <td>0.965630</td>\n",
       "      <td>0.995614</td>\n",
       "      <td>0.973597</td>\n",
       "      <td>3643.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>3632</td>\n",
       "      <td>21</td>\n",
       "      <td>590</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>2</td>\n",
       "      <td>0.996961</td>\n",
       "      <td>0.963722</td>\n",
       "      <td>0.993667</td>\n",
       "      <td>0.982315</td>\n",
       "      <td>0.995312</td>\n",
       "      <td>0.972930</td>\n",
       "      <td>3632.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>3609</td>\n",
       "      <td>11</td>\n",
       "      <td>611</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset                 model data balancing technique  fold  precision_1  \\\n",
       "20     DF5  BaggedTreeClassifier     Random Under Sampler     1     0.994251   \n",
       "21     DF5  BaggedTreeClassifier     Random Under Sampler     2     0.996961   \n",
       "\n",
       "    precision_2  recall_1  recall_2  f1-score_1  f1-score_2  support_1  \\\n",
       "20     0.981697  0.996981  0.965630    0.995614    0.973597     3643.0   \n",
       "21     0.963722  0.993667  0.982315    0.995312    0.972930     3632.0   \n",
       "\n",
       "    support_2    TP  FP   TN  FN  \n",
       "20      611.0  3632  21  590  11  \n",
       "21      622.0  3609  11  611  23  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_metrics[(combined_metrics['data balancing technique'] == 'Random Under Sampler') & (combined_metrics['dataset'] == 'DF5')].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc10646",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier with df5 data and imbalance data tackling (RandomOverSampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c500a1fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.99\n",
      "Mean Precision: 0.99\n",
      "Mean Recall: 0.99\n",
      "Mean F1-Score: 0.99\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df5' is your DataFrame with features and the target column\n",
    "# Replace 'features' with the actual list of feature columns\n",
    "features = df5.drop(columns=['target'])  # Drop the target column to get the feature columns\n",
    "target = df5['target']  # Target column to predict\n",
    "\n",
    "# Initialize a Decision Tree classifier\n",
    "base_estimator = DecisionTreeClassifier()\n",
    "model = BaggingClassifier(base_estimator, n_estimators=10, random_state=42)\n",
    "\n",
    "# Initialize KFold with 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    # Oversampling the majority class\n",
    "    ros = RandomOverSampler(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Predict on the testing set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    y_pred = np.round(y_pred)\n",
    "\n",
    "    y_pred[y_pred <= 0] = 1\n",
    "    y_pred[y_pred >= 2] = 2\n",
    "    \n",
    "    # Model evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Convert classification report to DataFrame\n",
    "    report_df = pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).transpose()\n",
    "    # Convert confusion matrix to DataFrame\n",
    "    matrix_df = pd.DataFrame(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    # Extract metrics for class 1\n",
    "    metrics_1 = report_df.loc['1', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract metrics for class 2\n",
    "    metrics_2 = report_df.loc['2', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract TP, TN, FP, FN counts from the confusion matrix DataFrame\n",
    "    TP = matrix_df.loc[0, 0]\n",
    "    TN = matrix_df.loc[1, 1]\n",
    "    FP = matrix_df.loc[1, 0]\n",
    "    FN = matrix_df.loc[0, 1]\n",
    "    \n",
    "    new_metric_row = {\n",
    "    'dataset': 'DF5',\n",
    "    'model' : 'BaggedTreeClassifier',\n",
    "    'data balancing technique' : 'Random Over Sampler',\n",
    "    'fold' : i,\n",
    "    'precision_1': metrics_1['precision'],\n",
    "    'precision_2': metrics_2['precision'],\n",
    "    'recall_1': metrics_1['recall'],\n",
    "    'recall_2': metrics_2['recall'],\n",
    "    'f1-score_1': metrics_1['f1-score'],\n",
    "    'f1-score_2': metrics_2['f1-score'],\n",
    "    'support_1': metrics_1['support'],\n",
    "    'support_2': metrics_2['support'],\n",
    "    'TP' : TP,\n",
    "    'FP' : FP,\n",
    "    'TN' : TN,\n",
    "    'FN' : FN\n",
    "    }\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    #combined_metrics = combined_metrics.append(new_metric_row, ignore_index=True)\n",
    "    combined_metrics.loc[len(combined_metrics)] = new_metric_row\n",
    "    \n",
    "    \n",
    "    # Append evaluation metrics to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "\n",
    "# Calculate mean evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores) #sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = np.mean(precision_scores) #sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = np.mean(recall_scores) #sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = np.mean(f1_scores) #sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print('Mean Accuracy: {:.2f}'.format(mean_accuracy))\n",
    "print('Mean Precision: {:.2f}'.format(mean_precision))\n",
    "print('Mean Recall: {:.2f}'.format(mean_recall))\n",
    "print('Mean F1-Score: {:.2f}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca7e58c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>data balancing technique</th>\n",
       "      <th>fold</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_2</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>f1-score_1</th>\n",
       "      <th>f1-score_2</th>\n",
       "      <th>support_1</th>\n",
       "      <th>support_2</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>1</td>\n",
       "      <td>0.993179</td>\n",
       "      <td>0.994907</td>\n",
       "      <td>0.999177</td>\n",
       "      <td>0.959083</td>\n",
       "      <td>0.996169</td>\n",
       "      <td>0.976667</td>\n",
       "      <td>3643.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>3640</td>\n",
       "      <td>25</td>\n",
       "      <td>586</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>2</td>\n",
       "      <td>0.994515</td>\n",
       "      <td>0.990132</td>\n",
       "      <td>0.998348</td>\n",
       "      <td>0.967846</td>\n",
       "      <td>0.996428</td>\n",
       "      <td>0.978862</td>\n",
       "      <td>3632.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>3626</td>\n",
       "      <td>20</td>\n",
       "      <td>602</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset                 model data balancing technique  fold  precision_1  \\\n",
       "30     DF5  BaggedTreeClassifier      Random Over Sampler     1     0.993179   \n",
       "31     DF5  BaggedTreeClassifier      Random Over Sampler     2     0.994515   \n",
       "\n",
       "    precision_2  recall_1  recall_2  f1-score_1  f1-score_2  support_1  \\\n",
       "30     0.994907  0.999177  0.959083    0.996169    0.976667     3643.0   \n",
       "31     0.990132  0.998348  0.967846    0.996428    0.978862     3632.0   \n",
       "\n",
       "    support_2    TP  FP   TN  FN  \n",
       "30      611.0  3640  25  586   3  \n",
       "31      622.0  3626  20  602   6  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_metrics[(combined_metrics['data balancing technique'] == 'Random Over Sampler') & (combined_metrics['dataset'] == 'DF5')].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3502aa0f",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier with df5 data and imbalance data tackling (SMOTEENN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14344c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.99\n",
      "Mean Precision: 0.99\n",
      "Mean Recall: 0.99\n",
      "Mean F1-Score: 0.99\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df5' is your DataFrame with features and the target column\n",
    "# Replace 'features' with the actual list of feature columns\n",
    "features = df5.drop(columns=['target'])  # Drop the target column to get the feature columns\n",
    "target = df5['target']  # Target column to predict\n",
    "\n",
    "# Initialize a Decision Tree classifier\n",
    "base_estimator = DecisionTreeClassifier()\n",
    "model = BaggingClassifier(base_estimator, n_estimators=10, random_state=42)\n",
    "\n",
    "# Initialize KFold with 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    # Apply SMOTEENN for combined over and undersampling\n",
    "    smote_enn = SMOTEENN(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote_enn.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Predict on the testing set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    y_pred = np.round(y_pred)\n",
    "\n",
    "    y_pred[y_pred <= 0] = 1\n",
    "    y_pred[y_pred >= 2] = 2\n",
    "    \n",
    "    # Model evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Convert classification report to DataFrame\n",
    "    report_df = pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).transpose()\n",
    "    # Convert confusion matrix to DataFrame\n",
    "    matrix_df = pd.DataFrame(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    # Extract metrics for class 1\n",
    "    metrics_1 = report_df.loc['1', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract metrics for class 2\n",
    "    metrics_2 = report_df.loc['2', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract TP, TN, FP, FN counts from the confusion matrix DataFrame\n",
    "    TP = matrix_df.loc[0, 0]\n",
    "    TN = matrix_df.loc[1, 1]\n",
    "    FP = matrix_df.loc[1, 0]\n",
    "    FN = matrix_df.loc[0, 1]\n",
    "    \n",
    "    new_metric_row = {\n",
    "    'dataset': 'DF5',\n",
    "    'model' : 'BaggedTreeClassifier',\n",
    "    'data balancing technique' : 'SMOTEENN',\n",
    "    'fold' : i,\n",
    "    'precision_1': metrics_1['precision'],\n",
    "    'precision_2': metrics_2['precision'],\n",
    "    'recall_1': metrics_1['recall'],\n",
    "    'recall_2': metrics_2['recall'],\n",
    "    'f1-score_1': metrics_1['f1-score'],\n",
    "    'f1-score_2': metrics_2['f1-score'],\n",
    "    'support_1': metrics_1['support'],\n",
    "    'support_2': metrics_2['support'],\n",
    "    'TP' : TP,\n",
    "    'FP' : FP,\n",
    "    'TN' : TN,\n",
    "    'FN' : FN\n",
    "    }\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    #combined_metrics = combined_metrics.append(new_metric_row, ignore_index=True)\n",
    "    combined_metrics.loc[len(combined_metrics)] = new_metric_row\n",
    "    \n",
    "    \n",
    "    # Append evaluation metrics to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "\n",
    "# Calculate mean evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores) #sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = np.mean(precision_scores) #sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = np.mean(recall_scores) #sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = np.mean(f1_scores) #sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print('Mean Accuracy: {:.2f}'.format(mean_accuracy))\n",
    "print('Mean Precision: {:.2f}'.format(mean_precision))\n",
    "print('Mean Recall: {:.2f}'.format(mean_recall))\n",
    "print('Mean F1-Score: {:.2f}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "661a7658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>data balancing technique</th>\n",
       "      <th>fold</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_2</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>f1-score_1</th>\n",
       "      <th>f1-score_2</th>\n",
       "      <th>support_1</th>\n",
       "      <th>support_2</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>SMOTEENN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.993448</td>\n",
       "      <td>0.993232</td>\n",
       "      <td>0.998902</td>\n",
       "      <td>0.96072</td>\n",
       "      <td>0.996168</td>\n",
       "      <td>0.976705</td>\n",
       "      <td>3643.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>3639</td>\n",
       "      <td>24</td>\n",
       "      <td>587</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>SMOTEENN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.996429</td>\n",
       "      <td>0.991857</td>\n",
       "      <td>0.998623</td>\n",
       "      <td>0.97910</td>\n",
       "      <td>0.997525</td>\n",
       "      <td>0.985437</td>\n",
       "      <td>3632.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>3627</td>\n",
       "      <td>13</td>\n",
       "      <td>609</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset                 model data balancing technique  fold  precision_1  \\\n",
       "40     DF5  BaggedTreeClassifier                 SMOTEENN     1     0.993448   \n",
       "41     DF5  BaggedTreeClassifier                 SMOTEENN     2     0.996429   \n",
       "\n",
       "    precision_2  recall_1  recall_2  f1-score_1  f1-score_2  support_1  \\\n",
       "40     0.993232  0.998902   0.96072    0.996168    0.976705     3643.0   \n",
       "41     0.991857  0.998623   0.97910    0.997525    0.985437     3632.0   \n",
       "\n",
       "    support_2    TP  FP   TN  FN  \n",
       "40      611.0  3639  24  587   4  \n",
       "41      622.0  3627  13  609   5  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_metrics[(combined_metrics['data balancing technique'] == 'SMOTEENN') & (combined_metrics['dataset'] == 'DF5')].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d61e0f",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier with df5 data and imbalance data tackling (SMOTETOMEK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "474f7eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.99\n",
      "Mean Precision: 0.99\n",
      "Mean Recall: 0.99\n",
      "Mean F1-Score: 0.99\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df5' is your DataFrame with features and the target column\n",
    "# Replace 'features' with the actual list of feature columns\n",
    "features = df5.drop(columns=['target'])  # Drop the target column to get the feature columns\n",
    "target = df5['target']  # Target column to predict\n",
    "\n",
    "# Initialize a Decision Tree classifier\n",
    "base_estimator = DecisionTreeClassifier()\n",
    "model = BaggingClassifier(base_estimator, n_estimators=10, random_state=42)\n",
    "\n",
    "# Initialize KFold with 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    # Apply SMOTETomek for combined over and undersampling\n",
    "    SMOTE_Tomek = SMOTETomek(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = SMOTE_Tomek.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Predict on the testing set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    y_pred = np.round(y_pred)\n",
    "\n",
    "    y_pred[y_pred <= 0] = 1\n",
    "    y_pred[y_pred >= 2] = 2\n",
    "    \n",
    "    # Model evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Convert classification report to DataFrame\n",
    "    report_df = pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).transpose()\n",
    "    # Convert confusion matrix to DataFrame\n",
    "    matrix_df = pd.DataFrame(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    # Extract metrics for class 1\n",
    "    metrics_1 = report_df.loc['1', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract metrics for class 2\n",
    "    metrics_2 = report_df.loc['2', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract TP, TN, FP, FN counts from the confusion matrix DataFrame\n",
    "    TP = matrix_df.loc[0, 0]\n",
    "    TN = matrix_df.loc[1, 1]\n",
    "    FP = matrix_df.loc[1, 0]\n",
    "    FN = matrix_df.loc[0, 1]\n",
    "    \n",
    "    new_metric_row = {\n",
    "    'dataset': 'DF5',\n",
    "    'model' : 'BaggedTreeClassifier',\n",
    "    'data balancing technique' : 'SMOTETomek',\n",
    "    'fold' : i,\n",
    "    'precision_1': metrics_1['precision'],\n",
    "    'precision_2': metrics_2['precision'],\n",
    "    'recall_1': metrics_1['recall'],\n",
    "    'recall_2': metrics_2['recall'],\n",
    "    'f1-score_1': metrics_1['f1-score'],\n",
    "    'f1-score_2': metrics_2['f1-score'],\n",
    "    'support_1': metrics_1['support'],\n",
    "    'support_2': metrics_2['support'],\n",
    "    'TP' : TP,\n",
    "    'FP' : FP,\n",
    "    'TN' : TN,\n",
    "    'FN' : FN\n",
    "    }\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    #combined_metrics = combined_metrics.append(new_metric_row, ignore_index=True)\n",
    "    combined_metrics.loc[len(combined_metrics)] = new_metric_row\n",
    "    \n",
    "    \n",
    "    # Append evaluation metrics to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "\n",
    "# Calculate mean evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores) #sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = np.mean(precision_scores) #sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = np.mean(recall_scores) #sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = np.mean(f1_scores) #sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print('Mean Accuracy: {:.2f}'.format(mean_accuracy))\n",
    "print('Mean Precision: {:.2f}'.format(mean_precision))\n",
    "print('Mean Recall: {:.2f}'.format(mean_recall))\n",
    "print('Mean F1-Score: {:.2f}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f6da809c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>data balancing technique</th>\n",
       "      <th>fold</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_2</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>f1-score_1</th>\n",
       "      <th>f1-score_2</th>\n",
       "      <th>support_1</th>\n",
       "      <th>support_2</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>SMOTETomek</td>\n",
       "      <td>1</td>\n",
       "      <td>0.992912</td>\n",
       "      <td>0.998294</td>\n",
       "      <td>0.999726</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.996307</td>\n",
       "      <td>0.977444</td>\n",
       "      <td>3643.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>3642</td>\n",
       "      <td>26</td>\n",
       "      <td>585</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>SMOTETomek</td>\n",
       "      <td>2</td>\n",
       "      <td>0.995610</td>\n",
       "      <td>0.995074</td>\n",
       "      <td>0.999174</td>\n",
       "      <td>0.974277</td>\n",
       "      <td>0.997389</td>\n",
       "      <td>0.984565</td>\n",
       "      <td>3632.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>3629</td>\n",
       "      <td>16</td>\n",
       "      <td>606</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset                 model data balancing technique  fold  precision_1  \\\n",
       "50     DF5  BaggedTreeClassifier               SMOTETomek     1     0.992912   \n",
       "51     DF5  BaggedTreeClassifier               SMOTETomek     2     0.995610   \n",
       "\n",
       "    precision_2  recall_1  recall_2  f1-score_1  f1-score_2  support_1  \\\n",
       "50     0.998294  0.999726  0.957447    0.996307    0.977444     3643.0   \n",
       "51     0.995074  0.999174  0.974277    0.997389    0.984565     3632.0   \n",
       "\n",
       "    support_2    TP  FP   TN  FN  \n",
       "50      611.0  3642  26  585   1  \n",
       "51      622.0  3629  16  606   3  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_metrics[(combined_metrics['data balancing technique'] == 'SMOTETomek') & (combined_metrics['dataset'] == 'DF5')].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d2a74b23",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sys' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m sys\u001b[38;5;241m.\u001b[39mexit()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sys' is not defined"
     ]
    }
   ],
   "source": [
    "sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85f183d",
   "metadata": {},
   "source": [
    "## DF5c - Bagged Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b53bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'df5' is your DataFrame with features and the target column\n",
    "# Replace 'features' with the actual list of feature columns\n",
    "features = df5c.drop(columns=['target'])  # Drop the target column to get the feature columns\n",
    "target = df5c['target']  # Target column to predict\n",
    "\n",
    "# Initialize a Decision Tree classifier\n",
    "base_estimator = DecisionTreeClassifier()\n",
    "model = BaggingClassifier(base_estimator, n_estimators=10, random_state=42)\n",
    "\n",
    "# Initialize KFold with 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the testing set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Model evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Convert classification report to DataFrame\n",
    "    report_df = pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).transpose()\n",
    "    # Convert confusion matrix to DataFrame\n",
    "    matrix_df = pd.DataFrame(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    # Extract metrics for class 1\n",
    "    metrics_1 = report_df.loc['1', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract metrics for class 2\n",
    "    metrics_2 = report_df.loc['2', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract TP, TN, FP, FN counts from the confusion matrix DataFrame\n",
    "    TP = matrix_df.loc[0, 0]\n",
    "    TN = matrix_df.loc[1, 1]\n",
    "    FP = matrix_df.loc[1, 0]\n",
    "    FN = matrix_df.loc[0, 1]\n",
    "    \n",
    "    new_metric_row = {\n",
    "    'dataset': 'DF5c',\n",
    "    'model' : 'BaggedTreeClassifier',\n",
    "    'data balancing technique' : 'None',\n",
    "    'fold' : i,\n",
    "    'precision_1': metrics_1['precision'],\n",
    "    'precision_2': metrics_2['precision'],\n",
    "    'recall_1': metrics_1['recall'],\n",
    "    'recall_2': metrics_2['recall'],\n",
    "    'f1-score_1': metrics_1['f1-score'],\n",
    "    'f1-score_2': metrics_2['f1-score'],\n",
    "    'support_1': metrics_1['support'],\n",
    "    'support_2': metrics_2['support'],\n",
    "    'TP' : TP,\n",
    "    'FP' : FP,\n",
    "    'TN' : TN,\n",
    "    'FN' : FN\n",
    "    }\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    #combined_metrics = combined_metrics.append(new_metric_row, ignore_index=True)\n",
    "    combined_metrics.loc[len(combined_metrics)] = new_metric_row\n",
    "    \n",
    "    \n",
    "    # Append evaluation metrics to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "\n",
    "# Calculate mean evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores) #sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = np.mean(precision_scores) #sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = np.mean(recall_scores) #sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = np.mean(f1_scores) #sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print('Mean Accuracy: {:.2f}'.format(mean_accuracy))\n",
    "print('Mean Precision: {:.2f}'.format(mean_precision))\n",
    "print('Mean Recall: {:.2f}'.format(mean_recall))\n",
    "print('Mean F1-Score: {:.2f}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbc10dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_metrics[(combined_metrics['data balancing technique'] == 'None') & (combined_metrics['dataset'] == 'DF5c')].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a96351",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier with df5c data and imbalance data tackling (SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa40392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'df5' is your DataFrame with features and the target column\n",
    "# Replace 'features' with the actual list of feature columns\n",
    "features = df5c.drop(columns=['target'])  # Drop the target column to get the feature columns\n",
    "target = df5c['target']  # Target column to predict\n",
    "\n",
    "# Initialize a Decision Tree classifier\n",
    "base_estimator = DecisionTreeClassifier()\n",
    "model = BaggingClassifier(base_estimator, n_estimators=10, random_state=42)\n",
    "\n",
    "# Initialize KFold with 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    # Apply SMOTE to the training data\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Predict on the testing set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Model evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Convert classification report to DataFrame\n",
    "    report_df = pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).transpose()\n",
    "    # Convert confusion matrix to DataFrame\n",
    "    matrix_df = pd.DataFrame(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    # Extract metrics for class 1\n",
    "    metrics_1 = report_df.loc['1', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract metrics for class 2\n",
    "    metrics_2 = report_df.loc['2', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract TP, TN, FP, FN counts from the confusion matrix DataFrame\n",
    "    TP = matrix_df.loc[0, 0]\n",
    "    TN = matrix_df.loc[1, 1]\n",
    "    FP = matrix_df.loc[1, 0]\n",
    "    FN = matrix_df.loc[0, 1]\n",
    "    \n",
    "    new_metric_row = {\n",
    "    'dataset': 'DF5c',\n",
    "    'model' : 'BaggedTreeClassifier',\n",
    "    'data balancing technique' : 'SMOTE',\n",
    "    'fold' : i,\n",
    "    'precision_1': metrics_1['precision'],\n",
    "    'precision_2': metrics_2['precision'],\n",
    "    'recall_1': metrics_1['recall'],\n",
    "    'recall_2': metrics_2['recall'],\n",
    "    'f1-score_1': metrics_1['f1-score'],\n",
    "    'f1-score_2': metrics_2['f1-score'],\n",
    "    'support_1': metrics_1['support'],\n",
    "    'support_2': metrics_2['support'],\n",
    "    'TP' : TP,\n",
    "    'FP' : FP,\n",
    "    'TN' : TN,\n",
    "    'FN' : FN\n",
    "    }\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    #combined_metrics = combined_metrics.append(new_metric_row, ignore_index=True)\n",
    "    combined_metrics.loc[len(combined_metrics)] = new_metric_row\n",
    "    \n",
    "    \n",
    "    # Append evaluation metrics to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "\n",
    "# Calculate mean evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores) #sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = np.mean(precision_scores) #sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = np.mean(recall_scores) #sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = np.mean(f1_scores) #sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print('Mean Accuracy: {:.2f}'.format(mean_accuracy))\n",
    "print('Mean Precision: {:.2f}'.format(mean_precision))\n",
    "print('Mean Recall: {:.2f}'.format(mean_recall))\n",
    "print('Mean F1-Score: {:.2f}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d1a9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_metrics[(combined_metrics['data balancing technique'] == 'SMOTE') & (combined_metrics['dataset'] == 'DF5c')].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fab885",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier with df5c data and imbalance data tackling (Random Under Sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9f5e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'df5' is your DataFrame with features and the target column\n",
    "# Replace 'features' with the actual list of feature columns\n",
    "features = df5c.drop(columns=['target'])  # Drop the target column to get the feature columns\n",
    "target = df5c['target']  # Target column to predict\n",
    "\n",
    "# Initialize a Decision Tree classifier\n",
    "base_estimator = DecisionTreeClassifier()\n",
    "model = BaggingClassifier(base_estimator, n_estimators=10, random_state=42)\n",
    "\n",
    "# Initialize KFold with 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    # Apply RUS to the training data\n",
    "    rus = RandomUnderSampler(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Predict on the testing set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Model evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Convert classification report to DataFrame\n",
    "    report_df = pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).transpose()\n",
    "    # Convert confusion matrix to DataFrame\n",
    "    matrix_df = pd.DataFrame(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    # Extract metrics for class 1\n",
    "    metrics_1 = report_df.loc['1', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract metrics for class 2\n",
    "    metrics_2 = report_df.loc['2', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract TP, TN, FP, FN counts from the confusion matrix DataFrame\n",
    "    TP = matrix_df.loc[0, 0]\n",
    "    TN = matrix_df.loc[1, 1]\n",
    "    FP = matrix_df.loc[1, 0]\n",
    "    FN = matrix_df.loc[0, 1]\n",
    "    \n",
    "    new_metric_row = {\n",
    "    'dataset': 'DF5c',\n",
    "    'model' : 'BaggedTreeClassifier',\n",
    "    'data balancing technique' : 'Random Under Sampler',\n",
    "    'fold' : i,\n",
    "    'precision_1': metrics_1['precision'],\n",
    "    'precision_2': metrics_2['precision'],\n",
    "    'recall_1': metrics_1['recall'],\n",
    "    'recall_2': metrics_2['recall'],\n",
    "    'f1-score_1': metrics_1['f1-score'],\n",
    "    'f1-score_2': metrics_2['f1-score'],\n",
    "    'support_1': metrics_1['support'],\n",
    "    'support_2': metrics_2['support'],\n",
    "    'TP' : TP,\n",
    "    'FP' : FP,\n",
    "    'TN' : TN,\n",
    "    'FN' : FN\n",
    "    }\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    #combined_metrics = combined_metrics.append(new_metric_row, ignore_index=True)\n",
    "    combined_metrics.loc[len(combined_metrics)] = new_metric_row\n",
    "    \n",
    "    \n",
    "    # Append evaluation metrics to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "\n",
    "# Calculate mean evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores) #sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = np.mean(precision_scores) #sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = np.mean(recall_scores) #sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = np.mean(f1_scores) #sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print('Mean Accuracy: {:.2f}'.format(mean_accuracy))\n",
    "print('Mean Precision: {:.2f}'.format(mean_precision))\n",
    "print('Mean Recall: {:.2f}'.format(mean_recall))\n",
    "print('Mean F1-Score: {:.2f}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1bb284",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_metrics[(combined_metrics['data balancing technique'] == 'Random Under Sampler') & (combined_metrics['dataset'] == 'DF5c')].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596f2d9a",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier with df5c data and imbalance data tackling (Random Over Sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deeacc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'df5' is your DataFrame with features and the target column\n",
    "# Replace 'features' with the actual list of feature columns\n",
    "features = df5c.drop(columns=['target'])  # Drop the target column to get the feature columns\n",
    "target = df5c['target']  # Target column to predict\n",
    "\n",
    "# Initialize a Decision Tree classifier\n",
    "base_estimator = DecisionTreeClassifier()\n",
    "model = BaggingClassifier(base_estimator, n_estimators=10, random_state=42)\n",
    "\n",
    "# Initialize KFold with 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    # Apply ROS to the training data\n",
    "    ros = RandomOverSampler(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Predict on the testing set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Model evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Convert classification report to DataFrame\n",
    "    report_df = pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).transpose()\n",
    "    # Convert confusion matrix to DataFrame\n",
    "    matrix_df = pd.DataFrame(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    # Extract metrics for class 1\n",
    "    metrics_1 = report_df.loc['1', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract metrics for class 2\n",
    "    metrics_2 = report_df.loc['2', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract TP, TN, FP, FN counts from the confusion matrix DataFrame\n",
    "    TP = matrix_df.loc[0, 0]\n",
    "    TN = matrix_df.loc[1, 1]\n",
    "    FP = matrix_df.loc[1, 0]\n",
    "    FN = matrix_df.loc[0, 1]\n",
    "    \n",
    "    new_metric_row = {\n",
    "    'dataset': 'DF5c',\n",
    "    'model' : 'BaggedTreeClassifier',\n",
    "    'data balancing technique' : 'Random Over Sampler',\n",
    "    'fold' : i,\n",
    "    'precision_1': metrics_1['precision'],\n",
    "    'precision_2': metrics_2['precision'],\n",
    "    'recall_1': metrics_1['recall'],\n",
    "    'recall_2': metrics_2['recall'],\n",
    "    'f1-score_1': metrics_1['f1-score'],\n",
    "    'f1-score_2': metrics_2['f1-score'],\n",
    "    'support_1': metrics_1['support'],\n",
    "    'support_2': metrics_2['support'],\n",
    "    'TP' : TP,\n",
    "    'FP' : FP,\n",
    "    'TN' : TN,\n",
    "    'FN' : FN\n",
    "    }\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    #combined_metrics = combined_metrics.append(new_metric_row, ignore_index=True)\n",
    "    combined_metrics.loc[len(combined_metrics)] = new_metric_row\n",
    "    \n",
    "    \n",
    "    # Append evaluation metrics to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "\n",
    "# Calculate mean evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores) #sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = np.mean(precision_scores) #sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = np.mean(recall_scores) #sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = np.mean(f1_scores) #sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print('Mean Accuracy: {:.2f}'.format(mean_accuracy))\n",
    "print('Mean Precision: {:.2f}'.format(mean_precision))\n",
    "print('Mean Recall: {:.2f}'.format(mean_recall))\n",
    "print('Mean F1-Score: {:.2f}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c845f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_metrics[(combined_metrics['data balancing technique'] == 'Random Over Sampler') & (combined_metrics['dataset'] == 'DF5c')].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d688e2",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier with df5c data and imbalance data tackling (SMOTEENN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c044fc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'df5' is your DataFrame with features and the target column\n",
    "# Replace 'features' with the actual list of feature columns\n",
    "features = df5c.drop(columns=['target'])  # Drop the target column to get the feature columns\n",
    "target = df5c['target']  # Target column to predict\n",
    "\n",
    "# Initialize a Decision Tree classifier\n",
    "base_estimator = DecisionTreeClassifier()\n",
    "model = BaggingClassifier(base_estimator, n_estimators=10, random_state=42)\n",
    "\n",
    "# Initialize KFold with 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    # Apply SMOTEENN to the training data\n",
    "    SMOTEEnn = SMOTEENN(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = SMOTEEnn.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Predict on the testing set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Model evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Convert classification report to DataFrame\n",
    "    report_df = pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).transpose()\n",
    "    # Convert confusion matrix to DataFrame\n",
    "    matrix_df = pd.DataFrame(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    # Extract metrics for class 1\n",
    "    metrics_1 = report_df.loc['1', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract metrics for class 2\n",
    "    metrics_2 = report_df.loc['2', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract TP, TN, FP, FN counts from the confusion matrix DataFrame\n",
    "    TP = matrix_df.loc[0, 0]\n",
    "    TN = matrix_df.loc[1, 1]\n",
    "    FP = matrix_df.loc[1, 0]\n",
    "    FN = matrix_df.loc[0, 1]\n",
    "    \n",
    "    new_metric_row = {\n",
    "    'dataset': 'DF5c',\n",
    "    'model' : 'BaggedTreeClassifier',\n",
    "    'data balancing technique' : 'SMOTEENN',\n",
    "    'fold' : i,\n",
    "    'precision_1': metrics_1['precision'],\n",
    "    'precision_2': metrics_2['precision'],\n",
    "    'recall_1': metrics_1['recall'],\n",
    "    'recall_2': metrics_2['recall'],\n",
    "    'f1-score_1': metrics_1['f1-score'],\n",
    "    'f1-score_2': metrics_2['f1-score'],\n",
    "    'support_1': metrics_1['support'],\n",
    "    'support_2': metrics_2['support'],\n",
    "    'TP' : TP,\n",
    "    'FP' : FP,\n",
    "    'TN' : TN,\n",
    "    'FN' : FN\n",
    "    }\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    #combined_metrics = combined_metrics.append(new_metric_row, ignore_index=True)\n",
    "    combined_metrics.loc[len(combined_metrics)] = new_metric_row\n",
    "    \n",
    "    \n",
    "    # Append evaluation metrics to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "\n",
    "# Calculate mean evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores) #sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = np.mean(precision_scores) #sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = np.mean(recall_scores) #sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = np.mean(f1_scores) #sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print('Mean Accuracy: {:.2f}'.format(mean_accuracy))\n",
    "print('Mean Precision: {:.2f}'.format(mean_precision))\n",
    "print('Mean Recall: {:.2f}'.format(mean_recall))\n",
    "print('Mean F1-Score: {:.2f}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81297c53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_metrics[(combined_metrics['data balancing technique'] == 'SMOTEENN') & (combined_metrics['dataset'] == 'DF5c')].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d72534",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier with df5c data and imbalance data tackling (SMOTETomek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2300ee90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'df5' is your DataFrame with features and the target column\n",
    "# Replace 'features' with the actual list of feature columns\n",
    "features = df5c.drop(columns=['target'])  # Drop the target column to get the feature columns\n",
    "target = df5c['target']  # Target column to predict\n",
    "\n",
    "# Initialize a Decision Tree classifier\n",
    "base_estimator = DecisionTreeClassifier()\n",
    "model = BaggingClassifier(base_estimator, n_estimators=10, random_state=42)\n",
    "\n",
    "# Initialize KFold with 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    # Apply SMOTEENN to the training data\n",
    "    SMOTETOMEK = SMOTETomek(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = SMOTETOMEK.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Predict on the testing set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Model evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Convert classification report to DataFrame\n",
    "    report_df = pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).transpose()\n",
    "    # Convert confusion matrix to DataFrame\n",
    "    matrix_df = pd.DataFrame(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    # Extract metrics for class 1\n",
    "    metrics_1 = report_df.loc['1', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract metrics for class 2\n",
    "    metrics_2 = report_df.loc['2', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract TP, TN, FP, FN counts from the confusion matrix DataFrame\n",
    "    TP = matrix_df.loc[0, 0]\n",
    "    TN = matrix_df.loc[1, 1]\n",
    "    FP = matrix_df.loc[1, 0]\n",
    "    FN = matrix_df.loc[0, 1]\n",
    "    \n",
    "    new_metric_row = {\n",
    "    'dataset': 'DF5c',\n",
    "    'model' : 'BaggedTreeClassifier',\n",
    "    'data balancing technique' : 'SMOTETomek',\n",
    "    'fold' : i,\n",
    "    'precision_1': metrics_1['precision'],\n",
    "    'precision_2': metrics_2['precision'],\n",
    "    'recall_1': metrics_1['recall'],\n",
    "    'recall_2': metrics_2['recall'],\n",
    "    'f1-score_1': metrics_1['f1-score'],\n",
    "    'f1-score_2': metrics_2['f1-score'],\n",
    "    'support_1': metrics_1['support'],\n",
    "    'support_2': metrics_2['support'],\n",
    "    'TP' : TP,\n",
    "    'FP' : FP,\n",
    "    'TN' : TN,\n",
    "    'FN' : FN\n",
    "    }\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    #combined_metrics = combined_metrics.append(new_metric_row, ignore_index=True)\n",
    "    combined_metrics.loc[len(combined_metrics)] = new_metric_row\n",
    "    \n",
    "    \n",
    "    # Append evaluation metrics to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "\n",
    "# Calculate mean evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores) #sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = np.mean(precision_scores) #sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = np.mean(recall_scores) #sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = np.mean(f1_scores) #sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print('Mean Accuracy: {:.2f}'.format(mean_accuracy))\n",
    "print('Mean Precision: {:.2f}'.format(mean_precision))\n",
    "print('Mean Recall: {:.2f}'.format(mean_recall))\n",
    "print('Mean F1-Score: {:.2f}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6d42eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_metrics[(combined_metrics['data balancing technique'] == 'SMOTETomek') & (combined_metrics['dataset'] == 'DF5c')].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd948ec1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc4b04f0",
   "metadata": {},
   "source": [
    "## Performance metrics for the Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1158fa25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>data balancing technique</th>\n",
       "      <th>fold</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_2</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>f1-score_1</th>\n",
       "      <th>f1-score_2</th>\n",
       "      <th>support_1</th>\n",
       "      <th>support_2</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0.992366</td>\n",
       "      <td>0.994881</td>\n",
       "      <td>0.999177</td>\n",
       "      <td>0.954173</td>\n",
       "      <td>0.995760</td>\n",
       "      <td>0.974102</td>\n",
       "      <td>3643.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>3640</td>\n",
       "      <td>28</td>\n",
       "      <td>583</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>0.994250</td>\n",
       "      <td>0.998339</td>\n",
       "      <td>0.999725</td>\n",
       "      <td>0.966238</td>\n",
       "      <td>0.996980</td>\n",
       "      <td>0.982026</td>\n",
       "      <td>3632.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>3631</td>\n",
       "      <td>21</td>\n",
       "      <td>601</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>0.993674</td>\n",
       "      <td>0.998382</td>\n",
       "      <td>0.999723</td>\n",
       "      <td>0.964063</td>\n",
       "      <td>0.996690</td>\n",
       "      <td>0.980922</td>\n",
       "      <td>3614.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3613</td>\n",
       "      <td>23</td>\n",
       "      <td>617</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>0.989575</td>\n",
       "      <td>0.995074</td>\n",
       "      <td>0.999169</td>\n",
       "      <td>0.940994</td>\n",
       "      <td>0.994349</td>\n",
       "      <td>0.967279</td>\n",
       "      <td>3610.0</td>\n",
       "      <td>644.0</td>\n",
       "      <td>3607</td>\n",
       "      <td>38</td>\n",
       "      <td>606</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>0.992572</td>\n",
       "      <td>0.991922</td>\n",
       "      <td>0.998616</td>\n",
       "      <td>0.957878</td>\n",
       "      <td>0.995585</td>\n",
       "      <td>0.974603</td>\n",
       "      <td>3613.0</td>\n",
       "      <td>641.0</td>\n",
       "      <td>3608</td>\n",
       "      <td>27</td>\n",
       "      <td>614</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>0.992853</td>\n",
       "      <td>0.998374</td>\n",
       "      <td>0.999723</td>\n",
       "      <td>0.959375</td>\n",
       "      <td>0.996276</td>\n",
       "      <td>0.978486</td>\n",
       "      <td>3613.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3612</td>\n",
       "      <td>26</td>\n",
       "      <td>614</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>None</td>\n",
       "      <td>7</td>\n",
       "      <td>0.991715</td>\n",
       "      <td>0.996835</td>\n",
       "      <td>0.999443</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.995564</td>\n",
       "      <td>0.975232</td>\n",
       "      <td>3593.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3591</td>\n",
       "      <td>30</td>\n",
       "      <td>630</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>None</td>\n",
       "      <td>8</td>\n",
       "      <td>0.992792</td>\n",
       "      <td>0.996904</td>\n",
       "      <td>0.999442</td>\n",
       "      <td>0.961194</td>\n",
       "      <td>0.996106</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>3583.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>3581</td>\n",
       "      <td>26</td>\n",
       "      <td>644</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>None</td>\n",
       "      <td>9</td>\n",
       "      <td>0.992263</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.957704</td>\n",
       "      <td>0.996117</td>\n",
       "      <td>0.978395</td>\n",
       "      <td>3591.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>3591</td>\n",
       "      <td>28</td>\n",
       "      <td>634</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.993121</td>\n",
       "      <td>0.996769</td>\n",
       "      <td>0.999446</td>\n",
       "      <td>0.961059</td>\n",
       "      <td>0.996273</td>\n",
       "      <td>0.978588</td>\n",
       "      <td>3611.0</td>\n",
       "      <td>642.0</td>\n",
       "      <td>3609</td>\n",
       "      <td>25</td>\n",
       "      <td>617</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>1</td>\n",
       "      <td>0.992639</td>\n",
       "      <td>0.996587</td>\n",
       "      <td>0.999451</td>\n",
       "      <td>0.955810</td>\n",
       "      <td>0.996033</td>\n",
       "      <td>0.975773</td>\n",
       "      <td>3643.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>3641</td>\n",
       "      <td>27</td>\n",
       "      <td>584</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>2</td>\n",
       "      <td>0.996156</td>\n",
       "      <td>0.993464</td>\n",
       "      <td>0.998899</td>\n",
       "      <td>0.977492</td>\n",
       "      <td>0.997525</td>\n",
       "      <td>0.985413</td>\n",
       "      <td>3632.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>3628</td>\n",
       "      <td>14</td>\n",
       "      <td>608</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>3</td>\n",
       "      <td>0.995310</td>\n",
       "      <td>0.990461</td>\n",
       "      <td>0.998340</td>\n",
       "      <td>0.973437</td>\n",
       "      <td>0.996823</td>\n",
       "      <td>0.981875</td>\n",
       "      <td>3614.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3608</td>\n",
       "      <td>17</td>\n",
       "      <td>623</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>4</td>\n",
       "      <td>0.993664</td>\n",
       "      <td>0.995192</td>\n",
       "      <td>0.999169</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.996409</td>\n",
       "      <td>0.979495</td>\n",
       "      <td>3610.0</td>\n",
       "      <td>644.0</td>\n",
       "      <td>3607</td>\n",
       "      <td>23</td>\n",
       "      <td>621</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>5</td>\n",
       "      <td>0.994490</td>\n",
       "      <td>0.995192</td>\n",
       "      <td>0.999170</td>\n",
       "      <td>0.968799</td>\n",
       "      <td>0.996825</td>\n",
       "      <td>0.981818</td>\n",
       "      <td>3613.0</td>\n",
       "      <td>641.0</td>\n",
       "      <td>3610</td>\n",
       "      <td>20</td>\n",
       "      <td>621</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>6</td>\n",
       "      <td>0.995040</td>\n",
       "      <td>0.996795</td>\n",
       "      <td>0.999446</td>\n",
       "      <td>0.971875</td>\n",
       "      <td>0.997238</td>\n",
       "      <td>0.984177</td>\n",
       "      <td>3613.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3611</td>\n",
       "      <td>18</td>\n",
       "      <td>622</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>7</td>\n",
       "      <td>0.992539</td>\n",
       "      <td>0.998423</td>\n",
       "      <td>0.999722</td>\n",
       "      <td>0.959091</td>\n",
       "      <td>0.996118</td>\n",
       "      <td>0.978362</td>\n",
       "      <td>3593.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3592</td>\n",
       "      <td>27</td>\n",
       "      <td>633</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>8</td>\n",
       "      <td>0.995551</td>\n",
       "      <td>0.995434</td>\n",
       "      <td>0.999163</td>\n",
       "      <td>0.976119</td>\n",
       "      <td>0.997353</td>\n",
       "      <td>0.985682</td>\n",
       "      <td>3583.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>3580</td>\n",
       "      <td>16</td>\n",
       "      <td>654</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>9</td>\n",
       "      <td>0.993904</td>\n",
       "      <td>0.993789</td>\n",
       "      <td>0.998886</td>\n",
       "      <td>0.966767</td>\n",
       "      <td>0.996389</td>\n",
       "      <td>0.980092</td>\n",
       "      <td>3591.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>3587</td>\n",
       "      <td>22</td>\n",
       "      <td>640</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>10</td>\n",
       "      <td>0.994760</td>\n",
       "      <td>0.993620</td>\n",
       "      <td>0.998892</td>\n",
       "      <td>0.970405</td>\n",
       "      <td>0.996822</td>\n",
       "      <td>0.981875</td>\n",
       "      <td>3611.0</td>\n",
       "      <td>642.0</td>\n",
       "      <td>3607</td>\n",
       "      <td>19</td>\n",
       "      <td>623</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>1</td>\n",
       "      <td>0.994251</td>\n",
       "      <td>0.981697</td>\n",
       "      <td>0.996981</td>\n",
       "      <td>0.965630</td>\n",
       "      <td>0.995614</td>\n",
       "      <td>0.973597</td>\n",
       "      <td>3643.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>3632</td>\n",
       "      <td>21</td>\n",
       "      <td>590</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>2</td>\n",
       "      <td>0.996961</td>\n",
       "      <td>0.963722</td>\n",
       "      <td>0.993667</td>\n",
       "      <td>0.982315</td>\n",
       "      <td>0.995312</td>\n",
       "      <td>0.972930</td>\n",
       "      <td>3632.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>3609</td>\n",
       "      <td>11</td>\n",
       "      <td>611</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>3</td>\n",
       "      <td>0.996126</td>\n",
       "      <td>0.978125</td>\n",
       "      <td>0.996126</td>\n",
       "      <td>0.978125</td>\n",
       "      <td>0.996126</td>\n",
       "      <td>0.978125</td>\n",
       "      <td>3614.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3600</td>\n",
       "      <td>14</td>\n",
       "      <td>626</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>4</td>\n",
       "      <td>0.993107</td>\n",
       "      <td>0.987241</td>\n",
       "      <td>0.997784</td>\n",
       "      <td>0.961180</td>\n",
       "      <td>0.995440</td>\n",
       "      <td>0.974036</td>\n",
       "      <td>3610.0</td>\n",
       "      <td>644.0</td>\n",
       "      <td>3602</td>\n",
       "      <td>25</td>\n",
       "      <td>619</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>5</td>\n",
       "      <td>0.995851</td>\n",
       "      <td>0.979656</td>\n",
       "      <td>0.996402</td>\n",
       "      <td>0.976599</td>\n",
       "      <td>0.996126</td>\n",
       "      <td>0.978125</td>\n",
       "      <td>3613.0</td>\n",
       "      <td>641.0</td>\n",
       "      <td>3600</td>\n",
       "      <td>15</td>\n",
       "      <td>626</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>6</td>\n",
       "      <td>0.995583</td>\n",
       "      <td>0.988906</td>\n",
       "      <td>0.998063</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.996821</td>\n",
       "      <td>0.981904</td>\n",
       "      <td>3613.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3606</td>\n",
       "      <td>16</td>\n",
       "      <td>624</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>7</td>\n",
       "      <td>0.994999</td>\n",
       "      <td>0.981651</td>\n",
       "      <td>0.996660</td>\n",
       "      <td>0.972727</td>\n",
       "      <td>0.995829</td>\n",
       "      <td>0.977169</td>\n",
       "      <td>3593.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3581</td>\n",
       "      <td>18</td>\n",
       "      <td>642</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>8</td>\n",
       "      <td>0.994432</td>\n",
       "      <td>0.983359</td>\n",
       "      <td>0.996930</td>\n",
       "      <td>0.970149</td>\n",
       "      <td>0.995679</td>\n",
       "      <td>0.976709</td>\n",
       "      <td>3583.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>3572</td>\n",
       "      <td>20</td>\n",
       "      <td>650</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>9</td>\n",
       "      <td>0.994443</td>\n",
       "      <td>0.981651</td>\n",
       "      <td>0.996658</td>\n",
       "      <td>0.969789</td>\n",
       "      <td>0.995549</td>\n",
       "      <td>0.975684</td>\n",
       "      <td>3591.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>3579</td>\n",
       "      <td>20</td>\n",
       "      <td>642</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>10</td>\n",
       "      <td>0.996132</td>\n",
       "      <td>0.990536</td>\n",
       "      <td>0.998338</td>\n",
       "      <td>0.978193</td>\n",
       "      <td>0.997234</td>\n",
       "      <td>0.984326</td>\n",
       "      <td>3611.0</td>\n",
       "      <td>642.0</td>\n",
       "      <td>3605</td>\n",
       "      <td>14</td>\n",
       "      <td>628</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>1</td>\n",
       "      <td>0.993179</td>\n",
       "      <td>0.994907</td>\n",
       "      <td>0.999177</td>\n",
       "      <td>0.959083</td>\n",
       "      <td>0.996169</td>\n",
       "      <td>0.976667</td>\n",
       "      <td>3643.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>3640</td>\n",
       "      <td>25</td>\n",
       "      <td>586</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>2</td>\n",
       "      <td>0.994515</td>\n",
       "      <td>0.990132</td>\n",
       "      <td>0.998348</td>\n",
       "      <td>0.967846</td>\n",
       "      <td>0.996428</td>\n",
       "      <td>0.978862</td>\n",
       "      <td>3632.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>3626</td>\n",
       "      <td>20</td>\n",
       "      <td>602</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>3</td>\n",
       "      <td>0.995316</td>\n",
       "      <td>0.996800</td>\n",
       "      <td>0.999447</td>\n",
       "      <td>0.973437</td>\n",
       "      <td>0.997377</td>\n",
       "      <td>0.984980</td>\n",
       "      <td>3614.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3612</td>\n",
       "      <td>17</td>\n",
       "      <td>623</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>4</td>\n",
       "      <td>0.992022</td>\n",
       "      <td>0.993538</td>\n",
       "      <td>0.998892</td>\n",
       "      <td>0.954969</td>\n",
       "      <td>0.995445</td>\n",
       "      <td>0.973872</td>\n",
       "      <td>3610.0</td>\n",
       "      <td>644.0</td>\n",
       "      <td>3606</td>\n",
       "      <td>29</td>\n",
       "      <td>615</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>5</td>\n",
       "      <td>0.995860</td>\n",
       "      <td>0.992076</td>\n",
       "      <td>0.998616</td>\n",
       "      <td>0.976599</td>\n",
       "      <td>0.997236</td>\n",
       "      <td>0.984277</td>\n",
       "      <td>3613.0</td>\n",
       "      <td>641.0</td>\n",
       "      <td>3608</td>\n",
       "      <td>15</td>\n",
       "      <td>626</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>6</td>\n",
       "      <td>0.996406</td>\n",
       "      <td>0.985849</td>\n",
       "      <td>0.997509</td>\n",
       "      <td>0.979688</td>\n",
       "      <td>0.996957</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>3613.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3604</td>\n",
       "      <td>13</td>\n",
       "      <td>627</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>7</td>\n",
       "      <td>0.994737</td>\n",
       "      <td>0.996890</td>\n",
       "      <td>0.999443</td>\n",
       "      <td>0.971212</td>\n",
       "      <td>0.997085</td>\n",
       "      <td>0.983883</td>\n",
       "      <td>3593.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3591</td>\n",
       "      <td>19</td>\n",
       "      <td>641</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>8</td>\n",
       "      <td>0.993889</td>\n",
       "      <td>0.992343</td>\n",
       "      <td>0.998605</td>\n",
       "      <td>0.967164</td>\n",
       "      <td>0.996241</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>3583.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>3578</td>\n",
       "      <td>22</td>\n",
       "      <td>648</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>9</td>\n",
       "      <td>0.994454</td>\n",
       "      <td>0.992272</td>\n",
       "      <td>0.998608</td>\n",
       "      <td>0.969789</td>\n",
       "      <td>0.996526</td>\n",
       "      <td>0.980901</td>\n",
       "      <td>3591.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>3586</td>\n",
       "      <td>20</td>\n",
       "      <td>642</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>10</td>\n",
       "      <td>0.995305</td>\n",
       "      <td>0.988924</td>\n",
       "      <td>0.998061</td>\n",
       "      <td>0.973520</td>\n",
       "      <td>0.996681</td>\n",
       "      <td>0.981162</td>\n",
       "      <td>3611.0</td>\n",
       "      <td>642.0</td>\n",
       "      <td>3604</td>\n",
       "      <td>17</td>\n",
       "      <td>625</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>SMOTEENN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.993448</td>\n",
       "      <td>0.993232</td>\n",
       "      <td>0.998902</td>\n",
       "      <td>0.960720</td>\n",
       "      <td>0.996168</td>\n",
       "      <td>0.976705</td>\n",
       "      <td>3643.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>3639</td>\n",
       "      <td>24</td>\n",
       "      <td>587</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>SMOTEENN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.996429</td>\n",
       "      <td>0.991857</td>\n",
       "      <td>0.998623</td>\n",
       "      <td>0.979100</td>\n",
       "      <td>0.997525</td>\n",
       "      <td>0.985437</td>\n",
       "      <td>3632.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>3627</td>\n",
       "      <td>13</td>\n",
       "      <td>609</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>SMOTEENN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.995860</td>\n",
       "      <td>0.990491</td>\n",
       "      <td>0.998340</td>\n",
       "      <td>0.976562</td>\n",
       "      <td>0.997098</td>\n",
       "      <td>0.983478</td>\n",
       "      <td>3614.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3608</td>\n",
       "      <td>15</td>\n",
       "      <td>625</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>SMOTEENN</td>\n",
       "      <td>4</td>\n",
       "      <td>0.993121</td>\n",
       "      <td>0.998387</td>\n",
       "      <td>0.999723</td>\n",
       "      <td>0.961180</td>\n",
       "      <td>0.996411</td>\n",
       "      <td>0.979430</td>\n",
       "      <td>3610.0</td>\n",
       "      <td>644.0</td>\n",
       "      <td>3609</td>\n",
       "      <td>25</td>\n",
       "      <td>619</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>SMOTEENN</td>\n",
       "      <td>5</td>\n",
       "      <td>0.994762</td>\n",
       "      <td>0.992026</td>\n",
       "      <td>0.998616</td>\n",
       "      <td>0.970359</td>\n",
       "      <td>0.996685</td>\n",
       "      <td>0.981073</td>\n",
       "      <td>3613.0</td>\n",
       "      <td>641.0</td>\n",
       "      <td>3608</td>\n",
       "      <td>19</td>\n",
       "      <td>622</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>SMOTEENN</td>\n",
       "      <td>6</td>\n",
       "      <td>0.994486</td>\n",
       "      <td>0.990415</td>\n",
       "      <td>0.998339</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.996409</td>\n",
       "      <td>0.979463</td>\n",
       "      <td>3613.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3607</td>\n",
       "      <td>20</td>\n",
       "      <td>620</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>SMOTEENN</td>\n",
       "      <td>7</td>\n",
       "      <td>0.995562</td>\n",
       "      <td>0.993827</td>\n",
       "      <td>0.998887</td>\n",
       "      <td>0.975758</td>\n",
       "      <td>0.997221</td>\n",
       "      <td>0.984709</td>\n",
       "      <td>3593.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3589</td>\n",
       "      <td>16</td>\n",
       "      <td>644</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>SMOTEENN</td>\n",
       "      <td>8</td>\n",
       "      <td>0.996105</td>\n",
       "      <td>0.995448</td>\n",
       "      <td>0.999163</td>\n",
       "      <td>0.979104</td>\n",
       "      <td>0.997631</td>\n",
       "      <td>0.987208</td>\n",
       "      <td>3583.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>3580</td>\n",
       "      <td>14</td>\n",
       "      <td>656</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>SMOTEENN</td>\n",
       "      <td>9</td>\n",
       "      <td>0.994454</td>\n",
       "      <td>0.992272</td>\n",
       "      <td>0.998608</td>\n",
       "      <td>0.969789</td>\n",
       "      <td>0.996526</td>\n",
       "      <td>0.980901</td>\n",
       "      <td>3591.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>3586</td>\n",
       "      <td>20</td>\n",
       "      <td>642</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>SMOTEENN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.994487</td>\n",
       "      <td>0.995200</td>\n",
       "      <td>0.999169</td>\n",
       "      <td>0.968847</td>\n",
       "      <td>0.996823</td>\n",
       "      <td>0.981847</td>\n",
       "      <td>3611.0</td>\n",
       "      <td>642.0</td>\n",
       "      <td>3608</td>\n",
       "      <td>20</td>\n",
       "      <td>622</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>SMOTETomek</td>\n",
       "      <td>1</td>\n",
       "      <td>0.992912</td>\n",
       "      <td>0.998294</td>\n",
       "      <td>0.999726</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.996307</td>\n",
       "      <td>0.977444</td>\n",
       "      <td>3643.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>3642</td>\n",
       "      <td>26</td>\n",
       "      <td>585</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>SMOTETomek</td>\n",
       "      <td>2</td>\n",
       "      <td>0.995610</td>\n",
       "      <td>0.995074</td>\n",
       "      <td>0.999174</td>\n",
       "      <td>0.974277</td>\n",
       "      <td>0.997389</td>\n",
       "      <td>0.984565</td>\n",
       "      <td>3632.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>3629</td>\n",
       "      <td>16</td>\n",
       "      <td>606</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>SMOTETomek</td>\n",
       "      <td>3</td>\n",
       "      <td>0.994221</td>\n",
       "      <td>0.998387</td>\n",
       "      <td>0.999723</td>\n",
       "      <td>0.967187</td>\n",
       "      <td>0.996965</td>\n",
       "      <td>0.982540</td>\n",
       "      <td>3614.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3613</td>\n",
       "      <td>21</td>\n",
       "      <td>619</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>SMOTETomek</td>\n",
       "      <td>4</td>\n",
       "      <td>0.993117</td>\n",
       "      <td>0.995177</td>\n",
       "      <td>0.999169</td>\n",
       "      <td>0.961180</td>\n",
       "      <td>0.996134</td>\n",
       "      <td>0.977883</td>\n",
       "      <td>3610.0</td>\n",
       "      <td>644.0</td>\n",
       "      <td>3607</td>\n",
       "      <td>25</td>\n",
       "      <td>619</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>SMOTETomek</td>\n",
       "      <td>5</td>\n",
       "      <td>0.995590</td>\n",
       "      <td>0.998403</td>\n",
       "      <td>0.999723</td>\n",
       "      <td>0.975039</td>\n",
       "      <td>0.997652</td>\n",
       "      <td>0.986582</td>\n",
       "      <td>3613.0</td>\n",
       "      <td>641.0</td>\n",
       "      <td>3612</td>\n",
       "      <td>16</td>\n",
       "      <td>625</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>SMOTETomek</td>\n",
       "      <td>6</td>\n",
       "      <td>0.995041</td>\n",
       "      <td>0.998395</td>\n",
       "      <td>0.999723</td>\n",
       "      <td>0.971875</td>\n",
       "      <td>0.997377</td>\n",
       "      <td>0.984956</td>\n",
       "      <td>3613.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3612</td>\n",
       "      <td>18</td>\n",
       "      <td>622</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>SMOTETomek</td>\n",
       "      <td>7</td>\n",
       "      <td>0.992814</td>\n",
       "      <td>0.998425</td>\n",
       "      <td>0.999722</td>\n",
       "      <td>0.960606</td>\n",
       "      <td>0.996256</td>\n",
       "      <td>0.979151</td>\n",
       "      <td>3593.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3592</td>\n",
       "      <td>26</td>\n",
       "      <td>634</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>SMOTETomek</td>\n",
       "      <td>8</td>\n",
       "      <td>0.996105</td>\n",
       "      <td>0.995448</td>\n",
       "      <td>0.999163</td>\n",
       "      <td>0.979104</td>\n",
       "      <td>0.997631</td>\n",
       "      <td>0.987208</td>\n",
       "      <td>3583.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>3580</td>\n",
       "      <td>14</td>\n",
       "      <td>656</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>SMOTETomek</td>\n",
       "      <td>9</td>\n",
       "      <td>0.993908</td>\n",
       "      <td>0.996885</td>\n",
       "      <td>0.999443</td>\n",
       "      <td>0.966767</td>\n",
       "      <td>0.996668</td>\n",
       "      <td>0.981595</td>\n",
       "      <td>3591.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>3589</td>\n",
       "      <td>22</td>\n",
       "      <td>640</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>DF5</td>\n",
       "      <td>BaggedTreeClassifier</td>\n",
       "      <td>SMOTETomek</td>\n",
       "      <td>10</td>\n",
       "      <td>0.995036</td>\n",
       "      <td>0.995215</td>\n",
       "      <td>0.999169</td>\n",
       "      <td>0.971963</td>\n",
       "      <td>0.997098</td>\n",
       "      <td>0.983452</td>\n",
       "      <td>3611.0</td>\n",
       "      <td>642.0</td>\n",
       "      <td>3608</td>\n",
       "      <td>18</td>\n",
       "      <td>624</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset                 model data balancing technique  fold  precision_1  \\\n",
       "0      DF5  BaggedTreeClassifier                     None     1     0.992366   \n",
       "1      DF5  BaggedTreeClassifier                     None     2     0.994250   \n",
       "2      DF5  BaggedTreeClassifier                     None     3     0.993674   \n",
       "3      DF5  BaggedTreeClassifier                     None     4     0.989575   \n",
       "4      DF5  BaggedTreeClassifier                     None     5     0.992572   \n",
       "5      DF5  BaggedTreeClassifier                     None     6     0.992853   \n",
       "6      DF5  BaggedTreeClassifier                     None     7     0.991715   \n",
       "7      DF5  BaggedTreeClassifier                     None     8     0.992792   \n",
       "8      DF5  BaggedTreeClassifier                     None     9     0.992263   \n",
       "9      DF5  BaggedTreeClassifier                     None    10     0.993121   \n",
       "10     DF5  BaggedTreeClassifier                    SMOTE     1     0.992639   \n",
       "11     DF5  BaggedTreeClassifier                    SMOTE     2     0.996156   \n",
       "12     DF5  BaggedTreeClassifier                    SMOTE     3     0.995310   \n",
       "13     DF5  BaggedTreeClassifier                    SMOTE     4     0.993664   \n",
       "14     DF5  BaggedTreeClassifier                    SMOTE     5     0.994490   \n",
       "15     DF5  BaggedTreeClassifier                    SMOTE     6     0.995040   \n",
       "16     DF5  BaggedTreeClassifier                    SMOTE     7     0.992539   \n",
       "17     DF5  BaggedTreeClassifier                    SMOTE     8     0.995551   \n",
       "18     DF5  BaggedTreeClassifier                    SMOTE     9     0.993904   \n",
       "19     DF5  BaggedTreeClassifier                    SMOTE    10     0.994760   \n",
       "20     DF5  BaggedTreeClassifier     Random Under Sampler     1     0.994251   \n",
       "21     DF5  BaggedTreeClassifier     Random Under Sampler     2     0.996961   \n",
       "22     DF5  BaggedTreeClassifier     Random Under Sampler     3     0.996126   \n",
       "23     DF5  BaggedTreeClassifier     Random Under Sampler     4     0.993107   \n",
       "24     DF5  BaggedTreeClassifier     Random Under Sampler     5     0.995851   \n",
       "25     DF5  BaggedTreeClassifier     Random Under Sampler     6     0.995583   \n",
       "26     DF5  BaggedTreeClassifier     Random Under Sampler     7     0.994999   \n",
       "27     DF5  BaggedTreeClassifier     Random Under Sampler     8     0.994432   \n",
       "28     DF5  BaggedTreeClassifier     Random Under Sampler     9     0.994443   \n",
       "29     DF5  BaggedTreeClassifier     Random Under Sampler    10     0.996132   \n",
       "30     DF5  BaggedTreeClassifier      Random Over Sampler     1     0.993179   \n",
       "31     DF5  BaggedTreeClassifier      Random Over Sampler     2     0.994515   \n",
       "32     DF5  BaggedTreeClassifier      Random Over Sampler     3     0.995316   \n",
       "33     DF5  BaggedTreeClassifier      Random Over Sampler     4     0.992022   \n",
       "34     DF5  BaggedTreeClassifier      Random Over Sampler     5     0.995860   \n",
       "35     DF5  BaggedTreeClassifier      Random Over Sampler     6     0.996406   \n",
       "36     DF5  BaggedTreeClassifier      Random Over Sampler     7     0.994737   \n",
       "37     DF5  BaggedTreeClassifier      Random Over Sampler     8     0.993889   \n",
       "38     DF5  BaggedTreeClassifier      Random Over Sampler     9     0.994454   \n",
       "39     DF5  BaggedTreeClassifier      Random Over Sampler    10     0.995305   \n",
       "40     DF5  BaggedTreeClassifier                 SMOTEENN     1     0.993448   \n",
       "41     DF5  BaggedTreeClassifier                 SMOTEENN     2     0.996429   \n",
       "42     DF5  BaggedTreeClassifier                 SMOTEENN     3     0.995860   \n",
       "43     DF5  BaggedTreeClassifier                 SMOTEENN     4     0.993121   \n",
       "44     DF5  BaggedTreeClassifier                 SMOTEENN     5     0.994762   \n",
       "45     DF5  BaggedTreeClassifier                 SMOTEENN     6     0.994486   \n",
       "46     DF5  BaggedTreeClassifier                 SMOTEENN     7     0.995562   \n",
       "47     DF5  BaggedTreeClassifier                 SMOTEENN     8     0.996105   \n",
       "48     DF5  BaggedTreeClassifier                 SMOTEENN     9     0.994454   \n",
       "49     DF5  BaggedTreeClassifier                 SMOTEENN    10     0.994487   \n",
       "50     DF5  BaggedTreeClassifier               SMOTETomek     1     0.992912   \n",
       "51     DF5  BaggedTreeClassifier               SMOTETomek     2     0.995610   \n",
       "52     DF5  BaggedTreeClassifier               SMOTETomek     3     0.994221   \n",
       "53     DF5  BaggedTreeClassifier               SMOTETomek     4     0.993117   \n",
       "54     DF5  BaggedTreeClassifier               SMOTETomek     5     0.995590   \n",
       "55     DF5  BaggedTreeClassifier               SMOTETomek     6     0.995041   \n",
       "56     DF5  BaggedTreeClassifier               SMOTETomek     7     0.992814   \n",
       "57     DF5  BaggedTreeClassifier               SMOTETomek     8     0.996105   \n",
       "58     DF5  BaggedTreeClassifier               SMOTETomek     9     0.993908   \n",
       "59     DF5  BaggedTreeClassifier               SMOTETomek    10     0.995036   \n",
       "\n",
       "    precision_2  recall_1  recall_2  f1-score_1  f1-score_2  support_1  \\\n",
       "0      0.994881  0.999177  0.954173    0.995760    0.974102     3643.0   \n",
       "1      0.998339  0.999725  0.966238    0.996980    0.982026     3632.0   \n",
       "2      0.998382  0.999723  0.964063    0.996690    0.980922     3614.0   \n",
       "3      0.995074  0.999169  0.940994    0.994349    0.967279     3610.0   \n",
       "4      0.991922  0.998616  0.957878    0.995585    0.974603     3613.0   \n",
       "5      0.998374  0.999723  0.959375    0.996276    0.978486     3613.0   \n",
       "6      0.996835  0.999443  0.954545    0.995564    0.975232     3593.0   \n",
       "7      0.996904  0.999442  0.961194    0.996106    0.978723     3583.0   \n",
       "8      1.000000  1.000000  0.957704    0.996117    0.978395     3591.0   \n",
       "9      0.996769  0.999446  0.961059    0.996273    0.978588     3611.0   \n",
       "10     0.996587  0.999451  0.955810    0.996033    0.975773     3643.0   \n",
       "11     0.993464  0.998899  0.977492    0.997525    0.985413     3632.0   \n",
       "12     0.990461  0.998340  0.973437    0.996823    0.981875     3614.0   \n",
       "13     0.995192  0.999169  0.964286    0.996409    0.979495     3610.0   \n",
       "14     0.995192  0.999170  0.968799    0.996825    0.981818     3613.0   \n",
       "15     0.996795  0.999446  0.971875    0.997238    0.984177     3613.0   \n",
       "16     0.998423  0.999722  0.959091    0.996118    0.978362     3593.0   \n",
       "17     0.995434  0.999163  0.976119    0.997353    0.985682     3583.0   \n",
       "18     0.993789  0.998886  0.966767    0.996389    0.980092     3591.0   \n",
       "19     0.993620  0.998892  0.970405    0.996822    0.981875     3611.0   \n",
       "20     0.981697  0.996981  0.965630    0.995614    0.973597     3643.0   \n",
       "21     0.963722  0.993667  0.982315    0.995312    0.972930     3632.0   \n",
       "22     0.978125  0.996126  0.978125    0.996126    0.978125     3614.0   \n",
       "23     0.987241  0.997784  0.961180    0.995440    0.974036     3610.0   \n",
       "24     0.979656  0.996402  0.976599    0.996126    0.978125     3613.0   \n",
       "25     0.988906  0.998063  0.975000    0.996821    0.981904     3613.0   \n",
       "26     0.981651  0.996660  0.972727    0.995829    0.977169     3593.0   \n",
       "27     0.983359  0.996930  0.970149    0.995679    0.976709     3583.0   \n",
       "28     0.981651  0.996658  0.969789    0.995549    0.975684     3591.0   \n",
       "29     0.990536  0.998338  0.978193    0.997234    0.984326     3611.0   \n",
       "30     0.994907  0.999177  0.959083    0.996169    0.976667     3643.0   \n",
       "31     0.990132  0.998348  0.967846    0.996428    0.978862     3632.0   \n",
       "32     0.996800  0.999447  0.973437    0.997377    0.984980     3614.0   \n",
       "33     0.993538  0.998892  0.954969    0.995445    0.973872     3610.0   \n",
       "34     0.992076  0.998616  0.976599    0.997236    0.984277     3613.0   \n",
       "35     0.985849  0.997509  0.979688    0.996957    0.982759     3613.0   \n",
       "36     0.996890  0.999443  0.971212    0.997085    0.983883     3593.0   \n",
       "37     0.992343  0.998605  0.967164    0.996241    0.979592     3583.0   \n",
       "38     0.992272  0.998608  0.969789    0.996526    0.980901     3591.0   \n",
       "39     0.988924  0.998061  0.973520    0.996681    0.981162     3611.0   \n",
       "40     0.993232  0.998902  0.960720    0.996168    0.976705     3643.0   \n",
       "41     0.991857  0.998623  0.979100    0.997525    0.985437     3632.0   \n",
       "42     0.990491  0.998340  0.976562    0.997098    0.983478     3614.0   \n",
       "43     0.998387  0.999723  0.961180    0.996411    0.979430     3610.0   \n",
       "44     0.992026  0.998616  0.970359    0.996685    0.981073     3613.0   \n",
       "45     0.990415  0.998339  0.968750    0.996409    0.979463     3613.0   \n",
       "46     0.993827  0.998887  0.975758    0.997221    0.984709     3593.0   \n",
       "47     0.995448  0.999163  0.979104    0.997631    0.987208     3583.0   \n",
       "48     0.992272  0.998608  0.969789    0.996526    0.980901     3591.0   \n",
       "49     0.995200  0.999169  0.968847    0.996823    0.981847     3611.0   \n",
       "50     0.998294  0.999726  0.957447    0.996307    0.977444     3643.0   \n",
       "51     0.995074  0.999174  0.974277    0.997389    0.984565     3632.0   \n",
       "52     0.998387  0.999723  0.967187    0.996965    0.982540     3614.0   \n",
       "53     0.995177  0.999169  0.961180    0.996134    0.977883     3610.0   \n",
       "54     0.998403  0.999723  0.975039    0.997652    0.986582     3613.0   \n",
       "55     0.998395  0.999723  0.971875    0.997377    0.984956     3613.0   \n",
       "56     0.998425  0.999722  0.960606    0.996256    0.979151     3593.0   \n",
       "57     0.995448  0.999163  0.979104    0.997631    0.987208     3583.0   \n",
       "58     0.996885  0.999443  0.966767    0.996668    0.981595     3591.0   \n",
       "59     0.995215  0.999169  0.971963    0.997098    0.983452     3611.0   \n",
       "\n",
       "    support_2    TP  FP   TN  FN  \n",
       "0       611.0  3640  28  583   3  \n",
       "1       622.0  3631  21  601   1  \n",
       "2       640.0  3613  23  617   1  \n",
       "3       644.0  3607  38  606   3  \n",
       "4       641.0  3608  27  614   5  \n",
       "5       640.0  3612  26  614   1  \n",
       "6       660.0  3591  30  630   2  \n",
       "7       670.0  3581  26  644   2  \n",
       "8       662.0  3591  28  634   0  \n",
       "9       642.0  3609  25  617   2  \n",
       "10      611.0  3641  27  584   2  \n",
       "11      622.0  3628  14  608   4  \n",
       "12      640.0  3608  17  623   6  \n",
       "13      644.0  3607  23  621   3  \n",
       "14      641.0  3610  20  621   3  \n",
       "15      640.0  3611  18  622   2  \n",
       "16      660.0  3592  27  633   1  \n",
       "17      670.0  3580  16  654   3  \n",
       "18      662.0  3587  22  640   4  \n",
       "19      642.0  3607  19  623   4  \n",
       "20      611.0  3632  21  590  11  \n",
       "21      622.0  3609  11  611  23  \n",
       "22      640.0  3600  14  626  14  \n",
       "23      644.0  3602  25  619   8  \n",
       "24      641.0  3600  15  626  13  \n",
       "25      640.0  3606  16  624   7  \n",
       "26      660.0  3581  18  642  12  \n",
       "27      670.0  3572  20  650  11  \n",
       "28      662.0  3579  20  642  12  \n",
       "29      642.0  3605  14  628   6  \n",
       "30      611.0  3640  25  586   3  \n",
       "31      622.0  3626  20  602   6  \n",
       "32      640.0  3612  17  623   2  \n",
       "33      644.0  3606  29  615   4  \n",
       "34      641.0  3608  15  626   5  \n",
       "35      640.0  3604  13  627   9  \n",
       "36      660.0  3591  19  641   2  \n",
       "37      670.0  3578  22  648   5  \n",
       "38      662.0  3586  20  642   5  \n",
       "39      642.0  3604  17  625   7  \n",
       "40      611.0  3639  24  587   4  \n",
       "41      622.0  3627  13  609   5  \n",
       "42      640.0  3608  15  625   6  \n",
       "43      644.0  3609  25  619   1  \n",
       "44      641.0  3608  19  622   5  \n",
       "45      640.0  3607  20  620   6  \n",
       "46      660.0  3589  16  644   4  \n",
       "47      670.0  3580  14  656   3  \n",
       "48      662.0  3586  20  642   5  \n",
       "49      642.0  3608  20  622   3  \n",
       "50      611.0  3642  26  585   1  \n",
       "51      622.0  3629  16  606   3  \n",
       "52      640.0  3613  21  619   1  \n",
       "53      644.0  3607  25  619   3  \n",
       "54      641.0  3612  16  625   1  \n",
       "55      640.0  3612  18  622   1  \n",
       "56      660.0  3592  26  634   1  \n",
       "57      670.0  3580  14  656   3  \n",
       "58      662.0  3589  22  640   2  \n",
       "59      642.0  3608  18  624   3  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "16a4e44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame\n",
    "combined_metrics.to_csv('Output Data/BaggedTreeClassifier.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed15f083",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
