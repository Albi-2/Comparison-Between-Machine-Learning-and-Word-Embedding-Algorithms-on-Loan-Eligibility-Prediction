{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d2c91a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f460afa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "import numpy as np\n",
    "from pprint import pprint as pp\n",
    "import csv\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "from itertools import product\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from imblearn.pipeline import Pipeline \n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import r2_score, classification_report, confusion_matrix, accuracy_score, roc_auc_score, roc_curve, precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import homogeneity_score, silhouette_score\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import MiniBatchKMeans, DBSCAN\n",
    "import fasttext\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17e9cee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, precision_score, recall_score, f1_score, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87969209",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import FastText\n",
    "import numpy as np\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6238cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, precision_score, recall_score, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75e8fc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.combine import SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "378df2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0db62d0",
   "metadata": {},
   "source": [
    "### Retrieving the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10513ea6",
   "metadata": {},
   "source": [
    "#### DF 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc3d2069",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df7 = pd.read_csv('df7.csv')\n",
    "df7a = pd.read_csv('df7a.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82ed7cb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_balance</th>\n",
       "      <th>duration</th>\n",
       "      <th>credit_history</th>\n",
       "      <th>purpose</th>\n",
       "      <th>credit_amount</th>\n",
       "      <th>savings_bond_value</th>\n",
       "      <th>employed_since</th>\n",
       "      <th>intallment_rate</th>\n",
       "      <th>sex_marital</th>\n",
       "      <th>guarantor</th>\n",
       "      <th>residence_since</th>\n",
       "      <th>property</th>\n",
       "      <th>age</th>\n",
       "      <th>other_installment_plans</th>\n",
       "      <th>type_of_housing</th>\n",
       "      <th>nr_of_existing_credits</th>\n",
       "      <th>job</th>\n",
       "      <th>number_of_dependents</th>\n",
       "      <th>telephone</th>\n",
       "      <th>foreign</th>\n",
       "      <th>target</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt; 0</td>\n",
       "      <td>6</td>\n",
       "      <td>critical account/other credits existing (not a...</td>\n",
       "      <td>radio/television</td>\n",
       "      <td>1169</td>\n",
       "      <td>unknown/no savings account</td>\n",
       "      <td>&gt;=7 years</td>\n",
       "      <td>4</td>\n",
       "      <td>male;single</td>\n",
       "      <td>bank</td>\n",
       "      <td>4</td>\n",
       "      <td>real estate</td>\n",
       "      <td>67</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>2</td>\n",
       "      <td>skilled employee;official</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>__label__1</td>\n",
       "      <td>__label__1 &lt; 0 6 critical account/other credit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0-200 DM</td>\n",
       "      <td>48</td>\n",
       "      <td>existing credits paid back duly till now</td>\n",
       "      <td>radio/television</td>\n",
       "      <td>5951</td>\n",
       "      <td>&lt; 100 DM</td>\n",
       "      <td>1-4 years</td>\n",
       "      <td>2</td>\n",
       "      <td>female;divorced/separated/married</td>\n",
       "      <td>bank</td>\n",
       "      <td>2</td>\n",
       "      <td>real estate</td>\n",
       "      <td>22</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>1</td>\n",
       "      <td>skilled employee;official</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>__label__2</td>\n",
       "      <td>__label__2 0-200 DM 48 existing credits paid b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  account_balance  duration  \\\n",
       "0             < 0         6   \n",
       "1        0-200 DM        48   \n",
       "\n",
       "                                      credit_history           purpose  \\\n",
       "0  critical account/other credits existing (not a...  radio/television   \n",
       "1           existing credits paid back duly till now  radio/television   \n",
       "\n",
       "   credit_amount          savings_bond_value employed_since  intallment_rate  \\\n",
       "0           1169  unknown/no savings account      >=7 years                4   \n",
       "1           5951                    < 100 DM      1-4 years                2   \n",
       "\n",
       "                         sex_marital guarantor  residence_since     property  \\\n",
       "0                        male;single      bank                4  real estate   \n",
       "1  female;divorced/separated/married      bank                2  real estate   \n",
       "\n",
       "   age other_installment_plans type_of_housing  nr_of_existing_credits  \\\n",
       "0   67                    none             own                       2   \n",
       "1   22                    none             own                       1   \n",
       "\n",
       "                         job  number_of_dependents telephone foreign  \\\n",
       "0  skilled employee;official                     1       Yes     Yes   \n",
       "1  skilled employee;official                     1        No     Yes   \n",
       "\n",
       "       target                                            content  \n",
       "0  __label__1  __label__1 < 0 6 critical account/other credit...  \n",
       "1  __label__2  __label__2 0-200 DM 48 existing credits paid b...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df7a.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f9963f",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee0a55ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store evaluation metrics for each fold\n",
    "dataset_used = []\n",
    "model_used = []\n",
    "data_balancing_technique = []\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "conf_matrices = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "903b5377",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combined_metrics = pd.DataFrame()\n",
    "\n",
    "combined_metrics = pd.DataFrame(columns=['dataset', 'model', 'data balancing technique', 'fold', 'precision_1','precision_2','recall_1','recall_2','f1-score_1','f1-score_2','support_1','support_2','TP','FP','TN','FN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052cda7c",
   "metadata": {},
   "source": [
    "# Fast Text \n",
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedf6e11",
   "metadata": {},
   "source": [
    "## DF7a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89f99b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.71\n",
      "Mean Precision: 0.70\n",
      "Mean Recall: 0.71\n",
      "Mean F1-Score: 0.70\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df7' is your DataFrame with features and the target column\n",
    "features = df7a['content'].apply(lambda x: x.split(' ', 1)[1])  # Drop the target column to get the feature columns\n",
    "target = df7a['target'].apply(lambda x: int(x.split(\"__label__\")[1]))  # Target column to predict\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = ''.join([word for word in text if word not in string.punctuation])\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Initialize KFold with 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    X_train = X_train.apply(preprocess)\n",
    "    X_test = X_test.apply(preprocess)\n",
    "\n",
    "    sentences = [sentence.split() for sentence in X_train]\n",
    "    \n",
    "    # Train the FastText model\n",
    "    fasttext_model = FastText(sentences, vector_size=100, window=20, min_count=2, workers=4, seed=42)\n",
    "    \n",
    "    def vectorize(sentence):\n",
    "        words = sentence.split()\n",
    "        words_vecs = [fasttext_model.wv[word] for word in words if word in fasttext_model.wv]\n",
    "        if len(words_vecs) == 0:\n",
    "            return np.zeros(100)\n",
    "        words_vecs = np.array(words_vecs)\n",
    "        return words_vecs.mean(axis=0)\n",
    "\n",
    "    X_train = np.array([vectorize(sentence) for sentence in X_train])\n",
    "    X_test = np.array([vectorize(sentence) for sentence in X_test])\n",
    "    \n",
    "    #clf = LogisticRegression()\n",
    "    clf = LinearRegression()\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    y_pred = np.round(y_pred)\n",
    "    \n",
    "    y_pred[y_pred <= 0] = 1\n",
    "    y_pred[y_pred >= 2] = 2\n",
    "    \n",
    "    # Model evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred.round())\n",
    "    precision = precision_score(y_test, y_pred.round(), average='weighted')\n",
    "    recall = recall_score(y_test, y_pred.round(), average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred.round(), average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred.round())\n",
    "    \n",
    "    \n",
    "    # Convert classification report to DataFrame\n",
    "    report_df = pd.DataFrame(classification_report(y_test, y_pred.round(), output_dict=True)).transpose()\n",
    "    # Convert confusion matrix to DataFrame\n",
    "    matrix_df = pd.DataFrame(confusion_matrix(y_test, y_pred.round()))\n",
    "    \n",
    "    # Extract metrics for class 1\n",
    "    metrics_1 = report_df.loc['1', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract metrics for class 2\n",
    "    metrics_2 = report_df.loc['2', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract TP, TN, FP, FN counts from the confusion matrix DataFrame\n",
    "    TP = matrix_df.loc[0, 0]\n",
    "    TN = matrix_df.loc[1, 1]\n",
    "    FP = matrix_df.loc[1, 0]\n",
    "    FN = matrix_df.loc[0, 1]\n",
    "    \n",
    "    new_metric_row = {\n",
    "    'dataset': 'DF7a',\n",
    "    'model' : 'Fast Text - Linear Regression',\n",
    "    'data balancing technique' : 'None',\n",
    "    'fold' : i,\n",
    "    'precision_1': metrics_1['precision'],\n",
    "    'precision_2': metrics_2['precision'],\n",
    "    'recall_1': metrics_1['recall'],\n",
    "    'recall_2': metrics_2['recall'],\n",
    "    'f1-score_1': metrics_1['f1-score'],\n",
    "    'f1-score_2': metrics_2['f1-score'],\n",
    "    'support_1': metrics_1['support'],\n",
    "    'support_2': metrics_2['support'],\n",
    "    'TP' : TP,\n",
    "    'FP' : FP,\n",
    "    'TN' : TN,\n",
    "    'FN' : FN\n",
    "    }\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    #combined_metrics = combined_metrics.append(new_metric_row, ignore_index=True)\n",
    "    combined_metrics.loc[len(combined_metrics)] = new_metric_row\n",
    "    \n",
    "    \n",
    "    # Append evaluation metrics to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "\n",
    "# Calculate mean evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores) #sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = np.mean(precision_scores) #sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = np.mean(recall_scores) #sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = np.mean(f1_scores) #sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print('Mean Accuracy: {:.2f}'.format(mean_accuracy))\n",
    "print('Mean Precision: {:.2f}'.format(mean_precision))\n",
    "print('Mean Recall: {:.2f}'.format(mean_recall))\n",
    "print('Mean F1-Score: {:.2f}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5cd58d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>data balancing technique</th>\n",
       "      <th>fold</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_2</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>f1-score_1</th>\n",
       "      <th>f1-score_2</th>\n",
       "      <th>support_1</th>\n",
       "      <th>support_2</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DF7a</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0.773333</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.816901</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.794521</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>71.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>58</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DF7a</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>70.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>60</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DF7a</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>0.743590</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.794521</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>68.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>58</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DF7a</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>0.797468</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.863014</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.828947</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>73.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>63</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DF7a</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.845070</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>71.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>60</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DF7a</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>0.697368</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>0.768116</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>62.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>53</td>\n",
       "      <td>23</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DF7a</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>7</td>\n",
       "      <td>0.783133</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>77.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>65</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DF7a</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>8</td>\n",
       "      <td>0.783133</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.955882</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.860927</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>68.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>65</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DF7a</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>9</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.425532</td>\n",
       "      <td>75.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>63</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DF7a</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.830769</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>65.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>54</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset                          model data balancing technique  fold  \\\n",
       "0    DF7a  Fast Text - Linear Regression                     None     1   \n",
       "1    DF7a  Fast Text - Linear Regression                     None     2   \n",
       "2    DF7a  Fast Text - Linear Regression                     None     3   \n",
       "3    DF7a  Fast Text - Linear Regression                     None     4   \n",
       "4    DF7a  Fast Text - Linear Regression                     None     5   \n",
       "5    DF7a  Fast Text - Linear Regression                     None     6   \n",
       "6    DF7a  Fast Text - Linear Regression                     None     7   \n",
       "7    DF7a  Fast Text - Linear Regression                     None     8   \n",
       "8    DF7a  Fast Text - Linear Regression                     None     9   \n",
       "9    DF7a  Fast Text - Linear Regression                     None    10   \n",
       "\n",
       "   precision_1  precision_2  recall_1  recall_2  f1-score_1  f1-score_2  \\\n",
       "0     0.773333     0.480000  0.816901  0.413793    0.794521    0.444444   \n",
       "1     0.769231     0.545455  0.857143  0.400000    0.810811    0.461538   \n",
       "2     0.743590     0.545455  0.852941  0.375000    0.794521    0.444444   \n",
       "3     0.797468     0.523810  0.863014  0.407407    0.828947    0.458333   \n",
       "4     0.740741     0.421053  0.845070  0.275862    0.789474    0.333333   \n",
       "5     0.697368     0.625000  0.854839  0.394737    0.768116    0.483871   \n",
       "6     0.783133     0.294118  0.844156  0.217391    0.812500    0.250000   \n",
       "7     0.783133     0.823529  0.955882  0.437500    0.860927    0.571429   \n",
       "8     0.807692     0.454545  0.840000  0.400000    0.823529    0.425532   \n",
       "9     0.720000     0.560000  0.830769  0.400000    0.771429    0.466667   \n",
       "\n",
       "   support_1  support_2  TP  FP  TN  FN  \n",
       "0       71.0       29.0  58  17  12  13  \n",
       "1       70.0       30.0  60  18  12  10  \n",
       "2       68.0       32.0  58  20  12  10  \n",
       "3       73.0       27.0  63  16  11  10  \n",
       "4       71.0       29.0  60  21   8  11  \n",
       "5       62.0       38.0  53  23  15   9  \n",
       "6       77.0       23.0  65  18   5  12  \n",
       "7       68.0       32.0  65  18  14   3  \n",
       "8       75.0       25.0  63  15  10  12  \n",
       "9       65.0       35.0  54  21  14  11  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_metrics[(combined_metrics['data balancing technique'] == 'None') & (combined_metrics['dataset'] == 'DF7a')]#.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737bdf77",
   "metadata": {},
   "source": [
    "### FastText Linear Regression with df7a data and imbalance data tackling (RandomUnderSampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21b575ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.69\n",
      "Mean Precision: 0.68\n",
      "Mean Recall: 0.69\n",
      "Mean F1-Score: 0.68\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df7' is your DataFrame with features and the target column\n",
    "features = df7a['content'].apply(lambda x: x.split(' ', 1)[1])  # Drop the target column to get the feature columns\n",
    "target = df7a['target'].apply(lambda x: int(x.split(\"__label__\")[1]))  # Target column to predict\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = ''.join([word for word in text if word not in string.punctuation])\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Initialize KFold with 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    X_train = X_train.apply(preprocess)\n",
    "    X_test = X_test.apply(preprocess)\n",
    "\n",
    "    sentences = [sentence.split() for sentence in X_train]\n",
    "    \n",
    "    # Train the FastText model\n",
    "    fasttext_model = FastText(sentences, vector_size=100, window=20, min_count=2, workers=4, seed=42)\n",
    "    \n",
    "    def vectorize(sentence):\n",
    "        words = sentence.split()\n",
    "        words_vecs = [fasttext_model.wv[word] for word in words if word in fasttext_model.wv]\n",
    "        if len(words_vecs) == 0:\n",
    "            return np.zeros(100)\n",
    "        words_vecs = np.array(words_vecs)\n",
    "        return words_vecs.mean(axis=0)\n",
    "\n",
    "    X_train = np.array([vectorize(sentence) for sentence in X_train])\n",
    "    X_test = np.array([vectorize(sentence) for sentence in X_test])\n",
    "    \n",
    "    # Apply random undersampling\n",
    "    rus = RandomUnderSampler(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)\n",
    "    \n",
    "    #clf = LogisticRegression()\n",
    "    clf = LinearRegression()\n",
    "    clf.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Apply random undersampling to test data\n",
    "    X_test_resampled, y_test_resampled = rus.fit_resample(X_test, y_test)\n",
    "    \n",
    "    y_pred = clf.predict(X_test_resampled)\n",
    "    \n",
    "    y_pred = np.round(y_pred)\n",
    "    \n",
    "    y_pred[y_pred <= 0] = 1\n",
    "    y_pred[y_pred >= 2] = 2\n",
    "    \n",
    "    # Model evaluation\n",
    "    accuracy = accuracy_score(y_test_resampled, y_pred.round())\n",
    "    precision = precision_score(y_test_resampled, y_pred.round(), average='weighted')\n",
    "    recall = recall_score(y_test_resampled, y_pred.round(), average='weighted')\n",
    "    f1 = f1_score(y_test_resampled, y_pred.round(), average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test_resampled, y_pred.round())\n",
    "    \n",
    "    # Convert classification report to DataFrame\n",
    "    report_df = pd.DataFrame(classification_report(y_test_resampled, y_pred.round(), output_dict=True)).transpose()\n",
    "    # Convert confusion matrix to DataFrame\n",
    "    matrix_df = pd.DataFrame(confusion_matrix(y_test_resampled, y_pred.round()))\n",
    "    \n",
    "    # Extract metrics for class 1\n",
    "    metrics_1 = report_df.loc['1', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract metrics for class 2\n",
    "    metrics_2 = report_df.loc['2', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract TP, TN, FP, FN counts from the confusion matrix DataFrame\n",
    "    TP = matrix_df.loc[0, 0]\n",
    "    TN = matrix_df.loc[1, 1]\n",
    "    FP = matrix_df.loc[1, 0]\n",
    "    FN = matrix_df.loc[0, 1]\n",
    "    \n",
    "    new_metric_row = {\n",
    "    'dataset': 'DF7a',\n",
    "    'model' : 'Fast Text - Linear Regression',\n",
    "    'data balancing technique' : 'Random Under Sampler',\n",
    "    'fold' : i,\n",
    "    'precision_1': metrics_1['precision'],\n",
    "    'precision_2': metrics_2['precision'],\n",
    "    'recall_1': metrics_1['recall'],\n",
    "    'recall_2': metrics_2['recall'],\n",
    "    'f1-score_1': metrics_1['f1-score'],\n",
    "    'f1-score_2': metrics_2['f1-score'],\n",
    "    'support_1': metrics_1['support'],\n",
    "    'support_2': metrics_2['support'],\n",
    "    'TP' : TP,\n",
    "    'FP' : FP,\n",
    "    'TN' : TN,\n",
    "    'FN' : FN\n",
    "    }\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    #combined_metrics = combined_metrics.append(new_metric_row, ignore_index=True)\n",
    "    combined_metrics.loc[len(combined_metrics)] = new_metric_row\n",
    "    \n",
    "    \n",
    "    # Append evaluation metrics to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "\n",
    "# Calculate mean evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores) #sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = np.mean(precision_scores) #sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = np.mean(recall_scores) #sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = np.mean(f1_scores) #sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print('Mean Accuracy: {:.2f}'.format(mean_accuracy))\n",
    "print('Mean Precision: {:.2f}'.format(mean_precision))\n",
    "print('Mean Recall: {:.2f}'.format(mean_recall))\n",
    "print('Mean F1-Score: {:.2f}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f08b12d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>data balancing technique</th>\n",
       "      <th>fold</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_2</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>f1-score_1</th>\n",
       "      <th>f1-score_2</th>\n",
       "      <th>support_1</th>\n",
       "      <th>support_2</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DF7a</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>1</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>29.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DF7a</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>2</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.634921</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset                          model data balancing technique  fold  \\\n",
       "10    DF7a  Fast Text - Linear Regression     Random Under Sampler     1   \n",
       "11    DF7a  Fast Text - Linear Regression     Random Under Sampler     2   \n",
       "\n",
       "    precision_1  precision_2  recall_1  recall_2  f1-score_1  f1-score_2  \\\n",
       "10     0.724138     0.724138  0.724138  0.724138    0.724138    0.724138   \n",
       "11     0.629630     0.606061  0.566667  0.666667    0.596491    0.634921   \n",
       "\n",
       "    support_1  support_2  TP  FP  TN  FN  \n",
       "10       29.0       29.0  21   8  21   8  \n",
       "11       30.0       30.0  17  10  20  13  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_metrics[(combined_metrics['data balancing technique'] == 'Random Under Sampler') & (combined_metrics['dataset'] == 'DF7a')].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc10646",
   "metadata": {},
   "source": [
    "### FastText Linear Regression with df7a data and imbalance data tackling (RandomOverSampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c500a1fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.68\n",
      "Mean Precision: 0.68\n",
      "Mean Recall: 0.68\n",
      "Mean F1-Score: 0.67\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df7' is your DataFrame with features and the target column\n",
    "features = df7a['content'].apply(lambda x: x.split(' ', 1)[1])  # Drop the target column to get the feature columns\n",
    "target = df7a['target'].apply(lambda x: int(x.split(\"__label__\")[1]))  # Target column to predict\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = ''.join([word for word in text if word not in string.punctuation])\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Initialize KFold with 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "i = 1\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    X_train = X_train.apply(preprocess)\n",
    "    X_test = X_test.apply(preprocess)\n",
    "\n",
    "    sentences = [sentence.split() for sentence in X_train]\n",
    "    \n",
    "    # Train the FastText model\n",
    "    fasttext_model = FastText(sentences, vector_size=100, window=20, min_count=2, workers=4, seed=42)\n",
    "    \n",
    "    def vectorize(sentence):\n",
    "        words = sentence.split()\n",
    "        words_vecs = [fasttext_model.wv[word] for word in words if word in fasttext_model.wv]\n",
    "        if len(words_vecs) == 0:\n",
    "            return np.zeros(100)\n",
    "        words_vecs = np.array(words_vecs)\n",
    "        return words_vecs.mean(axis=0)\n",
    "\n",
    "    X_train = np.array([vectorize(sentence) for sentence in X_train])\n",
    "    X_test = np.array([vectorize(sentence) for sentence in X_test])\n",
    "    \n",
    "    # Apply random undersampling\n",
    "    ros = RandomOverSampler(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
    "    \n",
    "    #clf = LogisticRegression()\n",
    "    clf = LinearRegression()\n",
    "    clf.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Apply random undersampling to test data\n",
    "    X_test_resampled, y_test_resampled = rus.fit_resample(X_test, y_test)\n",
    "    \n",
    "    y_pred = clf.predict(X_test_resampled)\n",
    "    \n",
    "    y_pred = np.round(y_pred)\n",
    "    \n",
    "    y_pred[y_pred <= 0] = 1\n",
    "    y_pred[y_pred >= 2] = 2\n",
    "    \n",
    "    # Model evaluation\n",
    "    accuracy = accuracy_score(y_test_resampled, y_pred.round())\n",
    "    precision = precision_score(y_test_resampled, y_pred.round(), average='weighted')\n",
    "    recall = recall_score(y_test_resampled, y_pred.round(), average='weighted')\n",
    "    f1 = f1_score(y_test_resampled, y_pred.round(), average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test_resampled, y_pred.round())\n",
    "    \n",
    "    # Convert classification report to DataFrame\n",
    "    report_df = pd.DataFrame(classification_report(y_test_resampled, y_pred.round(), output_dict=True)).transpose()\n",
    "    # Convert confusion matrix to DataFrame\n",
    "    matrix_df = pd.DataFrame(confusion_matrix(y_test_resampled, y_pred.round()))\n",
    "    \n",
    "    # Extract metrics for class 1\n",
    "    metrics_1 = report_df.loc['1', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract metrics for class 2\n",
    "    metrics_2 = report_df.loc['2', ['precision', 'recall', 'f1-score', 'support']]\n",
    "\n",
    "    # Extract TP, TN, FP, FN counts from the confusion matrix DataFrame\n",
    "    TP = matrix_df.loc[0, 0]\n",
    "    TN = matrix_df.loc[1, 1]\n",
    "    FP = matrix_df.loc[1, 0]\n",
    "    FN = matrix_df.loc[0, 1]\n",
    "    \n",
    "    new_metric_row = {\n",
    "    'dataset': 'DF7a',\n",
    "    'model' : 'Fast Text - Linear Regression',\n",
    "    'data balancing technique' : 'Random Over Sampler',\n",
    "    'fold' : i,\n",
    "    'precision_1': metrics_1['precision'],\n",
    "    'precision_2': metrics_2['precision'],\n",
    "    'recall_1': metrics_1['recall'],\n",
    "    'recall_2': metrics_2['recall'],\n",
    "    'f1-score_1': metrics_1['f1-score'],\n",
    "    'f1-score_2': metrics_2['f1-score'],\n",
    "    'support_1': metrics_1['support'],\n",
    "    'support_2': metrics_2['support'],\n",
    "    'TP' : TP,\n",
    "    'FP' : FP,\n",
    "    'TN' : TN,\n",
    "    'FN' : FN\n",
    "    }\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    #combined_metrics = combined_metrics.append(new_metric_row, ignore_index=True)\n",
    "    combined_metrics.loc[len(combined_metrics)] = new_metric_row\n",
    "    \n",
    "    \n",
    "    # Append evaluation metrics to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    conf_matrices.append(conf_matrix)\n",
    "\n",
    "# Calculate mean evaluation metrics across all folds\n",
    "mean_accuracy = np.mean(accuracy_scores) #sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = np.mean(precision_scores) #sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = np.mean(recall_scores) #sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = np.mean(f1_scores) #sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print('Mean Accuracy: {:.2f}'.format(mean_accuracy))\n",
    "print('Mean Precision: {:.2f}'.format(mean_precision))\n",
    "print('Mean Recall: {:.2f}'.format(mean_recall))\n",
    "print('Mean F1-Score: {:.2f}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca7e58c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>data balancing technique</th>\n",
       "      <th>fold</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_2</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>f1-score_1</th>\n",
       "      <th>f1-score_2</th>\n",
       "      <th>support_1</th>\n",
       "      <th>support_2</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>DF7a</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>1</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.711864</td>\n",
       "      <td>29.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>DF7a</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>2</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>DF7a</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>3</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>DF7a</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>4</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.690909</td>\n",
       "      <td>0.679245</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>DF7a</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>5</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>29.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>DF7a</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>6</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>20</td>\n",
       "      <td>14</td>\n",
       "      <td>24</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>DF7a</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>7</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>DF7a</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>8</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>DF7a</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>9</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>DF7a</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>10</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>22</td>\n",
       "      <td>11</td>\n",
       "      <td>24</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset                          model data balancing technique  fold  \\\n",
       "20    DF7a  Fast Text - Linear Regression      Random Over Sampler     1   \n",
       "21    DF7a  Fast Text - Linear Regression      Random Over Sampler     2   \n",
       "22    DF7a  Fast Text - Linear Regression      Random Over Sampler     3   \n",
       "23    DF7a  Fast Text - Linear Regression      Random Over Sampler     4   \n",
       "24    DF7a  Fast Text - Linear Regression      Random Over Sampler     5   \n",
       "25    DF7a  Fast Text - Linear Regression      Random Over Sampler     6   \n",
       "26    DF7a  Fast Text - Linear Regression      Random Over Sampler     7   \n",
       "27    DF7a  Fast Text - Linear Regression      Random Over Sampler     8   \n",
       "28    DF7a  Fast Text - Linear Regression      Random Over Sampler     9   \n",
       "29    DF7a  Fast Text - Linear Regression      Random Over Sampler    10   \n",
       "\n",
       "    precision_1  precision_2  recall_1  recall_2  f1-score_1  f1-score_2  \\\n",
       "20     0.714286     0.700000  0.689655  0.724138    0.701754    0.711864   \n",
       "21     0.607143     0.593750  0.566667  0.633333    0.586207    0.612903   \n",
       "22     0.666667     0.714286  0.750000  0.625000    0.705882    0.666667   \n",
       "23     0.678571     0.692308  0.703704  0.666667    0.690909    0.679245   \n",
       "24     0.636364     0.680000  0.724138  0.586207    0.677419    0.629630   \n",
       "25     0.588235     0.571429  0.526316  0.631579    0.555556    0.600000   \n",
       "26     0.640000     0.666667  0.695652  0.608696    0.666667    0.636364   \n",
       "27     0.833333     0.700000  0.625000  0.875000    0.714286    0.777778   \n",
       "28     0.551724     0.571429  0.640000  0.480000    0.592593    0.521739   \n",
       "29     0.666667     0.648649  0.628571  0.685714    0.647059    0.666667   \n",
       "\n",
       "    support_1  support_2  TP  FP  TN  FN  \n",
       "20       29.0       29.0  20   8  21   9  \n",
       "21       30.0       30.0  17  11  19  13  \n",
       "22       32.0       32.0  24  12  20   8  \n",
       "23       27.0       27.0  19   9  18   8  \n",
       "24       29.0       29.0  21  12  17   8  \n",
       "25       38.0       38.0  20  14  24  18  \n",
       "26       23.0       23.0  16   9  14   7  \n",
       "27       32.0       32.0  20   4  28  12  \n",
       "28       25.0       25.0  16  13  12   9  \n",
       "29       35.0       35.0  22  11  24  13  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_metrics[(combined_metrics['data balancing technique'] == 'Random Over Sampler') & (combined_metrics['dataset'] == 'DF7a')]#.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd948ec1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc4b04f0",
   "metadata": {},
   "source": [
    "## Performance metrics for the Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1158fa25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>data balancing technique</th>\n",
       "      <th>fold</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_2</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>recall_2</th>\n",
       "      <th>f1-score_1</th>\n",
       "      <th>f1-score_2</th>\n",
       "      <th>support_1</th>\n",
       "      <th>support_2</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DF7a</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0.773333</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.816901</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.794521</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>71.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>58</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DF7a</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>70.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>60</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DF7a</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>0.743590</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.794521</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>68.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>58</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DF7a</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>0.797468</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.863014</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.828947</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>73.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>63</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DF7a</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.845070</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>71.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>60</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DF7a</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>0.697368</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>0.768116</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>62.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>53</td>\n",
       "      <td>23</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DF7a</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>7</td>\n",
       "      <td>0.783133</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>77.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>65</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DF7a</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>8</td>\n",
       "      <td>0.783133</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.955882</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.860927</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>68.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>65</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DF7a</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>9</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.425532</td>\n",
       "      <td>75.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>63</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DF7a</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.830769</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>65.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>54</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DF7a</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>1</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>29.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DF7a</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>2</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.634921</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DF7a</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>3</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.738462</td>\n",
       "      <td>0.730159</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DF7a</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>4</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DF7a</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>5</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>29.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>DF7a</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>6</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.492754</td>\n",
       "      <td>0.578313</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>24</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DF7a</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>7</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DF7a</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>8</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>DF7a</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>9</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.553191</td>\n",
       "      <td>0.603774</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DF7a</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Under Sampler</td>\n",
       "      <td>10</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.657895</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.656716</td>\n",
       "      <td>0.684932</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>DF7a</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>1</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.711864</td>\n",
       "      <td>29.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>DF7a</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>2</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>DF7a</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>3</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>DF7a</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>4</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.690909</td>\n",
       "      <td>0.679245</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>DF7a</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>5</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>29.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>DF7a</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>6</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>20</td>\n",
       "      <td>14</td>\n",
       "      <td>24</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>DF7a</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>7</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>DF7a</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>8</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>DF7a</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>9</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>DF7a</td>\n",
       "      <td>Fast Text - Linear Regression</td>\n",
       "      <td>Random Over Sampler</td>\n",
       "      <td>10</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>22</td>\n",
       "      <td>11</td>\n",
       "      <td>24</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset                          model data balancing technique  fold  \\\n",
       "0     DF7a  Fast Text - Linear Regression                     None     1   \n",
       "1     DF7a  Fast Text - Linear Regression                     None     2   \n",
       "2     DF7a  Fast Text - Linear Regression                     None     3   \n",
       "3     DF7a  Fast Text - Linear Regression                     None     4   \n",
       "4     DF7a  Fast Text - Linear Regression                     None     5   \n",
       "5     DF7a  Fast Text - Linear Regression                     None     6   \n",
       "6     DF7a  Fast Text - Linear Regression                     None     7   \n",
       "7     DF7a  Fast Text - Linear Regression                     None     8   \n",
       "8     DF7a  Fast Text - Linear Regression                     None     9   \n",
       "9     DF7a  Fast Text - Linear Regression                     None    10   \n",
       "10    DF7a  Fast Text - Linear Regression     Random Under Sampler     1   \n",
       "11    DF7a  Fast Text - Linear Regression     Random Under Sampler     2   \n",
       "12    DF7a  Fast Text - Linear Regression     Random Under Sampler     3   \n",
       "13    DF7a  Fast Text - Linear Regression     Random Under Sampler     4   \n",
       "14    DF7a  Fast Text - Linear Regression     Random Under Sampler     5   \n",
       "15    DF7a  Fast Text - Linear Regression     Random Under Sampler     6   \n",
       "16    DF7a  Fast Text - Linear Regression     Random Under Sampler     7   \n",
       "17    DF7a  Fast Text - Linear Regression     Random Under Sampler     8   \n",
       "18    DF7a  Fast Text - Linear Regression     Random Under Sampler     9   \n",
       "19    DF7a  Fast Text - Linear Regression     Random Under Sampler    10   \n",
       "20    DF7a  Fast Text - Linear Regression      Random Over Sampler     1   \n",
       "21    DF7a  Fast Text - Linear Regression      Random Over Sampler     2   \n",
       "22    DF7a  Fast Text - Linear Regression      Random Over Sampler     3   \n",
       "23    DF7a  Fast Text - Linear Regression      Random Over Sampler     4   \n",
       "24    DF7a  Fast Text - Linear Regression      Random Over Sampler     5   \n",
       "25    DF7a  Fast Text - Linear Regression      Random Over Sampler     6   \n",
       "26    DF7a  Fast Text - Linear Regression      Random Over Sampler     7   \n",
       "27    DF7a  Fast Text - Linear Regression      Random Over Sampler     8   \n",
       "28    DF7a  Fast Text - Linear Regression      Random Over Sampler     9   \n",
       "29    DF7a  Fast Text - Linear Regression      Random Over Sampler    10   \n",
       "\n",
       "    precision_1  precision_2  recall_1  recall_2  f1-score_1  f1-score_2  \\\n",
       "0      0.773333     0.480000  0.816901  0.413793    0.794521    0.444444   \n",
       "1      0.769231     0.545455  0.857143  0.400000    0.810811    0.461538   \n",
       "2      0.743590     0.545455  0.852941  0.375000    0.794521    0.444444   \n",
       "3      0.797468     0.523810  0.863014  0.407407    0.828947    0.458333   \n",
       "4      0.740741     0.421053  0.845070  0.275862    0.789474    0.333333   \n",
       "5      0.697368     0.625000  0.854839  0.394737    0.768116    0.483871   \n",
       "6      0.783133     0.294118  0.844156  0.217391    0.812500    0.250000   \n",
       "7      0.783133     0.823529  0.955882  0.437500    0.860927    0.571429   \n",
       "8      0.807692     0.454545  0.840000  0.400000    0.823529    0.425532   \n",
       "9      0.720000     0.560000  0.830769  0.400000    0.771429    0.466667   \n",
       "10     0.724138     0.724138  0.724138  0.724138    0.724138    0.724138   \n",
       "11     0.629630     0.606061  0.566667  0.666667    0.596491    0.634921   \n",
       "12     0.727273     0.741935  0.750000  0.718750    0.738462    0.730159   \n",
       "13     0.689655     0.720000  0.740741  0.666667    0.714286    0.692308   \n",
       "14     0.740741     0.709677  0.689655  0.758621    0.714286    0.733333   \n",
       "15     0.548387     0.533333  0.447368  0.631579    0.492754    0.578313   \n",
       "16     0.666667     0.681818  0.695652  0.652174    0.680851    0.666667   \n",
       "17     0.785714     0.722222  0.687500  0.812500    0.733333    0.764706   \n",
       "18     0.590909     0.571429  0.520000  0.640000    0.553191    0.603774   \n",
       "19     0.687500     0.657895  0.628571  0.714286    0.656716    0.684932   \n",
       "20     0.714286     0.700000  0.689655  0.724138    0.701754    0.711864   \n",
       "21     0.607143     0.593750  0.566667  0.633333    0.586207    0.612903   \n",
       "22     0.666667     0.714286  0.750000  0.625000    0.705882    0.666667   \n",
       "23     0.678571     0.692308  0.703704  0.666667    0.690909    0.679245   \n",
       "24     0.636364     0.680000  0.724138  0.586207    0.677419    0.629630   \n",
       "25     0.588235     0.571429  0.526316  0.631579    0.555556    0.600000   \n",
       "26     0.640000     0.666667  0.695652  0.608696    0.666667    0.636364   \n",
       "27     0.833333     0.700000  0.625000  0.875000    0.714286    0.777778   \n",
       "28     0.551724     0.571429  0.640000  0.480000    0.592593    0.521739   \n",
       "29     0.666667     0.648649  0.628571  0.685714    0.647059    0.666667   \n",
       "\n",
       "    support_1  support_2  TP  FP  TN  FN  \n",
       "0        71.0       29.0  58  17  12  13  \n",
       "1        70.0       30.0  60  18  12  10  \n",
       "2        68.0       32.0  58  20  12  10  \n",
       "3        73.0       27.0  63  16  11  10  \n",
       "4        71.0       29.0  60  21   8  11  \n",
       "5        62.0       38.0  53  23  15   9  \n",
       "6        77.0       23.0  65  18   5  12  \n",
       "7        68.0       32.0  65  18  14   3  \n",
       "8        75.0       25.0  63  15  10  12  \n",
       "9        65.0       35.0  54  21  14  11  \n",
       "10       29.0       29.0  21   8  21   8  \n",
       "11       30.0       30.0  17  10  20  13  \n",
       "12       32.0       32.0  24   9  23   8  \n",
       "13       27.0       27.0  20   9  18   7  \n",
       "14       29.0       29.0  20   7  22   9  \n",
       "15       38.0       38.0  17  14  24  21  \n",
       "16       23.0       23.0  16   8  15   7  \n",
       "17       32.0       32.0  22   6  26  10  \n",
       "18       25.0       25.0  13   9  16  12  \n",
       "19       35.0       35.0  22  10  25  13  \n",
       "20       29.0       29.0  20   8  21   9  \n",
       "21       30.0       30.0  17  11  19  13  \n",
       "22       32.0       32.0  24  12  20   8  \n",
       "23       27.0       27.0  19   9  18   8  \n",
       "24       29.0       29.0  21  12  17   8  \n",
       "25       38.0       38.0  20  14  24  18  \n",
       "26       23.0       23.0  16   9  14   7  \n",
       "27       32.0       32.0  20   4  28  12  \n",
       "28       25.0       25.0  16  13  12   9  \n",
       "29       35.0       35.0  22  11  24  13  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8905e922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame\n",
    "combined_metrics.to_csv('Output Data/Fast Text - Linear Regression2.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
